son.nguyen@n234-182-031:~/workspace/dtf/tfsession$ ./run.sh 
LD_LIBRARY_PATH:
/usr/lib/x86_64-linux-gnu
/usr/local/cuda-11.0/lib64
/data00/home/son.nguyen/workspace/common/cudnn/lib
/data00/home/son.nguyen/workspace/common/tensorflow/lib
/data00/home/son.nguyen/workspace/common/protobuf/lib
2023-12-24 16:15:55.219933: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2023-12-24 16:15:55.220423: I tensorflow/core/platform/cloud/gcs_file_system.cc:806] GCS cache max size = 0 ; block size = 67108864 ; max staleness = 0
2023-12-24 16:15:55.220466: I ./tensorflow/core/platform/cloud/ram_file_block_cache.h:64] GCS file block cache is disabled
2023-12-24 16:15:55.220497: I tensorflow/core/platform/cloud/gcs_file_system.cc:846] GCS DNS cache is disabled, because GCS_RESOLVE_REFRESH_SECS = 0 (or is not set)
2023-12-24 16:15:55.220505: I tensorflow/core/platform/cloud/gcs_file_system.cc:876] GCS additional header DISABLED. No environment variable set.
2023-12-24 16:15:55.230446: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0
2023-12-24 16:15:55.399257: I tensorflow/core/platform/cloud/gcs_file_system.cc:806] GCS cache max size = 0 ; block size = 67108864 ; max staleness = 0
2023-12-24 16:15:55.399303: I ./tensorflow/core/platform/cloud/ram_file_block_cache.h:64] GCS file block cache is disabled
2023-12-24 16:15:55.399330: I tensorflow/core/platform/cloud/gcs_file_system.cc:846] GCS DNS cache is disabled, because GCS_RESOLVE_REFRESH_SECS = 0 (or is not set)
2023-12-24 16:15:55.399337: I tensorflow/core/platform/cloud/gcs_file_system.cc:876] GCS additional header DISABLED. No environment variable set.
Graph file: models/test/test_model_v1/gpu/graph.pb




========================================================================================================================
1. Create a new TF Session object
========================================================================================================================
2023-12-24 16:15:55.399853: I tensorflow/core/common_runtime/session_factory.cc:75] SessionFactory type DIRECT_SESSION accepts target: 
2023-12-24 16:15:55.399943: I ./tensorflow/core/common_runtime/mkl_cpu_allocator.h:148] MklCPUAllocator: In MklCPUAllocator
2023-12-24 16:15:55.399964: I ./tensorflow/core/common_runtime/mkl_cpu_allocator.h:178] MklCPUAllocator: Setting max_mem_bytes: 404052434944
2023-12-24 16:15:55.399997: I tensorflow/core/common_runtime/bfc_allocator.cc:70] Creating new BFCAllocator named: mklcpu
2023-12-24 16:15:55.400006: I tensorflow/core/common_runtime/bfc_allocator.cc:73] Creating bin of max chunk size 256B
2023-12-24 16:15:55.400016: I tensorflow/core/common_runtime/bfc_allocator.cc:73] Creating bin of max chunk size 512B
2023-12-24 16:15:55.400025: I tensorflow/core/common_runtime/bfc_allocator.cc:73] Creating bin of max chunk size 1.0KiB
2023-12-24 16:15:55.400032: I tensorflow/core/common_runtime/bfc_allocator.cc:73] Creating bin of max chunk size 2.0KiB
2023-12-24 16:15:55.400038: I tensorflow/core/common_runtime/bfc_allocator.cc:73] Creating bin of max chunk size 4.0KiB
2023-12-24 16:15:55.400046: I tensorflow/core/common_runtime/bfc_allocator.cc:73] Creating bin of max chunk size 8.0KiB
2023-12-24 16:15:55.400053: I tensorflow/core/common_runtime/bfc_allocator.cc:73] Creating bin of max chunk size 16.0KiB
2023-12-24 16:15:55.400060: I tensorflow/core/common_runtime/bfc_allocator.cc:73] Creating bin of max chunk size 32.0KiB
2023-12-24 16:15:55.400067: I tensorflow/core/common_runtime/bfc_allocator.cc:73] Creating bin of max chunk size 64.0KiB
2023-12-24 16:15:55.400075: I tensorflow/core/common_runtime/bfc_allocator.cc:73] Creating bin of max chunk size 128.0KiB
2023-12-24 16:15:55.400082: I tensorflow/core/common_runtime/bfc_allocator.cc:73] Creating bin of max chunk size 256.0KiB
2023-12-24 16:15:55.400089: I tensorflow/core/common_runtime/bfc_allocator.cc:73] Creating bin of max chunk size 512.0KiB
2023-12-24 16:15:55.400096: I tensorflow/core/common_runtime/bfc_allocator.cc:73] Creating bin of max chunk size 1.00MiB
2023-12-24 16:15:55.400103: I tensorflow/core/common_runtime/bfc_allocator.cc:73] Creating bin of max chunk size 2.00MiB
2023-12-24 16:15:55.400110: I tensorflow/core/common_runtime/bfc_allocator.cc:73] Creating bin of max chunk size 4.00MiB
2023-12-24 16:15:55.400117: I tensorflow/core/common_runtime/bfc_allocator.cc:73] Creating bin of max chunk size 8.00MiB
2023-12-24 16:15:55.400124: I tensorflow/core/common_runtime/bfc_allocator.cc:73] Creating bin of max chunk size 16.00MiB
2023-12-24 16:15:55.400131: I tensorflow/core/common_runtime/bfc_allocator.cc:73] Creating bin of max chunk size 32.00MiB
2023-12-24 16:15:55.400138: I tensorflow/core/common_runtime/bfc_allocator.cc:73] Creating bin of max chunk size 64.00MiB
2023-12-24 16:15:55.400145: I tensorflow/core/common_runtime/bfc_allocator.cc:73] Creating bin of max chunk size 128.00MiB
2023-12-24 16:15:55.400153: I tensorflow/core/common_runtime/bfc_allocator.cc:73] Creating bin of max chunk size 256.00MiB
2023-12-24 16:15:55.400262: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-12-24 16:15:55.400719: I tensorflow/compiler/xla/parse_flags_from_env.cc:197] For env var TF_XLA_FLAGS found arguments:
2023-12-24 16:15:55.400742: I tensorflow/compiler/xla/parse_flags_from_env.cc:199]   argv[0] = <argv[0]>
2023-12-24 16:15:55.400762: I tensorflow/compiler/xla/parse_flags_from_env.cc:197] For env var TF_JITRT_FLAGS found arguments:
2023-12-24 16:15:55.400769: I tensorflow/compiler/xla/parse_flags_from_env.cc:199]   argv[0] = <argv[0]>
2023-12-24 16:15:55.400777: I tensorflow/compiler/jit/xla_cpu_device.cc:58] Not creating XLA devices, tf_xla_enable_xla_devices not set
2023-12-24 16:15:55.400786: I tensorflow/compiler/jit/xla_gpu_device.cc:79] Not creating XLA devices, tf_xla_enable_xla_devices not set
2023-12-24 16:15:55.401704: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcuda.so.1
2023-12-24 16:15:55.411007: I tensorflow/stream_executor/executor_cache.cc:54] building executor
2023-12-24 16:15:55.491469: I tensorflow/stream_executor/cuda/cuda_driver.cc:392] created or reused context 0x558e09f8ebb0 for this thread
2023-12-24 16:15:55.491572: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 0
2023-12-24 16:15:55.491590: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 0
2023-12-24 16:15:55.491628: I tensorflow/stream_executor/executor_cache.cc:54] building executor
2023-12-24 16:15:55.566896: I tensorflow/stream_executor/cuda/cuda_driver.cc:392] created or reused context 0x558e09f81ea0 for this thread
2023-12-24 16:15:55.567006: I tensorflow/stream_executor/cuda/cuda_driver.cc:151] ScopedActivateContext switching to 1
2023-12-24 16:15:55.567041: I tensorflow/stream_executor/cuda/cuda_driver.cc:151] ScopedActivateContext switching to 2
2023-12-24 16:15:55.567082: I tensorflow/stream_executor/cuda/cuda_driver.cc:151] ScopedActivateContext switching to 1
2023-12-24 16:15:55.568454: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 0
2023-12-24 16:15:55.568536: I tensorflow/stream_executor/executor_cache.cc:54] building executor
2023-12-24 16:15:55.642053: I tensorflow/stream_executor/cuda/cuda_driver.cc:392] created or reused context 0x558e09f884b0 for this thread
2023-12-24 16:15:55.642143: I tensorflow/stream_executor/cuda/cuda_driver.cc:151] ScopedActivateContext switching to 1
2023-12-24 16:15:55.642155: I tensorflow/stream_executor/cuda/cuda_driver.cc:151] ScopedActivateContext switching to 3
2023-12-24 16:15:55.642168: I tensorflow/stream_executor/cuda/cuda_driver.cc:151] ScopedActivateContext switching to 1
2023-12-24 16:15:55.643185: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 0
2023-12-24 16:15:55.643240: I tensorflow/stream_executor/executor_cache.cc:54] building executor
2023-12-24 16:15:55.722613: I tensorflow/stream_executor/cuda/cuda_driver.cc:392] created or reused context 0x558e09fc0400 for this thread
2023-12-24 16:15:55.722700: I tensorflow/stream_executor/cuda/cuda_driver.cc:151] ScopedActivateContext switching to 1
2023-12-24 16:15:55.722713: I tensorflow/stream_executor/cuda/cuda_driver.cc:151] ScopedActivateContext switching to 4
2023-12-24 16:15:55.722725: I tensorflow/stream_executor/cuda/cuda_driver.cc:151] ScopedActivateContext switching to 1
2023-12-24 16:15:55.723741: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 1
2023-12-24 16:15:55.723761: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 0
2023-12-24 16:15:55.723770: I tensorflow/stream_executor/cuda/cuda_driver.cc:151] ScopedActivateContext switching to 2
2023-12-24 16:15:55.723778: I tensorflow/stream_executor/cuda/cuda_driver.cc:151] ScopedActivateContext switching to 1
2023-12-24 16:15:55.723787: I tensorflow/stream_executor/cuda/cuda_driver.cc:151] ScopedActivateContext switching to 2
2023-12-24 16:15:55.723797: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 1
2023-12-24 16:15:55.723806: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 1
2023-12-24 16:15:55.723816: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 1
2023-12-24 16:15:55.723825: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 2
2023-12-24 16:15:55.723832: I tensorflow/stream_executor/cuda/cuda_driver.cc:151] ScopedActivateContext switching to 2
2023-12-24 16:15:55.723840: I tensorflow/stream_executor/cuda/cuda_driver.cc:151] ScopedActivateContext switching to 3
2023-12-24 16:15:55.723847: I tensorflow/stream_executor/cuda/cuda_driver.cc:151] ScopedActivateContext switching to 2
2023-12-24 16:15:55.724821: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 1
2023-12-24 16:15:55.724837: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 3
2023-12-24 16:15:55.724845: I tensorflow/stream_executor/cuda/cuda_driver.cc:151] ScopedActivateContext switching to 2
2023-12-24 16:15:55.724853: I tensorflow/stream_executor/cuda/cuda_driver.cc:151] ScopedActivateContext switching to 4
2023-12-24 16:15:55.724861: I tensorflow/stream_executor/cuda/cuda_driver.cc:151] ScopedActivateContext switching to 2
2023-12-24 16:15:55.725797: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 2
2023-12-24 16:15:55.725812: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 0
2023-12-24 16:15:55.725821: I tensorflow/stream_executor/cuda/cuda_driver.cc:151] ScopedActivateContext switching to 3
2023-12-24 16:15:55.725829: I tensorflow/stream_executor/cuda/cuda_driver.cc:151] ScopedActivateContext switching to 1
2023-12-24 16:15:55.725837: I tensorflow/stream_executor/cuda/cuda_driver.cc:151] ScopedActivateContext switching to 3
2023-12-24 16:15:55.725848: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 2
2023-12-24 16:15:55.725857: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 1
2023-12-24 16:15:55.725865: I tensorflow/stream_executor/cuda/cuda_driver.cc:151] ScopedActivateContext switching to 3
2023-12-24 16:15:55.725872: I tensorflow/stream_executor/cuda/cuda_driver.cc:151] ScopedActivateContext switching to 2
2023-12-24 16:15:55.725880: I tensorflow/stream_executor/cuda/cuda_driver.cc:151] ScopedActivateContext switching to 3
2023-12-24 16:15:55.725893: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 2
2023-12-24 16:15:55.725906: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 2
2023-12-24 16:15:55.725915: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 2
2023-12-24 16:15:55.725924: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 3
2023-12-24 16:15:55.725931: I tensorflow/stream_executor/cuda/cuda_driver.cc:151] ScopedActivateContext switching to 3
2023-12-24 16:15:55.725937: I tensorflow/stream_executor/cuda/cuda_driver.cc:151] ScopedActivateContext switching to 4
2023-12-24 16:15:55.725943: I tensorflow/stream_executor/cuda/cuda_driver.cc:151] ScopedActivateContext switching to 3
2023-12-24 16:15:55.726929: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 3
2023-12-24 16:15:55.726945: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 0
2023-12-24 16:15:55.726956: I tensorflow/stream_executor/cuda/cuda_driver.cc:151] ScopedActivateContext switching to 4
2023-12-24 16:15:55.726964: I tensorflow/stream_executor/cuda/cuda_driver.cc:151] ScopedActivateContext switching to 1
2023-12-24 16:15:55.726973: I tensorflow/stream_executor/cuda/cuda_driver.cc:151] ScopedActivateContext switching to 4
2023-12-24 16:15:55.726984: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 3
2023-12-24 16:15:55.726993: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 1
2023-12-24 16:15:55.727000: I tensorflow/stream_executor/cuda/cuda_driver.cc:151] ScopedActivateContext switching to 4
2023-12-24 16:15:55.727007: I tensorflow/stream_executor/cuda/cuda_driver.cc:151] ScopedActivateContext switching to 2
2023-12-24 16:15:55.727014: I tensorflow/stream_executor/cuda/cuda_driver.cc:151] ScopedActivateContext switching to 4
2023-12-24 16:15:55.727024: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 3
2023-12-24 16:15:55.727033: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 2
2023-12-24 16:15:55.727041: I tensorflow/stream_executor/cuda/cuda_driver.cc:151] ScopedActivateContext switching to 4
2023-12-24 16:15:55.727048: I tensorflow/stream_executor/cuda/cuda_driver.cc:151] ScopedActivateContext switching to 3
2023-12-24 16:15:55.727054: I tensorflow/stream_executor/cuda/cuda_driver.cc:151] ScopedActivateContext switching to 4
2023-12-24 16:15:55.727064: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 3
2023-12-24 16:15:55.727073: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 3
2023-12-24 16:15:55.727157: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:252] found DLL info with name: /usr/lib/x86_64-linux-gnu/libcuda.so.1
2023-12-24 16:15:55.727175: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:257] found DLL info with resolved path: /usr/lib/x86_64-linux-gnu/libcuda.so.450.191.01
2023-12-24 16:15:55.727221: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:106] version string "450.191.01" made value 450.191.1
2023-12-24 16:15:55.727279: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:945] trying to read NUMA node for device ordinal: 0
2023-12-24 16:15:55.728060: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1818] Found device 0 with properties: 
pciBusID: 0000:3b:00.0 name: Tesla T4 computeCapability: 7.5
coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s
2023-12-24 16:15:55.728103: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:252] found DLL info with name: /usr/lib/x86_64-linux-gnu/libcuda.so.1
2023-12-24 16:15:55.728118: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:257] found DLL info with resolved path: /usr/lib/x86_64-linux-gnu/libcuda.so.450.191.01
2023-12-24 16:15:55.728136: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:106] version string "450.191.01" made value 450.191.1
2023-12-24 16:15:55.728160: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:945] trying to read NUMA node for device ordinal: 1
2023-12-24 16:15:55.728856: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1818] Found device 1 with properties: 
pciBusID: 0000:5e:00.0 name: Tesla T4 computeCapability: 7.5
coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s
2023-12-24 16:15:55.728881: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:252] found DLL info with name: /usr/lib/x86_64-linux-gnu/libcuda.so.1
2023-12-24 16:15:55.728894: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:257] found DLL info with resolved path: /usr/lib/x86_64-linux-gnu/libcuda.so.450.191.01
2023-12-24 16:15:55.728907: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:106] version string "450.191.01" made value 450.191.1
2023-12-24 16:15:55.728924: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:945] trying to read NUMA node for device ordinal: 2
2023-12-24 16:15:55.729592: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1818] Found device 2 with properties: 
pciBusID: 0000:86:00.0 name: Tesla T4 computeCapability: 7.5
coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s
2023-12-24 16:15:55.729615: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:252] found DLL info with name: /usr/lib/x86_64-linux-gnu/libcuda.so.1
2023-12-24 16:15:55.729626: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:257] found DLL info with resolved path: /usr/lib/x86_64-linux-gnu/libcuda.so.450.191.01
2023-12-24 16:15:55.729639: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:106] version string "450.191.01" made value 450.191.1
2023-12-24 16:15:55.729656: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:945] trying to read NUMA node for device ordinal: 3
2023-12-24 16:15:55.730331: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1818] Found device 3 with properties: 
pciBusID: 0000:af:00.0 name: Tesla T4 computeCapability: 7.5
coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s
2023-12-24 16:15:55.730356: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0
2023-12-24 16:15:55.732677: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11
2023-12-24 16:15:55.732723: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11
2023-12-24 16:15:55.733745: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcufft.so.10
2023-12-24 16:15:55.734026: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcurand.so.10
2023-12-24 16:15:55.736293: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusolver.so.10
2023-12-24 16:15:55.736796: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusparse.so.11
2023-12-24 16:15:55.736939: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudnn.so.8
2023-12-24 16:15:55.736993: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:252] found DLL info with name: /usr/lib/x86_64-linux-gnu/libcuda.so.1
2023-12-24 16:15:55.737007: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:257] found DLL info with resolved path: /usr/lib/x86_64-linux-gnu/libcuda.so.450.191.01
2023-12-24 16:15:55.737023: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:106] version string "450.191.01" made value 450.191.1
2023-12-24 16:15:55.737052: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:945] trying to read NUMA node for device ordinal: 0
2023-12-24 16:15:55.737759: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:252] found DLL info with name: /usr/lib/x86_64-linux-gnu/libcuda.so.1
2023-12-24 16:15:55.737776: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:257] found DLL info with resolved path: /usr/lib/x86_64-linux-gnu/libcuda.so.450.191.01
2023-12-24 16:15:55.737790: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:106] version string "450.191.01" made value 450.191.1
2023-12-24 16:15:55.737809: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:945] trying to read NUMA node for device ordinal: 1
2023-12-24 16:15:55.738483: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:252] found DLL info with name: /usr/lib/x86_64-linux-gnu/libcuda.so.1
2023-12-24 16:15:55.738499: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:257] found DLL info with resolved path: /usr/lib/x86_64-linux-gnu/libcuda.so.450.191.01
2023-12-24 16:15:55.738511: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:106] version string "450.191.01" made value 450.191.1
2023-12-24 16:15:55.738527: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:945] trying to read NUMA node for device ordinal: 2
2023-12-24 16:15:55.739186: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:252] found DLL info with name: /usr/lib/x86_64-linux-gnu/libcuda.so.1
2023-12-24 16:15:55.739205: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:257] found DLL info with resolved path: /usr/lib/x86_64-linux-gnu/libcuda.so.450.191.01
2023-12-24 16:15:55.739217: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:106] version string "450.191.01" made value 450.191.1
2023-12-24 16:15:55.739236: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:945] trying to read NUMA node for device ordinal: 3
2023-12-24 16:15:55.739897: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:252] found DLL info with name: /usr/lib/x86_64-linux-gnu/libcuda.so.1
2023-12-24 16:15:55.739912: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:257] found DLL info with resolved path: /usr/lib/x86_64-linux-gnu/libcuda.so.450.191.01
2023-12-24 16:15:55.739923: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:106] version string "450.191.01" made value 450.191.1
2023-12-24 16:15:55.739940: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:945] trying to read NUMA node for device ordinal: 0
2023-12-24 16:15:55.740638: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:252] found DLL info with name: /usr/lib/x86_64-linux-gnu/libcuda.so.1
2023-12-24 16:15:55.740655: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:257] found DLL info with resolved path: /usr/lib/x86_64-linux-gnu/libcuda.so.450.191.01
2023-12-24 16:15:55.740667: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:106] version string "450.191.01" made value 450.191.1
2023-12-24 16:15:55.740685: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:945] trying to read NUMA node for device ordinal: 1
2023-12-24 16:15:55.741496: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:252] found DLL info with name: /usr/lib/x86_64-linux-gnu/libcuda.so.1
2023-12-24 16:15:55.741517: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:257] found DLL info with resolved path: /usr/lib/x86_64-linux-gnu/libcuda.so.450.191.01
2023-12-24 16:15:55.741531: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:106] version string "450.191.01" made value 450.191.1
2023-12-24 16:15:55.741551: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:945] trying to read NUMA node for device ordinal: 2
2023-12-24 16:15:55.742404: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:252] found DLL info with name: /usr/lib/x86_64-linux-gnu/libcuda.so.1
2023-12-24 16:15:55.742443: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:257] found DLL info with resolved path: /usr/lib/x86_64-linux-gnu/libcuda.so.450.191.01
2023-12-24 16:15:55.742463: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:106] version string "450.191.01" made value 450.191.1
2023-12-24 16:15:55.742493: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:945] trying to read NUMA node for device ordinal: 3
2023-12-24 16:15:55.743216: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1957] Adding visible gpu devices: 0, 1, 2, 3
2023-12-24 16:15:55.743268: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0
2023-12-24 16:15:56.283380: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1315] Cuda stream priority range on GPU(3): -2,0
2023-12-24 16:15:56.753985: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1315] Cuda stream priority range on GPU(3): -2,0
2023-12-24 16:15:57.221991: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1315] Cuda stream priority range on GPU(3): -2,0
2023-12-24 16:15:57.699532: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1315] Cuda stream priority range on GPU(3): -2,0
2023-12-24 16:15:57.699595: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1366] TensorFlow compiled with CUDA 11.0 and cuDNN 8.2.4
2023-12-24 16:15:57.699640: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 0
2023-12-24 16:15:57.699663: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 0
2023-12-24 16:15:57.699692: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 0
2023-12-24 16:15:57.699701: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 1
2023-12-24 16:15:57.699715: I tensorflow/stream_executor/cuda/cuda_driver.cc:151] ScopedActivateContext switching to 1
2023-12-24 16:15:57.699726: I tensorflow/stream_executor/cuda/cuda_driver.cc:151] ScopedActivateContext switching to 2
2023-12-24 16:15:57.699742: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 0
2023-12-24 16:15:57.699751: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 2
2023-12-24 16:15:57.699760: I tensorflow/stream_executor/cuda/cuda_driver.cc:151] ScopedActivateContext switching to 1
2023-12-24 16:15:57.699768: I tensorflow/stream_executor/cuda/cuda_driver.cc:151] ScopedActivateContext switching to 3
2023-12-24 16:15:57.699778: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 0
2023-12-24 16:15:57.699787: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 3
2023-12-24 16:15:57.699796: I tensorflow/stream_executor/cuda/cuda_driver.cc:151] ScopedActivateContext switching to 1
2023-12-24 16:15:57.699804: I tensorflow/stream_executor/cuda/cuda_driver.cc:151] ScopedActivateContext switching to 4
2023-12-24 16:15:57.699813: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 1
2023-12-24 16:15:57.699822: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 0
2023-12-24 16:15:57.699831: I tensorflow/stream_executor/cuda/cuda_driver.cc:151] ScopedActivateContext switching to 2
2023-12-24 16:15:57.699838: I tensorflow/stream_executor/cuda/cuda_driver.cc:151] ScopedActivateContext switching to 1
2023-12-24 16:15:57.699848: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 1
2023-12-24 16:15:57.699857: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 1
2023-12-24 16:15:57.699867: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 1
2023-12-24 16:15:57.699876: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 2
2023-12-24 16:15:57.699886: I tensorflow/stream_executor/cuda/cuda_driver.cc:151] ScopedActivateContext switching to 2
2023-12-24 16:15:57.699893: I tensorflow/stream_executor/cuda/cuda_driver.cc:151] ScopedActivateContext switching to 3
2023-12-24 16:15:57.699902: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 1
2023-12-24 16:15:57.699911: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 3
2023-12-24 16:15:57.699920: I tensorflow/stream_executor/cuda/cuda_driver.cc:151] ScopedActivateContext switching to 2
2023-12-24 16:15:57.699928: I tensorflow/stream_executor/cuda/cuda_driver.cc:151] ScopedActivateContext switching to 4
2023-12-24 16:15:57.699937: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 2
2023-12-24 16:15:57.699946: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 0
2023-12-24 16:15:57.699955: I tensorflow/stream_executor/cuda/cuda_driver.cc:151] ScopedActivateContext switching to 3
2023-12-24 16:15:57.699962: I tensorflow/stream_executor/cuda/cuda_driver.cc:151] ScopedActivateContext switching to 1
2023-12-24 16:15:57.699972: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 2
2023-12-24 16:15:57.699980: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 1
2023-12-24 16:15:57.699990: I tensorflow/stream_executor/cuda/cuda_driver.cc:151] ScopedActivateContext switching to 3
2023-12-24 16:15:57.699997: I tensorflow/stream_executor/cuda/cuda_driver.cc:151] ScopedActivateContext switching to 2
2023-12-24 16:15:57.700007: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 2
2023-12-24 16:15:57.700015: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 2
2023-12-24 16:15:57.700026: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 2
2023-12-24 16:15:57.700035: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 3
2023-12-24 16:15:57.700044: I tensorflow/stream_executor/cuda/cuda_driver.cc:151] ScopedActivateContext switching to 3
2023-12-24 16:15:57.700052: I tensorflow/stream_executor/cuda/cuda_driver.cc:151] ScopedActivateContext switching to 4
2023-12-24 16:15:57.700061: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 3
2023-12-24 16:15:57.700070: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 0
2023-12-24 16:15:57.700079: I tensorflow/stream_executor/cuda/cuda_driver.cc:151] ScopedActivateContext switching to 4
2023-12-24 16:15:57.700086: I tensorflow/stream_executor/cuda/cuda_driver.cc:151] ScopedActivateContext switching to 1
2023-12-24 16:15:57.700096: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 3
2023-12-24 16:15:57.700104: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 1
2023-12-24 16:15:57.700114: I tensorflow/stream_executor/cuda/cuda_driver.cc:151] ScopedActivateContext switching to 4
2023-12-24 16:15:57.700121: I tensorflow/stream_executor/cuda/cuda_driver.cc:151] ScopedActivateContext switching to 2
2023-12-24 16:15:57.700130: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 3
2023-12-24 16:15:57.700139: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 2
2023-12-24 16:15:57.700149: I tensorflow/stream_executor/cuda/cuda_driver.cc:151] ScopedActivateContext switching to 4
2023-12-24 16:15:57.700156: I tensorflow/stream_executor/cuda/cuda_driver.cc:151] ScopedActivateContext switching to 3
2023-12-24 16:15:57.700165: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 3
2023-12-24 16:15:57.700174: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 3
2023-12-24 16:15:57.700230: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1378] Device interconnect StreamExecutor with strength 1 edge matrix:
2023-12-24 16:15:57.700248: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1384]      0 1 2 3 
2023-12-24 16:15:57.700259: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1397] 0:   N Y Y Y 
2023-12-24 16:15:57.700267: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1397] 1:   Y N Y Y 
2023-12-24 16:15:57.700275: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1397] 2:   Y Y N Y 
2023-12-24 16:15:57.700282: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1397] 3:   Y Y Y N 
2023-12-24 16:15:57.700321: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 0
2023-12-24 16:15:57.700332: I tensorflow/stream_executor/cuda/cuda_driver.cc:151] ScopedActivateContext switching to 1
2023-12-24 16:15:57.700419: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:252] found DLL info with name: /usr/lib/x86_64-linux-gnu/libcuda.so.1
2023-12-24 16:15:57.700436: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:257] found DLL info with resolved path: /usr/lib/x86_64-linux-gnu/libcuda.so.450.191.01
2023-12-24 16:15:57.700460: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:106] version string "450.191.01" made value 450.191.1
2023-12-24 16:15:57.700497: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:945] trying to read NUMA node for device ordinal: 0
2023-12-24 16:15:57.701368: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 1
2023-12-24 16:15:57.701401: I tensorflow/stream_executor/cuda/cuda_driver.cc:151] ScopedActivateContext switching to 2
2023-12-24 16:15:57.701464: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:252] found DLL info with name: /usr/lib/x86_64-linux-gnu/libcuda.so.1
2023-12-24 16:15:57.701478: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:257] found DLL info with resolved path: /usr/lib/x86_64-linux-gnu/libcuda.so.450.191.01
2023-12-24 16:15:57.701496: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:106] version string "450.191.01" made value 450.191.1
2023-12-24 16:15:57.701522: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:945] trying to read NUMA node for device ordinal: 1
2023-12-24 16:15:57.702433: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 2
2023-12-24 16:15:57.702469: I tensorflow/stream_executor/cuda/cuda_driver.cc:151] ScopedActivateContext switching to 3
2023-12-24 16:15:57.702531: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:252] found DLL info with name: /usr/lib/x86_64-linux-gnu/libcuda.so.1
2023-12-24 16:15:57.702545: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:257] found DLL info with resolved path: /usr/lib/x86_64-linux-gnu/libcuda.so.450.191.01
2023-12-24 16:15:57.702562: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:106] version string "450.191.01" made value 450.191.1
2023-12-24 16:15:57.702590: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:945] trying to read NUMA node for device ordinal: 2
2023-12-24 16:15:57.703535: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 3
2023-12-24 16:15:57.703570: I tensorflow/stream_executor/cuda/cuda_driver.cc:151] ScopedActivateContext switching to 4
2023-12-24 16:15:57.703630: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:252] found DLL info with name: /usr/lib/x86_64-linux-gnu/libcuda.so.1
2023-12-24 16:15:57.703645: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:257] found DLL info with resolved path: /usr/lib/x86_64-linux-gnu/libcuda.so.450.191.01
2023-12-24 16:15:57.703664: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:106] version string "450.191.01" made value 450.191.1
2023-12-24 16:15:57.703688: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:945] trying to read NUMA node for device ordinal: 3
2023-12-24 16:15:57.704434: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:252] found DLL info with name: /usr/lib/x86_64-linux-gnu/libcuda.so.1
2023-12-24 16:15:57.704453: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:257] found DLL info with resolved path: /usr/lib/x86_64-linux-gnu/libcuda.so.450.191.01
2023-12-24 16:15:57.704467: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:106] version string "450.191.01" made value 450.191.1
2023-12-24 16:15:57.704486: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:945] trying to read NUMA node for device ordinal: 0
2023-12-24 16:15:57.705570: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1659] GPUDevice PlatformDeviceId 0 TfDeviceId 0 on bus 1 numa: 0 pci: 0000:3b:00.0 DeviceLocality: bus_id: 1
links {
  link {
    device_id: 1
    type: "StreamExecutor"
    strength: 1
  }
  link {
    device_id: 2
    type: "StreamExecutor"
    strength: 1
  }
  link {
    device_id: 3
    type: "StreamExecutor"
    strength: 1
  }
}

2023-12-24 16:15:57.705642: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:252] found DLL info with name: /usr/lib/x86_64-linux-gnu/libcuda.so.1
2023-12-24 16:15:57.705657: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:257] found DLL info with resolved path: /usr/lib/x86_64-linux-gnu/libcuda.so.450.191.01
2023-12-24 16:15:57.705672: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:106] version string "450.191.01" made value 450.191.1
2023-12-24 16:15:57.705694: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:945] trying to read NUMA node for device ordinal: 1
2023-12-24 16:15:57.706476: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1659] GPUDevice PlatformDeviceId 1 TfDeviceId 1 on bus 1 numa: 0 pci: 0000:5e:00.0 DeviceLocality: bus_id: 1
links {
  link {
    type: "StreamExecutor"
    strength: 1
  }
  link {
    device_id: 2
    type: "StreamExecutor"
    strength: 1
  }
  link {
    device_id: 3
    type: "StreamExecutor"
    strength: 1
  }
}

2023-12-24 16:15:57.706533: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:252] found DLL info with name: /usr/lib/x86_64-linux-gnu/libcuda.so.1
2023-12-24 16:15:57.706547: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:257] found DLL info with resolved path: /usr/lib/x86_64-linux-gnu/libcuda.so.450.191.01
2023-12-24 16:15:57.706562: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:106] version string "450.191.01" made value 450.191.1
2023-12-24 16:15:57.706583: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:945] trying to read NUMA node for device ordinal: 2
2023-12-24 16:15:57.707325: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1659] GPUDevice PlatformDeviceId 2 TfDeviceId 2 on bus 2 numa: 1 pci: 0000:86:00.0 DeviceLocality: bus_id: 2
numa_node: 1
links {
  link {
    type: "StreamExecutor"
    strength: 1
  }
  link {
    device_id: 1
    type: "StreamExecutor"
    strength: 1
  }
  link {
    device_id: 3
    type: "StreamExecutor"
    strength: 1
  }
}

2023-12-24 16:15:57.707376: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:252] found DLL info with name: /usr/lib/x86_64-linux-gnu/libcuda.so.1
2023-12-24 16:15:57.707389: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:257] found DLL info with resolved path: /usr/lib/x86_64-linux-gnu/libcuda.so.450.191.01
2023-12-24 16:15:57.707403: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:106] version string "450.191.01" made value 450.191.1
2023-12-24 16:15:57.707422: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:945] trying to read NUMA node for device ordinal: 3
2023-12-24 16:15:57.708127: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1659] GPUDevice PlatformDeviceId 3 TfDeviceId 3 on bus 2 numa: 1 pci: 0000:af:00.0 DeviceLocality: bus_id: 2
numa_node: 1
links {
  link {
    type: "StreamExecutor"
    strength: 1
  }
  link {
    device_id: 1
    type: "StreamExecutor"
    strength: 1
  }
  link {
    device_id: 2
    type: "StreamExecutor"
    strength: 1
  }
}

2023-12-24 16:15:57.708201: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:252] found DLL info with name: /usr/lib/x86_64-linux-gnu/libcuda.so.1
2023-12-24 16:15:57.708215: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:257] found DLL info with resolved path: /usr/lib/x86_64-linux-gnu/libcuda.so.450.191.01
2023-12-24 16:15:57.708229: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:106] version string "450.191.01" made value 450.191.1
2023-12-24 16:15:57.708249: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:945] trying to read NUMA node for device ordinal: 0
2023-12-24 16:15:57.708966: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 0
2023-12-24 16:15:57.709003: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 0
2023-12-24 16:15:57.709045: I tensorflow/core/common_runtime/bfc_allocator.cc:70] Creating new BFCAllocator named: GPU_0_bfc
2023-12-24 16:15:57.709055: I tensorflow/core/common_runtime/bfc_allocator.cc:73] Creating bin of max chunk size 256B
2023-12-24 16:15:57.709066: I tensorflow/core/common_runtime/bfc_allocator.cc:73] Creating bin of max chunk size 512B
2023-12-24 16:15:57.709075: I tensorflow/core/common_runtime/bfc_allocator.cc:73] Creating bin of max chunk size 1.0KiB
2023-12-24 16:15:57.709082: I tensorflow/core/common_runtime/bfc_allocator.cc:73] Creating bin of max chunk size 2.0KiB
2023-12-24 16:15:57.709088: I tensorflow/core/common_runtime/bfc_allocator.cc:73] Creating bin of max chunk size 4.0KiB
2023-12-24 16:15:57.709095: I tensorflow/core/common_runtime/bfc_allocator.cc:73] Creating bin of max chunk size 8.0KiB
2023-12-24 16:15:57.709103: I tensorflow/core/common_runtime/bfc_allocator.cc:73] Creating bin of max chunk size 16.0KiB
2023-12-24 16:15:57.709110: I tensorflow/core/common_runtime/bfc_allocator.cc:73] Creating bin of max chunk size 32.0KiB
2023-12-24 16:15:57.709117: I tensorflow/core/common_runtime/bfc_allocator.cc:73] Creating bin of max chunk size 64.0KiB
2023-12-24 16:15:57.709124: I tensorflow/core/common_runtime/bfc_allocator.cc:73] Creating bin of max chunk size 128.0KiB
2023-12-24 16:15:57.709132: I tensorflow/core/common_runtime/bfc_allocator.cc:73] Creating bin of max chunk size 256.0KiB
2023-12-24 16:15:57.709138: I tensorflow/core/common_runtime/bfc_allocator.cc:73] Creating bin of max chunk size 512.0KiB
2023-12-24 16:15:57.709146: I tensorflow/core/common_runtime/bfc_allocator.cc:73] Creating bin of max chunk size 1.00MiB
2023-12-24 16:15:57.709153: I tensorflow/core/common_runtime/bfc_allocator.cc:73] Creating bin of max chunk size 2.00MiB
2023-12-24 16:15:57.709160: I tensorflow/core/common_runtime/bfc_allocator.cc:73] Creating bin of max chunk size 4.00MiB
2023-12-24 16:15:57.709166: I tensorflow/core/common_runtime/bfc_allocator.cc:73] Creating bin of max chunk size 8.00MiB
2023-12-24 16:15:57.709173: I tensorflow/core/common_runtime/bfc_allocator.cc:73] Creating bin of max chunk size 16.00MiB
2023-12-24 16:15:57.709181: I tensorflow/core/common_runtime/bfc_allocator.cc:73] Creating bin of max chunk size 32.00MiB
2023-12-24 16:15:57.709187: I tensorflow/core/common_runtime/bfc_allocator.cc:73] Creating bin of max chunk size 64.00MiB
2023-12-24 16:15:57.709203: I tensorflow/core/common_runtime/bfc_allocator.cc:73] Creating bin of max chunk size 128.00MiB
2023-12-24 16:15:57.709211: I tensorflow/core/common_runtime/bfc_allocator.cc:73] Creating bin of max chunk size 256.00MiB
2023-12-24 16:15:57.709345: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6346 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:3b:00.0, compute capability: 7.5
2023-12-24 16:15:57.709376: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 0
2023-12-24 16:15:57.709444: I tensorflow/stream_executor/stream.cc:256] [stream=0x558e0bbeba30,impl=0x558e35b0f520] Called Stream::Stream(parent=0x558e09f625e0)
2023-12-24 16:15:57.709455: I tensorflow/stream_executor/stream.cc:298] [stream=0x558e0bbeba30,impl=0x558e35b0f520] Called Stream::Init()
2023-12-24 16:15:57.709466: I tensorflow/stream_executor/cuda/cuda_driver.cc:151] ScopedActivateContext switching to 1
2023-12-24 16:15:57.709504: I tensorflow/stream_executor/cuda/cuda_driver.cc:704] successfully created stream 0x558e2de47e80 for context 0x558e09f8ebb0 on thread
2023-12-24 16:15:57.709512: I tensorflow/stream_executor/cuda/cuda_driver.cc:151] ScopedActivateContext switching to 1
2023-12-24 16:15:57.709524: I tensorflow/core/common_runtime/gpu/gpu_device.cc:255] Created stream[0] = 0x558e0bbeba30 with priority: 0
2023-12-24 16:15:57.709538: I tensorflow/stream_executor/stream.cc:256] [stream=0x558e2617ff20,impl=0x558e0bbead30] Called Stream::Stream(parent=0x558e09f625e0)
2023-12-24 16:15:57.709546: I tensorflow/stream_executor/stream.cc:298] [stream=0x558e2617ff20,impl=0x558e0bbead30] Called Stream::Init()
2023-12-24 16:15:57.709553: I tensorflow/stream_executor/cuda/cuda_driver.cc:151] ScopedActivateContext switching to 1
2023-12-24 16:15:57.709562: I tensorflow/stream_executor/cuda/cuda_driver.cc:704] successfully created stream 0x558e2e542dd0 for context 0x558e09f8ebb0 on thread
2023-12-24 16:15:57.709568: I tensorflow/stream_executor/cuda/cuda_driver.cc:151] ScopedActivateContext switching to 1
2023-12-24 16:15:57.709577: I tensorflow/core/common_runtime/gpu/gpu_device.cc:274] Created host_to_device_stream[0] = 0x558e2617ff20
2023-12-24 16:15:57.709589: I tensorflow/stream_executor/stream.cc:256] [stream=0x558e0bbeb4a0,impl=0x558e35b0f460] Called Stream::Stream(parent=0x558e09f625e0)
2023-12-24 16:15:57.709597: I tensorflow/stream_executor/stream.cc:298] [stream=0x558e0bbeb4a0,impl=0x558e35b0f460] Called Stream::Init()
2023-12-24 16:15:57.709604: I tensorflow/stream_executor/cuda/cuda_driver.cc:151] ScopedActivateContext switching to 1
2023-12-24 16:15:57.709612: I tensorflow/stream_executor/cuda/cuda_driver.cc:704] successfully created stream 0x558e361a7ee0 for context 0x558e09f8ebb0 on thread
2023-12-24 16:15:57.709619: I tensorflow/stream_executor/cuda/cuda_driver.cc:151] ScopedActivateContext switching to 1
2023-12-24 16:15:57.709627: I tensorflow/core/common_runtime/gpu/gpu_device.cc:279] Created device_to_host_stream[0] = 0x558e0bbeb4a0
2023-12-24 16:15:57.709639: I tensorflow/stream_executor/stream.cc:256] [stream=0x558e35b10640,impl=0x558e35b0f2b0] Called Stream::Stream(parent=0x558e09f625e0)
2023-12-24 16:15:57.709647: I tensorflow/stream_executor/stream.cc:298] [stream=0x558e35b10640,impl=0x558e35b0f2b0] Called Stream::Init()
2023-12-24 16:15:57.709654: I tensorflow/stream_executor/cuda/cuda_driver.cc:151] ScopedActivateContext switching to 1
2023-12-24 16:15:57.709662: I tensorflow/stream_executor/cuda/cuda_driver.cc:704] successfully created stream 0x558e2e4b7f70 for context 0x558e09f8ebb0 on thread
2023-12-24 16:15:57.709669: I tensorflow/stream_executor/cuda/cuda_driver.cc:151] ScopedActivateContext switching to 1
2023-12-24 16:15:57.709683: I tensorflow/core/common_runtime/gpu/gpu_device.cc:295] Created device_to_device_stream[0] = 0x558e35b10640
2023-12-24 16:15:57.709710: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 0
2023-12-24 16:15:57.709741: I tensorflow/core/common_runtime/bfc_allocator.cc:70] Creating new BFCAllocator named: gpu_host_bfc
2023-12-24 16:15:57.709749: I tensorflow/core/common_runtime/bfc_allocator.cc:73] Creating bin of max chunk size 256B
2023-12-24 16:15:57.709757: I tensorflow/core/common_runtime/bfc_allocator.cc:73] Creating bin of max chunk size 512B
2023-12-24 16:15:57.709765: I tensorflow/core/common_runtime/bfc_allocator.cc:73] Creating bin of max chunk size 1.0KiB
2023-12-24 16:15:57.709773: I tensorflow/core/common_runtime/bfc_allocator.cc:73] Creating bin of max chunk size 2.0KiB
2023-12-24 16:15:57.709779: I tensorflow/core/common_runtime/bfc_allocator.cc:73] Creating bin of max chunk size 4.0KiB
2023-12-24 16:15:57.709786: I tensorflow/core/common_runtime/bfc_allocator.cc:73] Creating bin of max chunk size 8.0KiB
2023-12-24 16:15:57.709794: I tensorflow/core/common_runtime/bfc_allocator.cc:73] Creating bin of max chunk size 16.0KiB
2023-12-24 16:15:57.709801: I tensorflow/core/common_runtime/bfc_allocator.cc:73] Creating bin of max chunk size 32.0KiB
2023-12-24 16:15:57.709808: I tensorflow/core/common_runtime/bfc_allocator.cc:73] Creating bin of max chunk size 64.0KiB
2023-12-24 16:15:57.709815: I tensorflow/core/common_runtime/bfc_allocator.cc:73] Creating bin of max chunk size 128.0KiB
2023-12-24 16:15:57.709822: I tensorflow/core/common_runtime/bfc_allocator.cc:73] Creating bin of max chunk size 256.0KiB
2023-12-24 16:15:57.709829: I tensorflow/core/common_runtime/bfc_allocator.cc:73] Creating bin of max chunk size 512.0KiB
2023-12-24 16:15:57.709836: I tensorflow/core/common_runtime/bfc_allocator.cc:73] Creating bin of max chunk size 1.00MiB
2023-12-24 16:15:57.709843: I tensorflow/core/common_runtime/bfc_allocator.cc:73] Creating bin of max chunk size 2.00MiB
2023-12-24 16:15:57.709850: I tensorflow/core/common_runtime/bfc_allocator.cc:73] Creating bin of max chunk size 4.00MiB
2023-12-24 16:15:57.709857: I tensorflow/core/common_runtime/bfc_allocator.cc:73] Creating bin of max chunk size 8.00MiB
2023-12-24 16:15:57.709864: I tensorflow/core/common_runtime/bfc_allocator.cc:73] Creating bin of max chunk size 16.00MiB
2023-12-24 16:15:57.709871: I tensorflow/core/common_runtime/bfc_allocator.cc:73] Creating bin of max chunk size 32.00MiB
2023-12-24 16:15:57.709878: I tensorflow/core/common_runtime/bfc_allocator.cc:73] Creating bin of max chunk size 64.00MiB
2023-12-24 16:15:57.709885: I tensorflow/core/common_runtime/bfc_allocator.cc:73] Creating bin of max chunk size 128.00MiB
2023-12-24 16:15:57.709893: I tensorflow/core/common_runtime/bfc_allocator.cc:73] Creating bin of max chunk size 256.00MiB
2023-12-24 16:15:57.710392: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:252] found DLL info with name: /usr/lib/x86_64-linux-gnu/libcuda.so.1
2023-12-24 16:15:57.710413: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:257] found DLL info with resolved path: /usr/lib/x86_64-linux-gnu/libcuda.so.450.191.01
2023-12-24 16:15:57.710427: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:106] version string "450.191.01" made value 450.191.1
2023-12-24 16:15:57.710449: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:945] trying to read NUMA node for device ordinal: 1
2023-12-24 16:15:57.711178: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 1
2023-12-24 16:15:57.711210: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 1
2023-12-24 16:15:57.711240: I tensorflow/core/common_runtime/bfc_allocator.cc:70] Creating new BFCAllocator named: GPU_1_bfc
2023-12-24 16:15:57.711248: I tensorflow/core/common_runtime/bfc_allocator.cc:73] Creating bin of max chunk size 256B
2023-12-24 16:15:57.711257: I tensorflow/core/common_runtime/bfc_allocator.cc:73] Creating bin of max chunk size 512B
2023-12-24 16:15:57.711265: I tensorflow/core/common_runtime/bfc_allocator.cc:73] Creating bin of max chunk size 1.0KiB
2023-12-24 16:15:57.711272: I tensorflow/core/common_runtime/bfc_allocator.cc:73] Creating bin of max chunk size 2.0KiB
2023-12-24 16:15:57.711279: I tensorflow/core/common_runtime/bfc_allocator.cc:73] Creating bin of max chunk size 4.0KiB
2023-12-24 16:15:57.711286: I tensorflow/core/common_runtime/bfc_allocator.cc:73] Creating bin of max chunk size 8.0KiB
2023-12-24 16:15:57.711293: I tensorflow/core/common_runtime/bfc_allocator.cc:73] Creating bin of max chunk size 16.0KiB
2023-12-24 16:15:57.711300: I tensorflow/core/common_runtime/bfc_allocator.cc:73] Creating bin of max chunk size 32.0KiB
2023-12-24 16:15:57.711308: I tensorflow/core/common_runtime/bfc_allocator.cc:73] Creating bin of max chunk size 64.0KiB
2023-12-24 16:15:57.711315: I tensorflow/core/common_runtime/bfc_allocator.cc:73] Creating bin of max chunk size 128.0KiB
2023-12-24 16:15:57.711322: I tensorflow/core/common_runtime/bfc_allocator.cc:73] Creating bin of max chunk size 256.0KiB
2023-12-24 16:15:57.711329: I tensorflow/core/common_runtime/bfc_allocator.cc:73] Creating bin of max chunk size 512.0KiB
2023-12-24 16:15:57.711336: I tensorflow/core/common_runtime/bfc_allocator.cc:73] Creating bin of max chunk size 1.00MiB
2023-12-24 16:15:57.711343: I tensorflow/core/common_runtime/bfc_allocator.cc:73] Creating bin of max chunk size 2.00MiB
2023-12-24 16:15:57.711350: I tensorflow/core/common_runtime/bfc_allocator.cc:73] Creating bin of max chunk size 4.00MiB
2023-12-24 16:15:57.711358: I tensorflow/core/common_runtime/bfc_allocator.cc:73] Creating bin of max chunk size 8.00MiB
2023-12-24 16:15:57.711365: I tensorflow/core/common_runtime/bfc_allocator.cc:73] Creating bin of max chunk size 16.00MiB
2023-12-24 16:15:57.711372: I tensorflow/core/common_runtime/bfc_allocator.cc:73] Creating bin of max chunk size 32.00MiB
2023-12-24 16:15:57.711379: I tensorflow/core/common_runtime/bfc_allocator.cc:73] Creating bin of max chunk size 64.00MiB
2023-12-24 16:15:57.711386: I tensorflow/core/common_runtime/bfc_allocator.cc:73] Creating bin of max chunk size 128.00MiB
2023-12-24 16:15:57.711393: I tensorflow/core/common_runtime/bfc_allocator.cc:73] Creating bin of max chunk size 256.00MiB
2023-12-24 16:15:57.711472: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 6346 MB memory:  -> device: 1, name: Tesla T4, pci bus id: 0000:5e:00.0, compute capability: 7.5
2023-12-24 16:15:57.711500: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 1
2023-12-24 16:15:57.711540: I tensorflow/stream_executor/stream.cc:256] [stream=0x558e35b12ad0,impl=0x558e35b12670] Called Stream::Stream(parent=0x558e0a4f4fe0)
2023-12-24 16:15:57.711550: I tensorflow/stream_executor/stream.cc:298] [stream=0x558e35b12ad0,impl=0x558e35b12670] Called Stream::Init()
2023-12-24 16:15:57.711560: I tensorflow/stream_executor/cuda/cuda_driver.cc:151] ScopedActivateContext switching to 2
2023-12-24 16:15:57.711577: I tensorflow/stream_executor/cuda/cuda_driver.cc:704] successfully created stream 0x558e35b12e90 for context 0x558e09f81ea0 on thread
2023-12-24 16:15:57.711584: I tensorflow/stream_executor/cuda/cuda_driver.cc:151] ScopedActivateContext switching to 2
2023-12-24 16:15:57.711594: I tensorflow/core/common_runtime/gpu/gpu_device.cc:255] Created stream[0] = 0x558e35b12ad0 with priority: 0
2023-12-24 16:15:57.711606: I tensorflow/stream_executor/stream.cc:256] [stream=0x558e35b12b80,impl=0x558e35b126a0] Called Stream::Stream(parent=0x558e0a4f4fe0)
2023-12-24 16:15:57.711615: I tensorflow/stream_executor/stream.cc:298] [stream=0x558e35b12b80,impl=0x558e35b126a0] Called Stream::Init()
2023-12-24 16:15:57.711622: I tensorflow/stream_executor/cuda/cuda_driver.cc:151] ScopedActivateContext switching to 2
2023-12-24 16:15:57.711633: I tensorflow/stream_executor/cuda/cuda_driver.cc:704] successfully created stream 0x558e35b131f0 for context 0x558e09f81ea0 on thread
2023-12-24 16:15:57.711641: I tensorflow/stream_executor/cuda/cuda_driver.cc:151] ScopedActivateContext switching to 2
2023-12-24 16:15:57.711650: I tensorflow/core/common_runtime/gpu/gpu_device.cc:274] Created host_to_device_stream[0] = 0x558e35b12b80
2023-12-24 16:15:57.711662: I tensorflow/stream_executor/stream.cc:256] [stream=0x558e35b12c30,impl=0x558e35b12610] Called Stream::Stream(parent=0x558e0a4f4fe0)
2023-12-24 16:15:57.711670: I tensorflow/stream_executor/stream.cc:298] [stream=0x558e35b12c30,impl=0x558e35b12610] Called Stream::Init()
2023-12-24 16:15:57.711677: I tensorflow/stream_executor/cuda/cuda_driver.cc:151] ScopedActivateContext switching to 2
2023-12-24 16:15:57.711686: I tensorflow/stream_executor/cuda/cuda_driver.cc:704] successfully created stream 0x558e35b13430 for context 0x558e09f81ea0 on thread
2023-12-24 16:15:57.711693: I tensorflow/stream_executor/cuda/cuda_driver.cc:151] ScopedActivateContext switching to 2
2023-12-24 16:15:57.711701: I tensorflow/core/common_runtime/gpu/gpu_device.cc:279] Created device_to_host_stream[0] = 0x558e35b12c30
2023-12-24 16:15:57.711713: I tensorflow/stream_executor/stream.cc:256] [stream=0x558e35b13670,impl=0x558e35b12640] Called Stream::Stream(parent=0x558e0a4f4fe0)
2023-12-24 16:15:57.711721: I tensorflow/stream_executor/stream.cc:298] [stream=0x558e35b13670,impl=0x558e35b12640] Called Stream::Init()
2023-12-24 16:15:57.711728: I tensorflow/stream_executor/cuda/cuda_driver.cc:151] ScopedActivateContext switching to 2
2023-12-24 16:15:57.711737: I tensorflow/stream_executor/cuda/cuda_driver.cc:704] successfully created stream 0x558e35b13720 for context 0x558e09f81ea0 on thread
2023-12-24 16:15:57.711745: I tensorflow/stream_executor/cuda/cuda_driver.cc:151] ScopedActivateContext switching to 2
2023-12-24 16:15:57.711758: I tensorflow/core/common_runtime/gpu/gpu_device.cc:295] Created device_to_device_stream[0] = 0x558e35b13670
2023-12-24 16:15:57.712189: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:252] found DLL info with name: /usr/lib/x86_64-linux-gnu/libcuda.so.1
2023-12-24 16:15:57.712221: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:257] found DLL info with resolved path: /usr/lib/x86_64-linux-gnu/libcuda.so.450.191.01
2023-12-24 16:15:57.712235: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:106] version string "450.191.01" made value 450.191.1
2023-12-24 16:15:57.712255: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:945] trying to read NUMA node for device ordinal: 2
2023-12-24 16:15:57.712978: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 2
2023-12-24 16:15:57.713012: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 2
2023-12-24 16:15:57.713043: I tensorflow/core/common_runtime/bfc_allocator.cc:70] Creating new BFCAllocator named: GPU_2_bfc
2023-12-24 16:15:57.713053: I tensorflow/core/common_runtime/bfc_allocator.cc:73] Creating bin of max chunk size 256B
2023-12-24 16:15:57.713062: I tensorflow/core/common_runtime/bfc_allocator.cc:73] Creating bin of max chunk size 512B
2023-12-24 16:15:57.713070: I tensorflow/core/common_runtime/bfc_allocator.cc:73] Creating bin of max chunk size 1.0KiB
2023-12-24 16:15:57.713079: I tensorflow/core/common_runtime/bfc_allocator.cc:73] Creating bin of max chunk size 2.0KiB
2023-12-24 16:15:57.713089: I tensorflow/core/common_runtime/bfc_allocator.cc:73] Creating bin of max chunk size 4.0KiB
2023-12-24 16:15:57.713098: I tensorflow/core/common_runtime/bfc_allocator.cc:73] Creating bin of max chunk size 8.0KiB
2023-12-24 16:15:57.713108: I tensorflow/core/common_runtime/bfc_allocator.cc:73] Creating bin of max chunk size 16.0KiB
2023-12-24 16:15:57.713117: I tensorflow/core/common_runtime/bfc_allocator.cc:73] Creating bin of max chunk size 32.0KiB
2023-12-24 16:15:57.713127: I tensorflow/core/common_runtime/bfc_allocator.cc:73] Creating bin of max chunk size 64.0KiB
2023-12-24 16:15:57.713136: I tensorflow/core/common_runtime/bfc_allocator.cc:73] Creating bin of max chunk size 128.0KiB
2023-12-24 16:15:57.713145: I tensorflow/core/common_runtime/bfc_allocator.cc:73] Creating bin of max chunk size 256.0KiB
2023-12-24 16:15:57.713155: I tensorflow/core/common_runtime/bfc_allocator.cc:73] Creating bin of max chunk size 512.0KiB
2023-12-24 16:15:57.713165: I tensorflow/core/common_runtime/bfc_allocator.cc:73] Creating bin of max chunk size 1.00MiB
2023-12-24 16:15:57.713175: I tensorflow/core/common_runtime/bfc_allocator.cc:73] Creating bin of max chunk size 2.00MiB
2023-12-24 16:15:57.713188: I tensorflow/core/common_runtime/bfc_allocator.cc:73] Creating bin of max chunk size 4.00MiB
2023-12-24 16:15:57.713214: I tensorflow/core/common_runtime/bfc_allocator.cc:73] Creating bin of max chunk size 8.00MiB
2023-12-24 16:15:57.713233: I tensorflow/core/common_runtime/bfc_allocator.cc:73] Creating bin of max chunk size 16.00MiB
2023-12-24 16:15:57.713249: I tensorflow/core/common_runtime/bfc_allocator.cc:73] Creating bin of max chunk size 32.00MiB
2023-12-24 16:15:57.713267: I tensorflow/core/common_runtime/bfc_allocator.cc:73] Creating bin of max chunk size 64.00MiB
2023-12-24 16:15:57.713285: I tensorflow/core/common_runtime/bfc_allocator.cc:73] Creating bin of max chunk size 128.00MiB
2023-12-24 16:15:57.713303: I tensorflow/core/common_runtime/bfc_allocator.cc:73] Creating bin of max chunk size 256.00MiB
2023-12-24 16:15:57.713434: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:2 with 6346 MB memory:  -> device: 2, name: Tesla T4, pci bus id: 0000:86:00.0, compute capability: 7.5
2023-12-24 16:15:57.713505: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 2
2023-12-24 16:15:57.713562: I tensorflow/stream_executor/stream.cc:256] [stream=0x558e35b895b0,impl=0x558e35b89290] Called Stream::Stream(parent=0x558e0ab5aac0)
2023-12-24 16:15:57.713578: I tensorflow/stream_executor/stream.cc:298] [stream=0x558e35b895b0,impl=0x558e35b89290] Called Stream::Init()
2023-12-24 16:15:57.713592: I tensorflow/stream_executor/cuda/cuda_driver.cc:151] ScopedActivateContext switching to 3
2023-12-24 16:15:57.713617: I tensorflow/stream_executor/cuda/cuda_driver.cc:704] successfully created stream 0x558e35b89970 for context 0x558e09f884b0 on thread
2023-12-24 16:15:57.713627: I tensorflow/stream_executor/cuda/cuda_driver.cc:151] ScopedActivateContext switching to 3
2023-12-24 16:15:57.713642: I tensorflow/core/common_runtime/gpu/gpu_device.cc:255] Created stream[0] = 0x558e35b895b0 with priority: 0
2023-12-24 16:15:57.713665: I tensorflow/stream_executor/stream.cc:256] [stream=0x558e35b89660,impl=0x558e35b892c0] Called Stream::Stream(parent=0x558e0ab5aac0)
2023-12-24 16:15:57.713680: I tensorflow/stream_executor/stream.cc:298] [stream=0x558e35b89660,impl=0x558e35b892c0] Called Stream::Init()
2023-12-24 16:15:57.713691: I tensorflow/stream_executor/cuda/cuda_driver.cc:151] ScopedActivateContext switching to 3
2023-12-24 16:15:57.713712: I tensorflow/stream_executor/cuda/cuda_driver.cc:704] successfully created stream 0x558e35b89c70 for context 0x558e09f884b0 on thread
2023-12-24 16:15:57.713725: I tensorflow/stream_executor/cuda/cuda_driver.cc:151] ScopedActivateContext switching to 3
2023-12-24 16:15:57.713737: I tensorflow/core/common_runtime/gpu/gpu_device.cc:274] Created host_to_device_stream[0] = 0x558e35b89660
2023-12-24 16:15:57.713757: I tensorflow/stream_executor/stream.cc:256] [stream=0x558e35b89710,impl=0x558e35b89230] Called Stream::Stream(parent=0x558e0ab5aac0)
2023-12-24 16:15:57.713766: I tensorflow/stream_executor/stream.cc:298] [stream=0x558e35b89710,impl=0x558e35b89230] Called Stream::Init()
2023-12-24 16:15:57.713773: I tensorflow/stream_executor/cuda/cuda_driver.cc:151] ScopedActivateContext switching to 3
2023-12-24 16:15:57.713784: I tensorflow/stream_executor/cuda/cuda_driver.cc:704] successfully created stream 0x558e35b89eb0 for context 0x558e09f884b0 on thread
2023-12-24 16:15:57.713790: I tensorflow/stream_executor/cuda/cuda_driver.cc:151] ScopedActivateContext switching to 3
2023-12-24 16:15:57.713799: I tensorflow/core/common_runtime/gpu/gpu_device.cc:279] Created device_to_host_stream[0] = 0x558e35b89710
2023-12-24 16:15:57.713811: I tensorflow/stream_executor/stream.cc:256] [stream=0x558e35b8a0f0,impl=0x558e35b89260] Called Stream::Stream(parent=0x558e0ab5aac0)
2023-12-24 16:15:57.713819: I tensorflow/stream_executor/stream.cc:298] [stream=0x558e35b8a0f0,impl=0x558e35b89260] Called Stream::Init()
2023-12-24 16:15:57.713826: I tensorflow/stream_executor/cuda/cuda_driver.cc:151] ScopedActivateContext switching to 3
2023-12-24 16:15:57.713835: I tensorflow/stream_executor/cuda/cuda_driver.cc:704] successfully created stream 0x558e35b8a1a0 for context 0x558e09f884b0 on thread
2023-12-24 16:15:57.713842: I tensorflow/stream_executor/cuda/cuda_driver.cc:151] ScopedActivateContext switching to 3
2023-12-24 16:15:57.713859: I tensorflow/core/common_runtime/gpu/gpu_device.cc:295] Created device_to_device_stream[0] = 0x558e35b8a0f0
2023-12-24 16:15:57.714316: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:252] found DLL info with name: /usr/lib/x86_64-linux-gnu/libcuda.so.1
2023-12-24 16:15:57.714339: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:257] found DLL info with resolved path: /usr/lib/x86_64-linux-gnu/libcuda.so.450.191.01
2023-12-24 16:15:57.714356: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:106] version string "450.191.01" made value 450.191.1
2023-12-24 16:15:57.714381: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:945] trying to read NUMA node for device ordinal: 3
2023-12-24 16:15:57.715124: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 3
2023-12-24 16:15:57.715149: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 3
2023-12-24 16:15:57.715179: I tensorflow/core/common_runtime/bfc_allocator.cc:70] Creating new BFCAllocator named: GPU_3_bfc
2023-12-24 16:15:57.715187: I tensorflow/core/common_runtime/bfc_allocator.cc:73] Creating bin of max chunk size 256B
2023-12-24 16:15:57.715203: I tensorflow/core/common_runtime/bfc_allocator.cc:73] Creating bin of max chunk size 512B
2023-12-24 16:15:57.715211: I tensorflow/core/common_runtime/bfc_allocator.cc:73] Creating bin of max chunk size 1.0KiB
2023-12-24 16:15:57.715218: I tensorflow/core/common_runtime/bfc_allocator.cc:73] Creating bin of max chunk size 2.0KiB
2023-12-24 16:15:57.715225: I tensorflow/core/common_runtime/bfc_allocator.cc:73] Creating bin of max chunk size 4.0KiB
2023-12-24 16:15:57.715232: I tensorflow/core/common_runtime/bfc_allocator.cc:73] Creating bin of max chunk size 8.0KiB
2023-12-24 16:15:57.715239: I tensorflow/core/common_runtime/bfc_allocator.cc:73] Creating bin of max chunk size 16.0KiB
2023-12-24 16:15:57.715246: I tensorflow/core/common_runtime/bfc_allocator.cc:73] Creating bin of max chunk size 32.0KiB
2023-12-24 16:15:57.715253: I tensorflow/core/common_runtime/bfc_allocator.cc:73] Creating bin of max chunk size 64.0KiB
2023-12-24 16:15:57.715260: I tensorflow/core/common_runtime/bfc_allocator.cc:73] Creating bin of max chunk size 128.0KiB
2023-12-24 16:15:57.715267: I tensorflow/core/common_runtime/bfc_allocator.cc:73] Creating bin of max chunk size 256.0KiB
2023-12-24 16:15:57.715274: I tensorflow/core/common_runtime/bfc_allocator.cc:73] Creating bin of max chunk size 512.0KiB
2023-12-24 16:15:57.715281: I tensorflow/core/common_runtime/bfc_allocator.cc:73] Creating bin of max chunk size 1.00MiB
2023-12-24 16:15:57.715287: I tensorflow/core/common_runtime/bfc_allocator.cc:73] Creating bin of max chunk size 2.00MiB
2023-12-24 16:15:57.715294: I tensorflow/core/common_runtime/bfc_allocator.cc:73] Creating bin of max chunk size 4.00MiB
2023-12-24 16:15:57.715301: I tensorflow/core/common_runtime/bfc_allocator.cc:73] Creating bin of max chunk size 8.00MiB
2023-12-24 16:15:57.715308: I tensorflow/core/common_runtime/bfc_allocator.cc:73] Creating bin of max chunk size 16.00MiB
2023-12-24 16:15:57.715315: I tensorflow/core/common_runtime/bfc_allocator.cc:73] Creating bin of max chunk size 32.00MiB
2023-12-24 16:15:57.715322: I tensorflow/core/common_runtime/bfc_allocator.cc:73] Creating bin of max chunk size 64.00MiB
2023-12-24 16:15:57.715329: I tensorflow/core/common_runtime/bfc_allocator.cc:73] Creating bin of max chunk size 128.00MiB
2023-12-24 16:15:57.715336: I tensorflow/core/common_runtime/bfc_allocator.cc:73] Creating bin of max chunk size 256.00MiB
2023-12-24 16:15:57.715420: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:3 with 6346 MB memory:  -> device: 3, name: Tesla T4, pci bus id: 0000:af:00.0, compute capability: 7.5
2023-12-24 16:15:57.715449: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 3
2023-12-24 16:15:57.715487: I tensorflow/stream_executor/stream.cc:256] [stream=0x558e35b8bf30,impl=0x558e35b8bb30] Called Stream::Stream(parent=0x558e0b1c9060)
2023-12-24 16:15:57.715497: I tensorflow/stream_executor/stream.cc:298] [stream=0x558e35b8bf30,impl=0x558e35b8bb30] Called Stream::Init()
2023-12-24 16:15:57.715505: I tensorflow/stream_executor/cuda/cuda_driver.cc:151] ScopedActivateContext switching to 4
2023-12-24 16:15:57.715522: I tensorflow/stream_executor/cuda/cuda_driver.cc:704] successfully created stream 0x558e35b52fd0 for context 0x558e09fc0400 on thread
2023-12-24 16:15:57.715529: I tensorflow/stream_executor/cuda/cuda_driver.cc:151] ScopedActivateContext switching to 4
2023-12-24 16:15:57.715538: I tensorflow/core/common_runtime/gpu/gpu_device.cc:255] Created stream[0] = 0x558e35b8bf30 with priority: 0
2023-12-24 16:15:57.715550: I tensorflow/stream_executor/stream.cc:256] [stream=0x558e35b52d70,impl=0x558e35b8bb60] Called Stream::Stream(parent=0x558e0b1c9060)
2023-12-24 16:15:57.715558: I tensorflow/stream_executor/stream.cc:298] [stream=0x558e35b52d70,impl=0x558e35b8bb60] Called Stream::Init()
2023-12-24 16:15:57.715565: I tensorflow/stream_executor/cuda/cuda_driver.cc:151] ScopedActivateContext switching to 4
2023-12-24 16:15:57.715573: I tensorflow/stream_executor/cuda/cuda_driver.cc:704] successfully created stream 0x558e35b53330 for context 0x558e09fc0400 on thread
2023-12-24 16:15:57.715580: I tensorflow/stream_executor/cuda/cuda_driver.cc:151] ScopedActivateContext switching to 4
2023-12-24 16:15:57.715588: I tensorflow/core/common_runtime/gpu/gpu_device.cc:274] Created host_to_device_stream[0] = 0x558e35b52d70
2023-12-24 16:15:57.715599: I tensorflow/stream_executor/stream.cc:256] [stream=0x558e35b53570,impl=0x558e35b8bad0] Called Stream::Stream(parent=0x558e0b1c9060)
2023-12-24 16:15:57.715607: I tensorflow/stream_executor/stream.cc:298] [stream=0x558e35b53570,impl=0x558e35b8bad0] Called Stream::Init()
2023-12-24 16:15:57.715614: I tensorflow/stream_executor/cuda/cuda_driver.cc:151] ScopedActivateContext switching to 4
2023-12-24 16:15:57.715622: I tensorflow/stream_executor/cuda/cuda_driver.cc:704] successfully created stream 0x558e35b53620 for context 0x558e09fc0400 on thread
2023-12-24 16:15:57.715629: I tensorflow/stream_executor/cuda/cuda_driver.cc:151] ScopedActivateContext switching to 4
2023-12-24 16:15:57.715636: I tensorflow/core/common_runtime/gpu/gpu_device.cc:279] Created device_to_host_stream[0] = 0x558e35b53570
2023-12-24 16:15:57.715648: I tensorflow/stream_executor/stream.cc:256] [stream=0x558e35b53860,impl=0x558e35b8bb00] Called Stream::Stream(parent=0x558e0b1c9060)
2023-12-24 16:15:57.715656: I tensorflow/stream_executor/stream.cc:298] [stream=0x558e35b53860,impl=0x558e35b8bb00] Called Stream::Init()
2023-12-24 16:15:57.715662: I tensorflow/stream_executor/cuda/cuda_driver.cc:151] ScopedActivateContext switching to 4
2023-12-24 16:15:57.715671: I tensorflow/stream_executor/cuda/cuda_driver.cc:704] successfully created stream 0x558e35b53910 for context 0x558e09fc0400 on thread
2023-12-24 16:15:57.715677: I tensorflow/stream_executor/cuda/cuda_driver.cc:151] ScopedActivateContext switching to 4
2023-12-24 16:15:57.715688: I tensorflow/core/common_runtime/gpu/gpu_device.cc:295] Created device_to_device_stream[0] = 0x558e35b53860
2023-12-24 16:15:57.716227: I tensorflow/core/common_runtime/process_util.cc:159] Session inter op parallelism threads: 10
2023-12-24 16:15:57.717213: I tensorflow/core/common_runtime/direct_session.cc:370] Device mapping:
/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: Tesla T4, pci bus id: 0000:3b:00.0, compute capability: 7.5
/job:localhost/replica:0/task:0/device:GPU:1 -> device: 1, name: Tesla T4, pci bus id: 0000:5e:00.0, compute capability: 7.5
/job:localhost/replica:0/task:0/device:GPU:2 -> device: 2, name: Tesla T4, pci bus id: 0000:86:00.0, compute capability: 7.5
/job:localhost/replica:0/task:0/device:GPU:3 -> device: 3, name: Tesla T4, pci bus id: 0000:af:00.0, compute capability: 7.5

Successfully created a new TF Session object




========================================================================================================================
2. Create the Session object with graph
========================================================================================================================
2023-12-24 16:15:57.820322: I tensorflow/core/graph/graph.cc:616] AddNode: no type constructor for _SOURCE
2023-12-24 16:15:57.820440: I tensorflow/core/graph/graph.cc:616] AddNode: no type constructor for _SINK
2023-12-24 16:15:57.820961: I tensorflow/core/graph/graph.cc:616] AddNode: no type constructor for X
2023-12-24 16:15:57.821063: I tensorflow/core/graph/graph.cc:616] AddNode: no type constructor for Weight
2023-12-24 16:15:57.821129: I tensorflow/core/graph/graph.cc:616] AddNode: no type constructor for Weight/read
2023-12-24 16:15:57.821207: I tensorflow/core/graph/graph.cc:616] AddNode: no type constructor for Bias
2023-12-24 16:15:57.821262: I tensorflow/core/graph/graph.cc:616] AddNode: no type constructor for Bias/read
2023-12-24 16:15:57.821324: I tensorflow/core/graph/graph.cc:616] AddNode: no type constructor for MatMul
2023-12-24 16:15:57.821376: I tensorflow/core/graph/graph.cc:616] AddNode: no type constructor for Add
2023-12-24 16:15:57.821426: I tensorflow/core/graph/graph.cc:616] AddNode: no type constructor for Sigmoid
2023-12-24 16:15:57.821573: I tensorflow/core/common_runtime/optimization_registry.cc:54] Starting optimization of a group 0
2023-12-24 16:15:57.821727: W tensorflow/core/util/dump_graph.cc:134] Failed to dump before_grouping_0_94068946570032 because dump location is not  specified through either TF_DUMP_GRAPH_PREFIX environment variable or function argument.
2023-12-24 16:15:57.821837: I tensorflow/core/common_runtime/optimization_registry.cc:66] Running optimization phase 0
2023-12-24 16:15:57.821851: I tensorflow/core/common_runtime/optimization_registry.cc:68] Running optimization pass: MlirV1CompatGraphOptimizationPass
2023-12-24 16:15:57.821867: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:354] MLIR V1 optimization pass is not enabled
2023-12-24 16:15:57.821887: I tensorflow/core/common_runtime/optimization_registry.cc:66] Running optimization phase 9
2023-12-24 16:15:57.821894: I tensorflow/core/common_runtime/optimization_registry.cc:68] Running optimization pass: ControlFlowDepsToChainsPass
2023-12-24 16:15:57.821902: I tensorflow/core/common_runtime/control_flow_deps_to_chains.cc:37] ControlFlowDepsToChainsPass::Run
2023-12-24 16:15:57.821988: W tensorflow/core/util/dump_graph.cc:134] Failed to dump control_flow_deps_to_chains_before because dump location is not  specified through either TF_DUMP_GRAPH_PREFIX environment variable or function argument.
2023-12-24 16:15:57.822090: W tensorflow/core/util/dump_graph.cc:134] Failed to dump control_flow_deps_to_chains_after because dump location is not  specified through either TF_DUMP_GRAPH_PREFIX environment variable or function argument.
2023-12-24 16:15:57.822129: I tensorflow/core/common_runtime/optimization_registry.cc:66] Running optimization phase 10
2023-12-24 16:15:57.822138: I tensorflow/core/common_runtime/optimization_registry.cc:68] Running optimization pass: AccumulateNV2RemovePass
2023-12-24 16:15:57.822160: I tensorflow/core/common_runtime/optimization_registry.cc:68] Running optimization pass: LowerFunctionalOpsPass
2023-12-24 16:15:57.822178: I tensorflow/core/common_runtime/optimization_registry.cc:68] Running optimization pass: ParallelConcatRemovePass
2023-12-24 16:15:57.822193: I tensorflow/core/common_runtime/optimization_registry.cc:66] Running optimization phase 35
2023-12-24 16:15:57.822206: I tensorflow/core/common_runtime/optimization_registry.cc:68] Running optimization pass: IsolatePlacerInspectionRequiredOpsPass
2023-12-24 16:15:57.822214: I tensorflow/core/common_runtime/isolate_placer_inspection_required_ops_pass.cc:34] IsolatePlacerInspectionRequiredOpsPass::Run
2023-12-24 16:15:57.823491: I tensorflow/core/util/dump_graph.cc:219] Dumped Graph to /tmp/isolate_deep_ops_before.pbtxt
2023-12-24 16:15:57.824153: I tensorflow/core/util/dump_graph.cc:219] Dumped Graph to /tmp/isolate_deep_ops_after.pbtxt
2023-12-24 16:15:57.824229: I tensorflow/core/common_runtime/optimization_registry.cc:68] Running optimization pass: IntroduceFloatingPointJitterPass
2023-12-24 16:15:57.824246: I tensorflow/compiler/jit/introduce_floating_point_jitter_pass.cc:126] Nothing to do
2023-12-24 16:15:57.824259: I tensorflow/core/common_runtime/optimization_registry.cc:66] Running optimization phase 36
2023-12-24 16:15:57.824267: I tensorflow/core/common_runtime/optimization_registry.cc:68] Running optimization pass: EncapsulateXlaComputationsPass
2023-12-24 16:15:57.824377: W tensorflow/core/util/dump_graph.cc:134] Failed to dump encapsulate_xla_computations_before because dump location is not  specified through either TF_DUMP_GRAPH_PREFIX environment variable or function argument.
2023-12-24 16:15:57.824422: I tensorflow/compiler/jit/encapsulate_xla_computations_pass.cc:353] EncapsulateXlaComputations(): (failed to create writable file: INVALID_ARGUMENT: TF_DUMP_GRAPH_PREFIX not specified)
2023-12-24 16:15:57.824506: I tensorflow/core/graph/graph.cc:616] AddNode: no type constructor for _SOURCE
2023-12-24 16:15:57.824566: I tensorflow/core/graph/graph.cc:616] AddNode: no type constructor for _SINK
2023-12-24 16:15:57.824687: I tensorflow/core/graph/graph.cc:616] AddNode: no type constructor for _SOURCE
2023-12-24 16:15:57.824719: I tensorflow/core/graph/graph.cc:616] AddNode: no type constructor for _SINK
2023-12-24 16:15:57.825011: W tensorflow/core/util/dump_graph.cc:134] Failed to dump encapsulate_xla_computations_halfway because dump location is not  specified through either TF_DUMP_GRAPH_PREFIX environment variable or function argument.
2023-12-24 16:15:57.825060: I tensorflow/compiler/jit/encapsulate_xla_computations_pass.cc:364] EncapsulateXlaComputations() half-way: (failed to create writable file: INVALID_ARGUMENT: TF_DUMP_GRAPH_PREFIX not specified)
2023-12-24 16:15:57.825150: W tensorflow/core/util/dump_graph.cc:134] Failed to dump encapsulate_xla_computations_after because dump location is not  specified through either TF_DUMP_GRAPH_PREFIX environment variable or function argument.
2023-12-24 16:15:57.825183: I tensorflow/compiler/jit/encapsulate_xla_computations_pass.cc:370] EncapsulateXlaComputations() finished: (failed to create writable file: INVALID_ARGUMENT: TF_DUMP_GRAPH_PREFIX not specified)
2023-12-24 16:15:57.825213: I tensorflow/core/common_runtime/optimization_registry.cc:66] Running optimization phase 37
2023-12-24 16:15:57.825222: I tensorflow/core/common_runtime/optimization_registry.cc:68] Running optimization pass: FunctionalizeControlFlowForXlaPass
2023-12-24 16:15:57.825416: I tensorflow/core/common_runtime/optimization_registry.cc:66] Running optimization phase 99999
2023-12-24 16:15:57.825428: I tensorflow/core/common_runtime/optimization_registry.cc:68] Running optimization pass: WeakForwardTypeInferencePass
2023-12-24 16:15:57.825437: I tensorflow/core/common_runtime/forward_type_inference.cc:52] ForwardTypeInferencePass::Run
2023-12-24 16:15:57.825539: W tensorflow/core/util/dump_graph.cc:134] Failed to dump forward_type_inference_before because dump location is not  specified through either TF_DUMP_GRAPH_PREFIX environment variable or function argument.
2023-12-24 16:15:57.825717: I tensorflow/core/common_runtime/forward_type_inference.cc:165] Iteration 0, 5 nodes in queue
2023-12-24 16:15:57.825729: I tensorflow/core/common_runtime/forward_type_inference.cc:171]   visiting _SOURCE
2023-12-24 16:15:57.825740: I tensorflow/core/common_runtime/forward_type_inference.cc:72]   processing _SOURCE
2023-12-24 16:15:57.825763: I tensorflow/core/common_runtime/forward_type_inference.cc:183]   closing _SOURCE
2023-12-24 16:15:57.825774: I tensorflow/core/common_runtime/forward_type_inference.cc:171]   visiting _SINK
2023-12-24 16:15:57.825782: I tensorflow/core/common_runtime/forward_type_inference.cc:72]   processing _SINK
2023-12-24 16:15:57.825793: I tensorflow/core/common_runtime/forward_type_inference.cc:183]   closing _SINK
2023-12-24 16:15:57.825803: I tensorflow/core/common_runtime/forward_type_inference.cc:171]   visiting X
2023-12-24 16:15:57.825810: I tensorflow/core/common_runtime/forward_type_inference.cc:72]   processing X
2023-12-24 16:15:57.825821: I tensorflow/core/common_runtime/forward_type_inference.cc:183]   closing X
2023-12-24 16:15:57.825836: I tensorflow/core/common_runtime/forward_type_inference.cc:171]   visiting Weight
2023-12-24 16:15:57.825844: I tensorflow/core/common_runtime/forward_type_inference.cc:72]   processing Weight
2023-12-24 16:15:57.825855: I tensorflow/core/common_runtime/forward_type_inference.cc:183]   closing Weight
2023-12-24 16:15:57.825868: I tensorflow/core/common_runtime/forward_type_inference.cc:171]   visiting Bias
2023-12-24 16:15:57.825876: I tensorflow/core/common_runtime/forward_type_inference.cc:72]   processing Bias
2023-12-24 16:15:57.825887: I tensorflow/core/common_runtime/forward_type_inference.cc:183]   closing Bias
2023-12-24 16:15:57.825898: I tensorflow/core/common_runtime/forward_type_inference.cc:171]   visiting Weight/read
2023-12-24 16:15:57.825905: I tensorflow/core/common_runtime/forward_type_inference.cc:72]   processing Weight/read
2023-12-24 16:15:57.825942: I tensorflow/core/common_runtime/forward_type_inference.cc:115]   Weight/read no new type information
2023-12-24 16:15:57.825957: I tensorflow/core/common_runtime/forward_type_inference.cc:183]   closing Weight/read
2023-12-24 16:15:57.825969: I tensorflow/core/common_runtime/forward_type_inference.cc:171]   visiting Bias/read
2023-12-24 16:15:57.825977: I tensorflow/core/common_runtime/forward_type_inference.cc:72]   processing Bias/read
2023-12-24 16:15:57.825991: I tensorflow/core/common_runtime/forward_type_inference.cc:115]   Bias/read no new type information
2023-12-24 16:15:57.826002: I tensorflow/core/common_runtime/forward_type_inference.cc:183]   closing Bias/read
2023-12-24 16:15:57.826012: I tensorflow/core/common_runtime/forward_type_inference.cc:171]   visiting MatMul
2023-12-24 16:15:57.826019: I tensorflow/core/common_runtime/forward_type_inference.cc:72]   processing MatMul
2023-12-24 16:15:57.826031: I tensorflow/core/common_runtime/forward_type_inference.cc:183]   closing MatMul
2023-12-24 16:15:57.826045: I tensorflow/core/common_runtime/forward_type_inference.cc:171]   visiting Add
2023-12-24 16:15:57.826053: I tensorflow/core/common_runtime/forward_type_inference.cc:72]   processing Add
2023-12-24 16:15:57.826065: I tensorflow/core/common_runtime/forward_type_inference.cc:183]   closing Add
2023-12-24 16:15:57.826076: I tensorflow/core/common_runtime/forward_type_inference.cc:171]   visiting Sigmoid
2023-12-24 16:15:57.826084: I tensorflow/core/common_runtime/forward_type_inference.cc:72]   processing Sigmoid
2023-12-24 16:15:57.826095: I tensorflow/core/common_runtime/forward_type_inference.cc:183]   closing Sigmoid
2023-12-24 16:15:57.826104: I tensorflow/core/common_runtime/forward_type_inference.cc:206] Done iteration 0, 10 nodes closed
2023-12-24 16:15:57.826111: I tensorflow/core/common_runtime/forward_type_inference.cc:210] Finished after 0 iterations; done 10 of 10 nodes in 10 visits
2023-12-24 16:15:57.826217: W tensorflow/core/util/dump_graph.cc:134] Failed to dump forward_type_inference_after because dump location is not  specified through either TF_DUMP_GRAPH_PREFIX environment variable or function argument.
2023-12-24 16:15:57.826282: I tensorflow/core/common_runtime/optimization_registry.cc:87] Finished optimization of a group 0
2023-12-24 16:15:57.826364: W tensorflow/core/util/dump_graph.cc:134] Failed to dump after_grouping_0_94069088588736 because dump location is not  specified through either TF_DUMP_GRAPH_PREFIX environment variable or function argument.
2023-12-24 16:15:57.826463: W tensorflow/core/util/dump_graph.cc:134] Failed to dump placer_input because dump location is not  specified through either TF_DUMP_GRAPH_PREFIX environment variable or function argument.
2023-12-24 16:15:57.826600: I tensorflow/core/framework/op_kernel.cc:1356] No device-specific kernels found for NodeDef '{{node X}}'Will fall back to a default kernel.

Weight/read: (Identity): /job:localhost/replica:0/task:0/device:GPU:0
2023-12-24 16:15:57.827023: I tensorflow/core/common_runtime/placer.cc:114] Weight/read: (Identity): /job:localhost/replica:0/task:0/device:GPU:0
2023-12-24 16:15:57.827037: I tensorflow/core/common_runtime/placer.cc:124] Weight/read(Identity) placed on: /job:localhost/replica:0/task:0/device:GPU:0
Bias/read: (Identity): /job:localhost/replica:0/task:0/device:GPU:0
2023-12-24 16:15:57.827064: I tensorflow/core/common_runtime/placer.cc:114] Bias/read: (Identity): /job:localhost/replica:0/task:0/device:GPU:0
2023-12-24 16:15:57.827072: I tensorflow/core/common_runtime/placer.cc:124] Bias/read(Identity) placed on: /job:localhost/replica:0/task:0/device:GPU:0
MatMul: (MatMul): /job:localhost/replica:0/task:0/device:GPU:0
2023-12-24 16:15:57.827095: I tensorflow/core/common_runtime/placer.cc:114] MatMul: (MatMul): /job:localhost/replica:0/task:0/device:GPU:0
2023-12-24 16:15:57.827102: I tensorflow/core/common_runtime/placer.cc:124] MatMul(MatMul) placed on: /job:localhost/replica:0/task:0/device:GPU:0
Add: (Add): /job:localhost/replica:0/task:0/device:GPU:0
2023-12-24 16:15:57.827123: I tensorflow/core/common_runtime/placer.cc:114] Add: (Add): /job:localhost/replica:0/task:0/device:GPU:0
2023-12-24 16:15:57.827131: I tensorflow/core/common_runtime/placer.cc:124] Add(Add) placed on: /job:localhost/replica:0/task:0/device:GPU:0
Sigmoid: (Sigmoid): /job:localhost/replica:0/task:0/device:GPU:0
2023-12-24 16:15:57.827152: I tensorflow/core/common_runtime/placer.cc:114] Sigmoid: (Sigmoid): /job:localhost/replica:0/task:0/device:GPU:0
2023-12-24 16:15:57.827159: I tensorflow/core/common_runtime/placer.cc:124] Sigmoid(Sigmoid) placed on: /job:localhost/replica:0/task:0/device:GPU:0
X: (Placeholder): /job:localhost/replica:0/task:0/device:GPU:0
2023-12-24 16:15:57.827191: I tensorflow/core/common_runtime/placer.cc:114] X: (Placeholder): /job:localhost/replica:0/task:0/device:GPU:0
2023-12-24 16:15:57.827206: I tensorflow/core/common_runtime/placer.cc:124] X(Placeholder) placed on: /job:localhost/replica:0/task:0/device:GPU:0
Weight: (Const): /job:localhost/replica:0/task:0/device:GPU:0
2023-12-24 16:15:57.827228: I tensorflow/core/common_runtime/placer.cc:114] Weight: (Const): /job:localhost/replica:0/task:0/device:GPU:0
2023-12-24 16:15:57.827236: I tensorflow/core/common_runtime/placer.cc:124] Weight(Const) placed on: /job:localhost/replica:0/task:0/device:GPU:0
Bias: (Const): /job:localhost/replica:0/task:0/device:GPU:0
2023-12-24 16:15:57.827255: I tensorflow/core/common_runtime/placer.cc:114] Bias: (Const): /job:localhost/replica:0/task:0/device:GPU:0
2023-12-24 16:15:57.827262: I tensorflow/core/common_runtime/placer.cc:124] Bias(Const) placed on: /job:localhost/replica:0/task:0/device:GPU:0
2023-12-24 16:15:57.827365: W tensorflow/core/util/dump_graph.cc:134] Failed to dump placer_output because dump location is not  specified through either TF_DUMP_GRAPH_PREFIX environment variable or function argument.
2023-12-24 16:15:57.827414: E tensorflow/core/common_runtime/placer.cc:93] Failed to write final colocation graph to file  with INTERNAL: Failed to get the directory for colocation_graph because dump location is not specified through TF_DUMP_GRAPH_PREFIX environment variable
2023-12-24 16:15:57.827442: I tensorflow/core/common_runtime/optimization_registry.cc:54] Starting optimization of a group 1
2023-12-24 16:15:57.827524: W tensorflow/core/util/dump_graph.cc:134] Failed to dump before_grouping_1_94069088588736 because dump location is not  specified through either TF_DUMP_GRAPH_PREFIX environment variable or function argument.
2023-12-24 16:15:57.827564: I tensorflow/core/common_runtime/optimization_registry.cc:66] Running optimization phase 0
2023-12-24 16:15:57.827572: I tensorflow/core/common_runtime/optimization_registry.cc:68] Running optimization pass: NcclReplacePass
2023-12-24 16:15:57.827594: I tensorflow/core/common_runtime/optimization_registry.cc:87] Finished optimization of a group 1
2023-12-24 16:15:57.827670: W tensorflow/core/util/dump_graph.cc:134] Failed to dump after_grouping_1_94069088588736 because dump location is not  specified through either TF_DUMP_GRAPH_PREFIX environment variable or function argument.
2023-12-24 16:15:57.827706: I tensorflow/core/common_runtime/graph_execution_state.cc:636] Mapping _SOURCE to 0
2023-12-24 16:15:57.827725: I tensorflow/core/common_runtime/graph_execution_state.cc:636] Mapping _SINK to 1
2023-12-24 16:15:57.827733: I tensorflow/core/common_runtime/graph_execution_state.cc:636] Mapping X to 2
2023-12-24 16:15:57.827740: I tensorflow/core/common_runtime/graph_execution_state.cc:636] Mapping Weight to 3
2023-12-24 16:15:57.827748: I tensorflow/core/common_runtime/graph_execution_state.cc:636] Mapping Weight/read to 4
2023-12-24 16:15:57.827756: I tensorflow/core/common_runtime/graph_execution_state.cc:636] Mapping Bias to 5
2023-12-24 16:15:57.827764: I tensorflow/core/common_runtime/graph_execution_state.cc:636] Mapping Bias/read to 6
2023-12-24 16:15:57.827772: I tensorflow/core/common_runtime/graph_execution_state.cc:636] Mapping MatMul to 7
2023-12-24 16:15:57.827780: I tensorflow/core/common_runtime/graph_execution_state.cc:636] Mapping Add to 8
2023-12-24 16:15:57.827787: I tensorflow/core/common_runtime/graph_execution_state.cc:636] Mapping Sigmoid to 9
Successfully created session! model=test_model_v1




========================================================================================================================
3. Run the Session object with input tensors
========================================================================================================================
Input X:0 with shape{3, 5}
2023-12-24 16:15:57.828071: I tensorflow/core/framework/log_memory.cc:34] __LOG_MEMORY__ MemoryLogTensorAllocation { step_id: -6 kernel_name: "Unknown" tensor { dtype: DT_FLOAT shape { dim { size: 3 } dim { size: 5 } } allocation_description { requested_bytes: 60 allocated_bytes: 60 allocator_name: "mklcpu" allocation_id: 1 has_single_reference: true ptr: 94068540294144 } } }
>> 0.449184 0.681361 0.602557 0.332434 0.558131 
>> 0.939686 0.847847 0.404412 0.809223 0.0243093 
>> 0.227321 0.798963 0.309606 0.770183 0.0647006 

Fetch name: Sigmoid:0

>> Start Session Run
2023-12-24 16:15:57.828279: I tensorflow/core/common_runtime/graph_execution_state.cc:854] BuildGraph
2023-12-24 16:15:57.828302: I tensorflow/core/common_runtime/graph_execution_state.cc:871] Grappler optimization failed. Error: Meta Optimizer disabled
2023-12-24 16:15:57.828351: I tensorflow/core/graph/graph.cc:616] AddNode: no type constructor for _SOURCE
2023-12-24 16:15:57.828397: I tensorflow/core/graph/graph.cc:616] AddNode: no type constructor for _SINK
2023-12-24 16:15:57.828663: I tensorflow/core/graph/graph.cc:616] AddNode: no type constructor for _arg_X_0_0
2023-12-24 16:15:57.828752: I tensorflow/core/graph/subgraph.cc:141] Found fetch node for Sigmoid:0
2023-12-24 16:15:57.828850: I tensorflow/core/graph/graph.cc:616] AddNode: no type constructor for _retval_Sigmoid_0_0
2023-12-24 16:15:57.828943: I tensorflow/core/graph/algorithm.cc:235] Reverse reach : _retval_Sigmoid_0_0 from Sigmoid
2023-12-24 16:15:57.828956: I tensorflow/core/graph/algorithm.cc:235] Reverse reach : Sigmoid from Add
2023-12-24 16:15:57.828964: I tensorflow/core/graph/algorithm.cc:235] Reverse reach : Add from MatMul
2023-12-24 16:15:57.828970: I tensorflow/core/graph/algorithm.cc:235] Reverse reach : Add from Bias/read
2023-12-24 16:15:57.828978: I tensorflow/core/graph/algorithm.cc:235] Reverse reach : MatMul from _arg_X_0_0
2023-12-24 16:15:57.828984: I tensorflow/core/graph/algorithm.cc:235] Reverse reach : MatMul from Weight/read
2023-12-24 16:15:57.828991: I tensorflow/core/graph/algorithm.cc:235] Reverse reach : Bias/read from Bias
2023-12-24 16:15:57.828998: I tensorflow/core/graph/algorithm.cc:235] Reverse reach : _arg_X_0_0 from _SOURCE
2023-12-24 16:15:57.829005: I tensorflow/core/graph/algorithm.cc:235] Reverse reach : Weight/read from Weight
2023-12-24 16:15:57.829059: I tensorflow/core/common_runtime/optimization_registry.cc:54] Starting optimization of a group 2
2023-12-24 16:15:57.829175: W tensorflow/core/util/dump_graph.cc:134] Failed to dump before_grouping_2_94068946570032 because dump location is not  specified through either TF_DUMP_GRAPH_PREFIX environment variable or function argument.
2023-12-24 16:15:57.829232: I tensorflow/core/common_runtime/optimization_registry.cc:66] Running optimization phase 5
2023-12-24 16:15:57.829241: I tensorflow/core/common_runtime/optimization_registry.cc:68] Running optimization pass: CloneConstantsForBetterClusteringPass
2023-12-24 16:15:57.829260: I tensorflow/core/common_runtime/optimization_registry.cc:66] Running optimization phase 9
2023-12-24 16:15:57.829267: I tensorflow/core/common_runtime/optimization_registry.cc:68] Running optimization pass: ClusterScopingPass
2023-12-24 16:15:57.829279: I tensorflow/core/common_runtime/optimization_registry.cc:66] Running optimization phase 10
2023-12-24 16:15:57.829285: I tensorflow/core/common_runtime/optimization_registry.cc:68] Running optimization pass: MarkForCompilationPass
2023-12-24 16:15:57.829378: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: XlaWhile
2023-12-24 16:15:57.829460: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: XlaWhile
2023-12-24 16:15:57.829515: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: XlaIf
2023-12-24 16:15:57.829564: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: XlaIf
2023-12-24 16:15:57.829616: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: StatelessIf
2023-12-24 16:15:57.829661: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: StatelessIf
2023-12-24 16:15:57.829711: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: If
2023-12-24 16:15:57.829752: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: If
2023-12-24 16:15:57.829796: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: StatelessCase
2023-12-24 16:15:57.829836: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: StatelessCase
2023-12-24 16:15:57.829886: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: Svd
2023-12-24 16:15:57.829919: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Svd
2023-12-24 16:15:57.829959: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: XlaSvd
2023-12-24 16:15:57.829993: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: XlaSvd
2023-12-24 16:15:57.830028: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: SelfAdjointEigV2
2023-12-24 16:15:57.830057: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: SelfAdjointEigV2
2023-12-24 16:15:57.830091: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: XlaVariadicReduceV2
2023-12-24 16:15:57.830129: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: XlaVariadicReduceV2
2023-12-24 16:15:57.830172: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: XlaVariadicReduce
2023-12-24 16:15:57.830210: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: XlaVariadicReduce
2023-12-24 16:15:57.830246: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: XlaOptimizationBarrier
2023-12-24 16:15:57.830275: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: XlaOptimizationBarrier
2023-12-24 16:15:57.830315: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: XlaCustomCall
2023-12-24 16:15:57.830351: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: XlaCustomCall
2023-12-24 16:15:57.830403: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: XlaConvV2
2023-12-24 16:15:57.830456: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: XlaConvV2
2023-12-24 16:15:57.830505: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: XlaBroadcastHelper
2023-12-24 16:15:57.830541: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: XlaBroadcastHelper
2023-12-24 16:15:57.830580: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: Where
2023-12-24 16:15:57.830609: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Where
2023-12-24 16:15:57.830646: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: ResourceScatterNdSub
2023-12-24 16:15:57.830682: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: ResourceScatterNdSub
2023-12-24 16:15:57.830722: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: ResourceScatterNdAdd
2023-12-24 16:15:57.830772: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: ResourceScatterNdAdd
2023-12-24 16:15:57.830818: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: ResourceScatterNdUpdate
2023-12-24 16:15:57.830854: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: ResourceScatterNdUpdate
2023-12-24 16:15:57.830894: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: ResourceScatterMax
2023-12-24 16:15:57.830934: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: ResourceScatterMax
2023-12-24 16:15:57.830974: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: ResourceScatterMin
2023-12-24 16:15:57.831008: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: ResourceScatterMin
2023-12-24 16:15:57.831051: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: ResourceScatterDiv
2023-12-24 16:15:57.831087: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: ResourceScatterDiv
2023-12-24 16:15:57.831127: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: ResourceScatterMul
2023-12-24 16:15:57.831162: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: ResourceScatterMul
2023-12-24 16:15:57.831214: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: AssignSubVariableOp
2023-12-24 16:15:57.831250: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: AssignSubVariableOp
2023-12-24 16:15:57.831284: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: AssignVariableOp
2023-12-24 16:15:57.831313: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: AssignVariableOp
2023-12-24 16:15:57.831345: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: ReadVariableOp
2023-12-24 16:15:57.831373: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: ReadVariableOp
2023-12-24 16:15:57.831406: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: Unpack
2023-12-24 16:15:57.831434: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Unpack
2023-12-24 16:15:57.831474: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: UniqueV2
2023-12-24 16:15:57.831517: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: UniqueV2
2023-12-24 16:15:57.831559: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: Unique
2023-12-24 16:15:57.831593: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Unique
2023-12-24 16:15:57.831630: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: _UnaryOpsComposition
2023-12-24 16:15:57.831659: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: _UnaryOpsComposition
2023-12-24 16:15:57.831694: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: BesselI1e
2023-12-24 16:15:57.831722: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: BesselI1e
2023-12-24 16:15:57.831756: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: BesselI0e
2023-12-24 16:15:57.831785: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: BesselI0e
2023-12-24 16:15:57.831817: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: Digamma
2023-12-24 16:15:57.831846: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Digamma
2023-12-24 16:15:57.831878: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: Erfc
2023-12-24 16:15:57.831929: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Erfc
2023-12-24 16:15:57.831969: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: Erf
2023-12-24 16:15:57.831999: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Erf
2023-12-24 16:15:57.832035: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: Real
2023-12-24 16:15:57.832070: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Real
2023-12-24 16:15:57.832107: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: Tan
2023-12-24 16:15:57.832136: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Tan
2023-12-24 16:15:57.832168: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: Sqrt
2023-12-24 16:15:57.832207: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Sqrt
2023-12-24 16:15:57.832243: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: Softsign
2023-12-24 16:15:57.832271: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Softsign
2023-12-24 16:15:57.832304: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: Softplus
2023-12-24 16:15:57.832332: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Softplus
2023-12-24 16:15:57.832365: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: Tanh
2023-12-24 16:15:57.832394: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Tanh
2023-12-24 16:15:57.832427: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: Sigmoid
2023-12-24 16:15:57.832455: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Sigmoid
2023-12-24 16:15:57.832487: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: Rsqrt
2023-12-24 16:15:57.832516: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Rsqrt
2023-12-24 16:15:57.832548: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: Round
2023-12-24 16:15:57.832577: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Round
2023-12-24 16:15:57.832611: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: Neg
2023-12-24 16:15:57.832639: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Neg
2023-12-24 16:15:57.832683: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: XlaDotV2
2023-12-24 16:15:57.832726: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: XlaDotV2
2023-12-24 16:15:57.832761: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: LogicalNot
2023-12-24 16:15:57.832779: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: LogicalNot
2023-12-24 16:15:57.832806: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: Log1p
2023-12-24 16:15:57.832835: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Log1p
2023-12-24 16:15:57.832872: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: ResourceScatterAdd
2023-12-24 16:15:57.832907: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: ResourceScatterAdd
2023-12-24 16:15:57.832943: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: Log
2023-12-24 16:15:57.832972: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Log
2023-12-24 16:15:57.833005: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: Reciprocal
2023-12-24 16:15:57.833034: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Reciprocal
2023-12-24 16:15:57.833067: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: IsNan
2023-12-24 16:15:57.833095: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: IsNan
2023-12-24 16:15:57.833128: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: IsInf
2023-12-24 16:15:57.833157: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: IsInf
2023-12-24 16:15:57.833190: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: IsFinite
2023-12-24 16:15:57.833229: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: IsFinite
2023-12-24 16:15:57.833263: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: Floor
2023-12-24 16:15:57.833291: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Floor
2023-12-24 16:15:57.833324: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: Expm1
2023-12-24 16:15:57.833358: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Expm1
2023-12-24 16:15:57.833391: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: PopulationCount
2023-12-24 16:15:57.833420: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: PopulationCount
2023-12-24 16:15:57.833454: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: Sin
2023-12-24 16:15:57.833481: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Sin
2023-12-24 16:15:57.833514: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: Cosh
2023-12-24 16:15:57.833543: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Cosh
2023-12-24 16:15:57.833576: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: Cos
2023-12-24 16:15:57.833605: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Cos
2023-12-24 16:15:57.833639: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: Ceil
2023-12-24 16:15:57.833667: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Ceil
2023-12-24 16:15:57.833700: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: Atanh
2023-12-24 16:15:57.833729: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Atanh
2023-12-24 16:15:57.833761: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: Abs
2023-12-24 16:15:57.833790: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Abs
2023-12-24 16:15:57.833822: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: Sinh
2023-12-24 16:15:57.833851: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Sinh
2023-12-24 16:15:57.833887: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: ComplexAbs
2023-12-24 16:15:57.833920: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: ComplexAbs
2023-12-24 16:15:57.833960: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: TridiagonalSolve
2023-12-24 16:15:57.834031: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: TridiagonalSolve
2023-12-24 16:15:57.834080: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: InvertPermutation
2023-12-24 16:15:57.834113: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: InvertPermutation
2023-12-24 16:15:57.834152: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: ResourceApplyPowerSign
2023-12-24 16:15:57.834184: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: ResourceApplyPowerSign
2023-12-24 16:15:57.834229: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: Rint
2023-12-24 16:15:57.834260: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Rint
2023-12-24 16:15:57.834298: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: ResourceApplyAddSign
2023-12-24 16:15:57.834330: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: ResourceApplyAddSign
2023-12-24 16:15:57.834369: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: ResourceApplyAdadelta
2023-12-24 16:15:57.834402: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: ResourceApplyAdadelta
2023-12-24 16:15:57.834440: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: ResourceApplyFtrl
2023-12-24 16:15:57.834475: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: ResourceApplyFtrl
2023-12-24 16:15:57.834515: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: ResourceApplyCenteredRMSProp
2023-12-24 16:15:57.834548: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: ResourceApplyCenteredRMSProp
2023-12-24 16:15:57.834582: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: Sign
2023-12-24 16:15:57.834611: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Sign
2023-12-24 16:15:57.834648: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: ResourceApplyAdaMax
2023-12-24 16:15:57.834681: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: ResourceApplyAdaMax
2023-12-24 16:15:57.834719: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: ResourceApplyAdam
2023-12-24 16:15:57.834752: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: ResourceApplyAdam
2023-12-24 16:15:57.834791: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: ResourceApplyProximalAdagrad
2023-12-24 16:15:57.834825: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: ResourceApplyProximalAdagrad
2023-12-24 16:15:57.834863: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: ResourceApplyAdagradV2
2023-12-24 16:15:57.834896: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: ResourceApplyAdagradV2
2023-12-24 16:15:57.834933: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: ResourceApplyMomentum
2023-12-24 16:15:57.834966: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: ResourceApplyMomentum
2023-12-24 16:15:57.835004: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: ResourceApplyGradientDescent
2023-12-24 16:15:57.835036: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: ResourceApplyGradientDescent
2023-12-24 16:15:57.835070: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: Lgamma
2023-12-24 16:15:57.835098: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Lgamma
2023-12-24 16:15:57.835131: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: TensorListPushBack
2023-12-24 16:15:57.835159: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: TensorListPushBack
2023-12-24 16:15:57.835192: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: TensorListSetItem
2023-12-24 16:15:57.835229: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: TensorListSetItem
2023-12-24 16:15:57.835266: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: TensorListFromTensor
2023-12-24 16:15:57.835301: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: TensorListFromTensor
2023-12-24 16:15:57.835340: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: TensorListSplit
2023-12-24 16:15:57.835374: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: TensorListSplit
2023-12-24 16:15:57.835410: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: ResizeBilinearGrad
2023-12-24 16:15:57.835439: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: ResizeBilinearGrad
2023-12-24 16:15:57.835473: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: Atan2
2023-12-24 16:15:57.835501: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Atan2
2023-12-24 16:15:57.835536: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: BitwiseOr
2023-12-24 16:15:57.835565: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: BitwiseOr
2023-12-24 16:15:57.835601: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: NonMaxSuppressionV3
2023-12-24 16:15:57.835635: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: NonMaxSuppressionV3
2023-12-24 16:15:57.835673: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: FusedBatchNormV2
2023-12-24 16:15:57.835706: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: FusedBatchNormV2
2023-12-24 16:15:57.835742: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: AdjustSaturation
2023-12-24 16:15:57.835770: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: AdjustSaturation
2023-12-24 16:15:57.835803: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: PlaceholderWithDefault
2023-12-24 16:15:57.835831: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: PlaceholderWithDefault
2023-12-24 16:15:57.835867: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: StatefulPartitionedCall
2023-12-24 16:15:57.835901: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: StatefulPartitionedCall
2023-12-24 16:15:57.835939: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: _ArrayToList
2023-12-24 16:15:57.835972: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: _ArrayToList
2023-12-24 16:15:57.836002: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: LogicalOr
2023-12-24 16:15:57.836021: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: LogicalOr
2023-12-24 16:15:57.836050: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: OneHot
2023-12-24 16:15:57.836084: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: OneHot
2023-12-24 16:15:57.836126: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: IRFFT3D
2023-12-24 16:15:57.836162: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: IRFFT3D
2023-12-24 16:15:57.836194: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: CollectiveAssignGroupV2
2023-12-24 16:15:57.836222: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: CollectiveAssignGroupV2
2023-12-24 16:15:57.836256: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: IRFFT
2023-12-24 16:15:57.836292: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: IRFFT
2023-12-24 16:15:57.836333: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: RFFT3D
2023-12-24 16:15:57.836372: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: RFFT3D
2023-12-24 16:15:57.836413: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: RFFT2D
2023-12-24 16:15:57.836449: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: RFFT2D
2023-12-24 16:15:57.836487: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: IFFT3D
2023-12-24 16:15:57.836517: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: IFFT3D
2023-12-24 16:15:57.836551: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: ReluGrad
2023-12-24 16:15:57.836580: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: ReluGrad
2023-12-24 16:15:57.836613: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: FusedBatchNorm
2023-12-24 16:15:57.836644: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: FusedBatchNorm
2023-12-24 16:15:57.836677: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: NextAfter
2023-12-24 16:15:57.836706: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: NextAfter
2023-12-24 16:15:57.836736: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: FakeQuantWithMinMaxVarsPerChannelGradient
2023-12-24 16:15:57.836754: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: FakeQuantWithMinMaxVarsPerChannelGradient
2023-12-24 16:15:57.836775: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: FakeQuantWithMinMaxVarsGradient
2023-12-24 16:15:57.836792: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: FakeQuantWithMinMaxVarsGradient
2023-12-24 16:15:57.836813: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: FakeQuantWithMinMaxVars
2023-12-24 16:15:57.836830: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: FakeQuantWithMinMaxVars
2023-12-24 16:15:57.836856: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: _EagerConst
2023-12-24 16:15:57.836885: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: _EagerConst
2023-12-24 16:15:57.836918: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: FakeParam
2023-12-24 16:15:57.836945: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: FakeParam
2023-12-24 16:15:57.836978: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: Selu
2023-12-24 16:15:57.837007: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Selu
2023-12-24 16:15:57.837043: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: Case
2023-12-24 16:15:57.837076: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Case
2023-12-24 16:15:57.837120: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: UnsortedSegmentMin
2023-12-24 16:15:57.837160: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: UnsortedSegmentMin
2023-12-24 16:15:57.837212: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: XlaEinsum
2023-12-24 16:15:57.837249: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: XlaEinsum
2023-12-24 16:15:57.837286: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: FFT3D
2023-12-24 16:15:57.837316: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: FFT3D
2023-12-24 16:15:57.837354: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: XlaGather
2023-12-24 16:15:57.837389: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: XlaGather
2023-12-24 16:15:57.837426: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: ParallelDynamicStitch
2023-12-24 16:15:57.837453: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: ParallelDynamicStitch
2023-12-24 16:15:57.837489: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: XlaDynamicSlice
2023-12-24 16:15:57.837523: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: XlaDynamicSlice
2023-12-24 16:15:57.837564: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: Conv2D
2023-12-24 16:15:57.837595: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Conv2D
2023-12-24 16:15:57.837637: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: ArgMin
2023-12-24 16:15:57.837679: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: ArgMin
2023-12-24 16:15:57.837723: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: ExtractImagePatches
2023-12-24 16:15:57.837755: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: ExtractImagePatches
2023-12-24 16:15:57.837793: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: ConjugateTranspose
2023-12-24 16:15:57.837828: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: ConjugateTranspose
2023-12-24 16:15:57.837870: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: TruncatedNormal
2023-12-24 16:15:57.837907: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: TruncatedNormal
2023-12-24 16:15:57.837944: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: Exp
2023-12-24 16:15:57.837973: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Exp
2023-12-24 16:15:57.838006: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: PreventGradient
2023-12-24 16:15:57.838033: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: PreventGradient
2023-12-24 16:15:57.838067: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: Elu
2023-12-24 16:15:57.838097: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Elu
2023-12-24 16:15:57.838137: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: RFFT
2023-12-24 16:15:57.838175: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: RFFT
2023-12-24 16:15:57.838233: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: StatelessMultinomial
2023-12-24 16:15:57.838281: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: StatelessMultinomial
2023-12-24 16:15:57.838330: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: GatherV2
2023-12-24 16:15:57.838372: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: GatherV2
2023-12-24 16:15:57.838418: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: Einsum
2023-12-24 16:15:57.838528: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Einsum
2023-12-24 16:15:57.838583: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: DeviceIndex
2023-12-24 16:15:57.838603: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: DeviceIndex
2023-12-24 16:15:57.838636: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: RandomUniform
2023-12-24 16:15:57.838672: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: RandomUniform
2023-12-24 16:15:57.838709: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: StatelessWhile
2023-12-24 16:15:57.838737: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: StatelessWhile
2023-12-24 16:15:57.838773: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: DataFormatDimMap
2023-12-24 16:15:57.838803: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: DataFormatDimMap
2023-12-24 16:15:57.838847: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: Cumsum
2023-12-24 16:15:57.838888: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Cumsum
2023-12-24 16:15:57.838929: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: FusedBatchNormGradV3
2023-12-24 16:15:57.838964: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: FusedBatchNormGradV3
2023-12-24 16:15:57.839003: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: MaxPoolGradGradV2
2023-12-24 16:15:57.839034: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: MaxPoolGradGradV2
2023-12-24 16:15:57.839074: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: XlaConv
2023-12-24 16:15:57.839109: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: XlaConv
2023-12-24 16:15:57.839149: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: Conv2DBackpropFilter
2023-12-24 16:15:57.839179: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Conv2DBackpropFilter
2023-12-24 16:15:57.839222: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: MaxPoolGradV2
2023-12-24 16:15:57.839254: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: MaxPoolGradV2
2023-12-24 16:15:57.839300: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: Conv3DBackpropInputV2
2023-12-24 16:15:57.839337: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Conv3DBackpropInputV2
2023-12-24 16:15:57.839378: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: DepthwiseConv2dNative
2023-12-24 16:15:57.839408: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: DepthwiseConv2dNative
2023-12-24 16:15:57.839449: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: ResourceApplyProximalGradientDescent
2023-12-24 16:15:57.839483: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: ResourceApplyProximalGradientDescent
2023-12-24 16:15:57.839519: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: ResizeNearestNeighbor
2023-12-24 16:15:57.839548: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: ResizeNearestNeighbor
2023-12-24 16:15:57.839584: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: Conv3D
2023-12-24 16:15:57.839613: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Conv3D
2023-12-24 16:15:57.839646: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: Equal
2023-12-24 16:15:57.839674: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Equal
2023-12-24 16:15:57.839711: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: Max
2023-12-24 16:15:57.839747: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Max
2023-12-24 16:15:57.839785: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: Div
2023-12-24 16:15:57.839813: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Div
2023-12-24 16:15:57.839841: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: ConcatOffset
2023-12-24 16:15:57.839859: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: ConcatOffset
2023-12-24 16:15:57.839889: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: Slice
2023-12-24 16:15:57.839923: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Slice
2023-12-24 16:15:57.839959: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: TensorArrayScatterV3
2023-12-24 16:15:57.839987: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: TensorArrayScatterV3
2023-12-24 16:15:57.840019: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: BroadcastArgs
2023-12-24 16:15:57.840047: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: BroadcastArgs
2023-12-24 16:15:57.840082: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: ClipByValue
2023-12-24 16:15:57.840110: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: ClipByValue
2023-12-24 16:15:57.840145: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: ResizeBilinear
2023-12-24 16:15:57.840174: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: ResizeBilinear
2023-12-24 16:15:57.840217: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: Reshape
2023-12-24 16:15:57.840253: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Reshape
2023-12-24 16:15:57.840296: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: StatefulStandardNormalV2
2023-12-24 16:15:57.840333: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: StatefulStandardNormalV2
2023-12-24 16:15:57.840376: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: Dequantize
2023-12-24 16:15:57.840411: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Dequantize
2023-12-24 16:15:57.840447: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: BroadcastGradientArgs
2023-12-24 16:15:57.840475: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: BroadcastGradientArgs
2023-12-24 16:15:57.840508: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: Xlog1py
2023-12-24 16:15:57.840536: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Xlog1py
2023-12-24 16:15:57.840573: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: SparseSoftmaxCrossEntropyWithLogits
2023-12-24 16:15:57.840609: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: SparseSoftmaxCrossEntropyWithLogits
2023-12-24 16:15:57.840647: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: Transpose
2023-12-24 16:15:57.840680: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Transpose
2023-12-24 16:15:57.840716: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: TanhGrad
2023-12-24 16:15:57.840744: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: TanhGrad
2023-12-24 16:15:57.840774: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: FakeQuantWithMinMaxArgs
2023-12-24 16:15:57.840792: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: FakeQuantWithMinMaxArgs
2023-12-24 16:15:57.840819: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: DivNoNan
2023-12-24 16:15:57.840847: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: DivNoNan
2023-12-24 16:15:57.840881: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: Xlogy
2023-12-24 16:15:57.840909: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Xlogy
2023-12-24 16:15:57.840940: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: Identity
2023-12-24 16:15:57.840967: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Identity
2023-12-24 16:15:57.840999: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: Split
2023-12-24 16:15:57.841026: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Split
2023-12-24 16:15:57.841055: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: TensorListLength
2023-12-24 16:15:57.841074: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: TensorListLength
2023-12-24 16:15:57.841102: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: IFFT2D
2023-12-24 16:15:57.841131: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: IFFT2D
2023-12-24 16:15:57.841170: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: ResourceScatterSub
2023-12-24 16:15:57.841210: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: ResourceScatterSub
2023-12-24 16:15:57.841248: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: RsqrtGrad
2023-12-24 16:15:57.841276: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: RsqrtGrad
2023-12-24 16:15:57.841314: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: XlaSelfAdjointEig
2023-12-24 16:15:57.841344: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: XlaSelfAdjointEig
2023-12-24 16:15:57.841376: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: AdjustHue
2023-12-24 16:15:57.841408: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: AdjustHue
2023-12-24 16:15:57.841444: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: GatherNd
2023-12-24 16:15:57.841478: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: GatherNd
2023-12-24 16:15:57.841516: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: BatchToSpace
2023-12-24 16:15:57.841549: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: BatchToSpace
2023-12-24 16:15:57.841586: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: SqrtGrad
2023-12-24 16:15:57.841614: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: SqrtGrad
2023-12-24 16:15:57.841650: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: RandomUniformInt
2023-12-24 16:15:57.841685: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: RandomUniformInt
2023-12-24 16:15:57.841726: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: IRFFT2D
2023-12-24 16:15:57.841762: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: IRFFT2D
2023-12-24 16:15:57.841803: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: Bitcast
2023-12-24 16:15:57.841840: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Bitcast
2023-12-24 16:15:57.841882: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: SpaceToBatchND
2023-12-24 16:15:57.841920: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: SpaceToBatchND
2023-12-24 16:15:57.841960: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: AvgPool
2023-12-24 16:15:57.841988: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: AvgPool
2023-12-24 16:15:57.842023: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: Gather
2023-12-24 16:15:57.842057: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Gather
2023-12-24 16:15:57.842095: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: CollectiveReduceV2
2023-12-24 16:15:57.842125: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: CollectiveReduceV2
2023-12-24 16:15:57.842162: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: Pad
2023-12-24 16:15:57.842203: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Pad
2023-12-24 16:15:57.842245: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: FusedBatchNormV3
2023-12-24 16:15:57.842279: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: FusedBatchNormV3
2023-12-24 16:15:57.842314: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: SpaceToDepth
2023-12-24 16:15:57.842343: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: SpaceToDepth
2023-12-24 16:15:57.842376: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: IdentityN
2023-12-24 16:15:57.842403: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: IdentityN
2023-12-24 16:15:57.842438: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: BatchMatMulV2
2023-12-24 16:15:57.842466: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: BatchMatMulV2
2023-12-24 16:15:57.842499: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: FusedBatchNormGrad
2023-12-24 16:15:57.842528: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: FusedBatchNormGrad
2023-12-24 16:15:57.842560: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: SoftsignGrad
2023-12-24 16:15:57.842587: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: SoftsignGrad
2023-12-24 16:15:57.842620: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: TensorListPopBack
2023-12-24 16:15:57.842647: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: TensorListPopBack
2023-12-24 16:15:57.842682: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: Xdivy
2023-12-24 16:15:57.842710: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Xdivy
2023-12-24 16:15:57.842743: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: BitwiseXor
2023-12-24 16:15:57.842771: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: BitwiseXor
2023-12-24 16:15:57.842803: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: TruncateMod
2023-12-24 16:15:57.842832: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: TruncateMod
2023-12-24 16:15:57.842872: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: UnsortedSegmentMax
2023-12-24 16:15:57.842912: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: UnsortedSegmentMax
2023-12-24 16:15:57.842951: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: While
2023-12-24 16:15:57.842978: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: While
2023-12-24 16:15:57.843011: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: SoftmaxCrossEntropyWithLogits
2023-12-24 16:15:57.843041: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: SoftmaxCrossEntropyWithLogits
2023-12-24 16:15:57.843080: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: ResourceApplyFtrlV2
2023-12-24 16:15:57.843112: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: ResourceApplyFtrlV2
2023-12-24 16:15:57.843146: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: BiasAddGrad
2023-12-24 16:15:57.843175: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: BiasAddGrad
2023-12-24 16:15:57.843220: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: ResourceApplyAdagrad
2023-12-24 16:15:57.843254: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: ResourceApplyAdagrad
2023-12-24 16:15:57.843288: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: TensorListStack
2023-12-24 16:15:57.843316: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: TensorListStack
2023-12-24 16:15:57.843350: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: BatchMatMul
2023-12-24 16:15:57.843378: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: BatchMatMul
2023-12-24 16:15:57.843415: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: TopKV2
2023-12-24 16:15:57.843448: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: TopKV2
2023-12-24 16:15:57.843483: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: Conv3DBackpropFilterV2
2023-12-24 16:15:57.843513: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Conv3DBackpropFilterV2
2023-12-24 16:15:57.843547: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: Empty
2023-12-24 16:15:57.843575: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Empty
2023-12-24 16:15:57.843608: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: AddV2
2023-12-24 16:15:57.843637: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: AddV2
2023-12-24 16:15:57.843669: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: Atan
2023-12-24 16:15:57.843697: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Atan
2023-12-24 16:15:57.843732: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: QuantizeAndDequantizeV2
2023-12-24 16:15:57.843760: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: QuantizeAndDequantizeV2
2023-12-24 16:15:57.843792: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: AdjustContrastv2
2023-12-24 16:15:57.843820: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: AdjustContrastv2
2023-12-24 16:15:57.843851: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: EluGrad
2023-12-24 16:15:57.843879: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: EluGrad
2023-12-24 16:15:57.843911: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: CheckNumerics
2023-12-24 16:15:57.843939: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: CheckNumerics
2023-12-24 16:15:57.843974: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: NonMaxSuppressionV4
2023-12-24 16:15:57.844008: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: NonMaxSuppressionV4
2023-12-24 16:15:57.844047: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: ConcatV2
2023-12-24 16:15:57.844082: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: ConcatV2
2023-12-24 16:15:57.844118: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: Erfinv
2023-12-24 16:15:57.844146: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Erfinv
2023-12-24 16:15:57.844185: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: Sum
2023-12-24 16:15:57.844232: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Sum
2023-12-24 16:15:57.844272: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: Assert
2023-12-24 16:15:57.844300: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Assert
2023-12-24 16:15:57.844338: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: ReverseV2
2023-12-24 16:15:57.844373: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: ReverseV2
2023-12-24 16:15:57.844410: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: FloorDiv
2023-12-24 16:15:57.844439: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: FloorDiv
2023-12-24 16:15:57.844473: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: AddN
2023-12-24 16:15:57.844503: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: AddN
2023-12-24 16:15:57.844538: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: Cross
2023-12-24 16:15:57.844566: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Cross
2023-12-24 16:15:57.844609: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: StatelessRandomUniformInt
2023-12-24 16:15:57.844651: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: StatelessRandomUniformInt
2023-12-24 16:15:57.844691: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: Maximum
2023-12-24 16:15:57.844720: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Maximum
2023-12-24 16:15:57.844756: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: DepthwiseConv2dNativeBackpropFilter
2023-12-24 16:15:57.844787: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: DepthwiseConv2dNativeBackpropFilter
2023-12-24 16:15:57.844820: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: IgammaGradA
2023-12-24 16:15:57.844848: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: IgammaGradA
2023-12-24 16:15:57.844882: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: Inv
2023-12-24 16:15:57.844910: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Inv
2023-12-24 16:15:57.844946: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: Size
2023-12-24 16:15:57.844979: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Size
2023-12-24 16:15:57.845015: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: TensorArrayV3
2023-12-24 16:15:57.845043: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: TensorArrayV3
2023-12-24 16:15:57.845079: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: TensorScatterMin
2023-12-24 16:15:57.845113: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: TensorScatterMin
2023-12-24 16:15:57.845149: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: MulNoNan
2023-12-24 16:15:57.845177: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: MulNoNan
2023-12-24 16:15:57.845224: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: FusedBatchNormGradV2
2023-12-24 16:15:57.845261: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: FusedBatchNormGradV2
2023-12-24 16:15:57.845298: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: MatrixDiagV3
2023-12-24 16:15:57.845325: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: MatrixDiagV3
2023-12-24 16:15:57.845361: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: Cholesky
2023-12-24 16:15:57.845392: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Cholesky
2023-12-24 16:15:57.845425: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: Asin
2023-12-24 16:15:57.845454: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Asin
2023-12-24 16:15:57.845488: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: BiasAdd
2023-12-24 16:15:57.845516: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: BiasAdd
2023-12-24 16:15:57.845552: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: DepthwiseConv2dNativeBackpropInput
2023-12-24 16:15:57.845583: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: DepthwiseConv2dNativeBackpropInput
2023-12-24 16:15:57.845615: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: TensorArrayGatherV3
2023-12-24 16:15:57.845643: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: TensorArrayGatherV3
2023-12-24 16:15:57.845671: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: LogicalAnd
2023-12-24 16:15:57.845689: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: LogicalAnd
2023-12-24 16:15:57.845723: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: ParameterizedTruncatedNormal
2023-12-24 16:15:57.845761: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: ParameterizedTruncatedNormal
2023-12-24 16:15:57.845797: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: ReciprocalGrad
2023-12-24 16:15:57.845826: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: ReciprocalGrad
2023-12-24 16:15:57.845860: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: IFFT
2023-12-24 16:15:57.845889: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: IFFT
2023-12-24 16:15:57.845924: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: XlaDot
2023-12-24 16:15:57.845952: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: XlaDot
2023-12-24 16:15:57.845988: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: PadV2
2023-12-24 16:15:57.846021: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: PadV2
2023-12-24 16:15:57.846057: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: BitwiseAnd
2023-12-24 16:15:57.846085: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: BitwiseAnd
2023-12-24 16:15:57.846118: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: XlaVariadicSort
2023-12-24 16:15:57.846145: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: XlaVariadicSort
2023-12-24 16:15:57.846178: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: Less
2023-12-24 16:15:57.846211: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Less
2023-12-24 16:15:57.846246: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: _ListToArray
2023-12-24 16:15:57.846279: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: _ListToArray
2023-12-24 16:15:57.846315: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: Bucketize
2023-12-24 16:15:57.846342: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Bucketize
2023-12-24 16:15:57.846374: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: StopGradient
2023-12-24 16:15:57.846401: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: StopGradient
2023-12-24 16:15:57.846434: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: LeftShift
2023-12-24 16:15:57.846461: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: LeftShift
2023-12-24 16:15:57.846494: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: RightShift
2023-12-24 16:15:57.846522: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: RightShift
2023-12-24 16:15:57.846549: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: RngSkip
2023-12-24 16:15:57.846567: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: RngSkip
2023-12-24 16:15:57.846596: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: TensorScatterAdd
2023-12-24 16:15:57.846629: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: TensorScatterAdd
2023-12-24 16:15:57.846665: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: Minimum
2023-12-24 16:15:57.846694: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Minimum
2023-12-24 16:15:57.846726: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: Acosh
2023-12-24 16:15:57.846754: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Acosh
2023-12-24 16:15:57.846786: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: TensorArrayWriteV3
2023-12-24 16:15:57.846814: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: TensorArrayWriteV3
2023-12-24 16:15:57.846848: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: Add
2023-12-24 16:15:57.846876: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Add
2023-12-24 16:15:57.846908: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: Concat
2023-12-24 16:15:57.846938: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Concat
2023-12-24 16:15:57.846973: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: FFT2D
2023-12-24 16:15:57.847131: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: FFT2D
2023-12-24 16:15:57.847202: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: VarIsInitializedOp
2023-12-24 16:15:57.847223: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: VarIsInitializedOp
2023-12-24 16:15:57.847255: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: Imag
2023-12-24 16:15:57.847291: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Imag
2023-12-24 16:15:57.847328: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: Acos
2023-12-24 16:15:57.847357: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Acos
2023-12-24 16:15:57.847390: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: RealDiv
2023-12-24 16:15:57.847419: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: RealDiv
2023-12-24 16:15:57.847451: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: RandomGammaGrad
2023-12-24 16:15:57.847479: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: RandomGammaGrad
2023-12-24 16:15:57.847508: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: XlaDequantize
2023-12-24 16:15:57.847526: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: XlaDequantize
2023-12-24 16:15:57.847553: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: OnesLike
2023-12-24 16:15:57.847582: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: OnesLike
2023-12-24 16:15:57.847614: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: StackPopV2
2023-12-24 16:15:57.847642: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: StackPopV2
2023-12-24 16:15:57.847675: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: TruncateDiv
2023-12-24 16:15:57.847703: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: TruncateDiv
2023-12-24 16:15:57.847737: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: NotEqual
2023-12-24 16:15:57.847764: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: NotEqual
2023-12-24 16:15:57.847796: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: TensorListGather
2023-12-24 16:15:57.847824: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: TensorListGather
2023-12-24 16:15:57.847857: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: SeluGrad
2023-12-24 16:15:57.847885: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: SeluGrad
2023-12-24 16:15:57.847917: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: DynamicPartition
2023-12-24 16:15:57.847945: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: DynamicPartition
2023-12-24 16:15:57.847982: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: XlaSelectAndScatter
2023-12-24 16:15:57.848018: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: XlaSelectAndScatter
2023-12-24 16:15:57.848049: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: XlaSetBound
2023-12-24 16:15:57.848067: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: XlaSetBound
2023-12-24 16:15:57.848096: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: SparseToDense
2023-12-24 16:15:57.848130: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: SparseToDense
2023-12-24 16:15:57.848161: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: RngReadAndSkip
2023-12-24 16:15:57.848179: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: RngReadAndSkip
2023-12-24 16:15:57.848211: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: StatelessRandomGetKeyCounterAlg
2023-12-24 16:15:57.848240: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: StatelessRandomGetKeyCounterAlg
2023-12-24 16:15:57.848276: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: ShapeN
2023-12-24 16:15:57.848310: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: ShapeN
2023-12-24 16:15:57.848350: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: EmptyTensorList
2023-12-24 16:15:57.848384: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: EmptyTensorList
2023-12-24 16:15:57.848420: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: DepthToSpace
2023-12-24 16:15:57.848448: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: DepthToSpace
2023-12-24 16:15:57.848481: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: DiagPart
2023-12-24 16:15:57.848509: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: DiagPart
2023-12-24 16:15:57.848543: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: Greater
2023-12-24 16:15:57.848572: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Greater
2023-12-24 16:15:57.848605: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: XlaRemoveDynamicDimensionSize
2023-12-24 16:15:57.848632: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: XlaRemoveDynamicDimensionSize
2023-12-24 16:15:57.848666: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: GreaterEqual
2023-12-24 16:15:57.848694: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: GreaterEqual
2023-12-24 16:15:57.848738: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: StatelessTruncatedNormal
2023-12-24 16:15:57.848781: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: StatelessTruncatedNormal
2023-12-24 16:15:57.848821: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: Igamma
2023-12-24 16:15:57.848849: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Igamma
2023-12-24 16:15:57.848883: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: LessEqual
2023-12-24 16:15:57.848912: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: LessEqual
2023-12-24 16:15:57.848948: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: PartitionedCall
2023-12-24 16:15:57.848981: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: PartitionedCall
2023-12-24 16:15:57.849022: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: StatelessRandomNormalV2
2023-12-24 16:15:57.849056: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: StatelessRandomNormalV2
2023-12-24 16:15:57.849098: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: ResourceApplyKerasMomentum
2023-12-24 16:15:57.849130: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: ResourceApplyKerasMomentum
2023-12-24 16:15:57.849164: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: SigmoidGrad
2023-12-24 16:15:57.849193: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: SigmoidGrad
2023-12-24 16:15:57.849231: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: LeakyRelu
2023-12-24 16:15:57.849260: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: LeakyRelu
2023-12-24 16:15:57.849293: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: RGBToHSV
2023-12-24 16:15:57.849321: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: RGBToHSV
2023-12-24 16:15:57.849353: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: SquaredDifference
2023-12-24 16:15:57.849382: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: SquaredDifference
2023-12-24 16:15:57.849423: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: ArgMax
2023-12-24 16:15:57.849463: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: ArgMax
2023-12-24 16:15:57.849504: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: DataFormatVecPermute
2023-12-24 16:15:57.849534: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: DataFormatVecPermute
2023-12-24 16:15:57.849567: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: DataFormatVecPermute
2023-12-24 16:15:57.849597: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: DataFormatVecPermute
2023-12-24 16:15:57.849631: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: Mul
2023-12-24 16:15:57.849663: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Mul
2023-12-24 16:15:57.849696: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: Igammac
2023-12-24 16:15:57.849724: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Igammac
2023-12-24 16:15:57.849758: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: InTopKV2
2023-12-24 16:15:57.849787: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: InTopKV2
2023-12-24 16:15:57.849823: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: BroadcastTo
2023-12-24 16:15:57.849856: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: BroadcastTo
2023-12-24 16:15:57.849892: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: Zeta
2023-12-24 16:15:57.849919: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Zeta
2023-12-24 16:15:57.849954: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: ApproximateEqual
2023-12-24 16:15:57.849984: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: ApproximateEqual
2023-12-24 16:15:57.850019: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: Shape
2023-12-24 16:15:57.850051: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Shape
2023-12-24 16:15:57.850087: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: Invert
2023-12-24 16:15:57.850115: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Invert
2023-12-24 16:15:57.850148: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: FFT
2023-12-24 16:15:57.850178: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: FFT
2023-12-24 16:15:57.850221: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: _FusedBatchNormEx
2023-12-24 16:15:57.850256: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: _FusedBatchNormEx
2023-12-24 16:15:57.850290: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: XlaSetDynamicDimensionSize
2023-12-24 16:15:57.850318: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: XlaSetDynamicDimensionSize
2023-12-24 16:15:57.850350: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: TensorArrayConcatV3
2023-12-24 16:15:57.850377: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: TensorArrayConcatV3
2023-12-24 16:15:57.850412: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: Cast
2023-12-24 16:15:57.850444: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Cast
2023-12-24 16:15:57.850483: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: Conv2DBackpropInput
2023-12-24 16:15:57.850514: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Conv2DBackpropInput
2023-12-24 16:15:57.850557: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: StatelessRandomUniformFullInt
2023-12-24 16:15:57.850599: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: StatelessRandomUniformFullInt
2023-12-24 16:15:57.850638: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: BiasAddV1
2023-12-24 16:15:57.850667: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: BiasAddV1
2023-12-24 16:15:57.850704: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: Multinomial
2023-12-24 16:15:57.850739: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Multinomial
2023-12-24 16:15:57.850773: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: L2Loss
2023-12-24 16:15:57.850801: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: L2Loss
2023-12-24 16:15:57.850833: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: MatrixDiag
2023-12-24 16:15:57.850861: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: MatrixDiag
2023-12-24 16:15:57.850900: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: ListDiff
2023-12-24 16:15:57.850940: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: ListDiff
2023-12-24 16:15:57.850980: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: LowerBound
2023-12-24 16:15:57.851013: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: LowerBound
2023-12-24 16:15:57.851047: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: Snapshot
2023-12-24 16:15:57.851074: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Snapshot
2023-12-24 16:15:57.851112: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: StatefulTruncatedNormal
2023-12-24 16:15:57.851148: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: StatefulTruncatedNormal
2023-12-24 16:15:57.851187: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: MatrixSolve
2023-12-24 16:15:57.851223: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: MatrixSolve
2023-12-24 16:15:57.851262: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: ResourceApplyAdagradDA
2023-12-24 16:15:57.851294: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: ResourceApplyAdagradDA
2023-12-24 16:15:57.851330: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: Const
2023-12-24 16:15:57.851358: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Const
2023-12-24 16:15:57.851391: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: FloorMod
2023-12-24 16:15:57.851420: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: FloorMod
2023-12-24 16:15:57.851453: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: Relu6Grad
2023-12-24 16:15:57.851481: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Relu6Grad
2023-12-24 16:15:57.851519: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: MatMul
2023-12-24 16:15:57.851550: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: MatMul
2023-12-24 16:15:57.851588: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: SparseMatMul
2023-12-24 16:15:57.851624: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: SparseMatMul
2023-12-24 16:15:57.851658: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: SelectV2
2023-12-24 16:15:57.851686: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: SelectV2
2023-12-24 16:15:57.851721: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: MatrixBandPart
2023-12-24 16:15:57.851753: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: MatrixBandPart
2023-12-24 16:15:57.851791: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: Conj
2023-12-24 16:15:57.851819: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Conj
2023-12-24 16:15:57.851851: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: MatrixDiagV2
2023-12-24 16:15:57.851878: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: MatrixDiagV2
2023-12-24 16:15:57.851916: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: XlaScatter
2023-12-24 16:15:57.851950: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: XlaScatter
2023-12-24 16:15:57.851988: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: SymbolicGradient
2023-12-24 16:15:57.852020: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: SymbolicGradient
2023-12-24 16:15:57.852056: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: MatrixDiagPart
2023-12-24 16:15:57.852083: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: MatrixDiagPart
2023-12-24 16:15:57.852116: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: MaxPoolV2
2023-12-24 16:15:57.852144: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: MaxPoolV2
2023-12-24 16:15:57.852175: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: MatrixDiagPartV3
2023-12-24 16:15:57.852209: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: MatrixDiagPartV3
2023-12-24 16:15:57.852248: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: Prod
2023-12-24 16:15:57.852283: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Prod
2023-12-24 16:15:57.852317: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: MatrixSetDiag
2023-12-24 16:15:57.852344: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: MatrixSetDiag
2023-12-24 16:15:57.852376: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: MatrixSetDiagV3
2023-12-24 16:15:57.852403: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: MatrixSetDiagV3
2023-12-24 16:15:57.852438: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: Pow
2023-12-24 16:15:57.852467: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Pow
2023-12-24 16:15:57.852502: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: TensorScatterMax
2023-12-24 16:15:57.852536: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: TensorScatterMax
2023-12-24 16:15:57.852572: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: Square
2023-12-24 16:15:57.852600: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Square
2023-12-24 16:15:57.852640: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: ResourceApplyRMSProp
2023-12-24 16:15:57.852673: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: ResourceApplyRMSProp
2023-12-24 16:15:57.852707: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: Betainc
2023-12-24 16:15:57.852735: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Betainc
2023-12-24 16:15:57.852767: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: XlaSharding
2023-12-24 16:15:57.852795: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: XlaSharding
2023-12-24 16:15:57.852829: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: MatrixTriangularSolve
2023-12-24 16:15:57.852858: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: MatrixTriangularSolve
2023-12-24 16:15:57.852895: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: MirrorPadGrad
2023-12-24 16:15:57.852928: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: MirrorPadGrad
2023-12-24 16:15:57.852958: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: NoOp
2023-12-24 16:15:57.852977: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: NoOp
2023-12-24 16:15:57.852997: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: ControlTrigger
2023-12-24 16:15:57.853014: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: ControlTrigger
2023-12-24 16:15:57.853039: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: Pack
2023-12-24 16:15:57.853067: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Pack
2023-12-24 16:15:57.853104: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: MaxPool3DGradGrad
2023-12-24 16:15:57.853135: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: MaxPool3DGradGrad
2023-12-24 16:15:57.853170: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: MaxPool
2023-12-24 16:15:57.853205: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: MaxPool
2023-12-24 16:15:57.853240: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: MaxPool3D
2023-12-24 16:15:57.853269: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: MaxPool3D
2023-12-24 16:15:57.853302: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: Range
2023-12-24 16:15:57.853331: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Range
2023-12-24 16:15:57.853364: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: AvgPool3D
2023-12-24 16:15:57.853392: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: AvgPool3D
2023-12-24 16:15:57.853428: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: MaxPoolGrad
2023-12-24 16:15:57.853456: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: MaxPoolGrad
2023-12-24 16:15:57.853489: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: AvgPoolGrad
2023-12-24 16:15:57.853517: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: AvgPoolGrad
2023-12-24 16:15:57.853553: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: RandomStandardNormal
2023-12-24 16:15:57.853587: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: RandomStandardNormal
2023-12-24 16:15:57.853625: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: AvgPool3DGrad
2023-12-24 16:15:57.853653: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: AvgPool3DGrad
2023-12-24 16:15:57.853685: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: VariableShape
2023-12-24 16:15:57.853713: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: VariableShape
2023-12-24 16:15:57.853746: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: Qr
2023-12-24 16:15:57.853774: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Qr
2023-12-24 16:15:57.853808: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: QuantizeAndDequantizeV3
2023-12-24 16:15:57.853836: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: QuantizeAndDequantizeV3
2023-12-24 16:15:57.853871: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: Complex
2023-12-24 16:15:57.853905: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Complex
2023-12-24 16:15:57.853939: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: DynamicStitch
2023-12-24 16:15:57.853966: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: DynamicStitch
2023-12-24 16:15:57.853999: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: QuantizeAndDequantizeV4
2023-12-24 16:15:57.854029: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: QuantizeAndDequantizeV4
2023-12-24 16:15:57.854056: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: StackCloseV2
2023-12-24 16:15:57.854073: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: StackCloseV2
2023-12-24 16:15:57.854106: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: StatefulUniformInt
2023-12-24 16:15:57.854143: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: StatefulUniformInt
2023-12-24 16:15:57.854179: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: RandomShuffle
2023-12-24 16:15:57.854211: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: RandomShuffle
2023-12-24 16:15:57.854244: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: TensorArrayReadV3
2023-12-24 16:15:57.854271: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: TensorArrayReadV3
2023-12-24 16:15:57.854309: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: XlaReduceWindow
2023-12-24 16:15:57.854343: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: XlaReduceWindow
2023-12-24 16:15:57.854380: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: XlaPad
2023-12-24 16:15:57.854414: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: XlaPad
2023-12-24 16:15:57.854453: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: Min
2023-12-24 16:15:57.854487: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Min
2023-12-24 16:15:57.854522: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: TensorListGetItem
2023-12-24 16:15:57.854549: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: TensorListGetItem
2023-12-24 16:15:57.854583: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: XlaReduce
2023-12-24 16:15:57.854611: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: XlaReduce
2023-12-24 16:15:57.854647: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: Mean
2023-12-24 16:15:57.854681: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Mean
2023-12-24 16:15:57.854717: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: All
2023-12-24 16:15:57.854745: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: All
2023-12-24 16:15:57.854782: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: AssignAddVariableOp
2023-12-24 16:15:57.854815: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: AssignAddVariableOp
2023-12-24 16:15:57.854848: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: HSVToRGB
2023-12-24 16:15:57.854876: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: HSVToRGB
2023-12-24 16:15:57.854904: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: TensorArrayGradV3
2023-12-24 16:15:57.854922: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: TensorArrayGradV3
2023-12-24 16:15:57.854948: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: Any
2023-12-24 16:15:57.854975: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Any
2023-12-24 16:15:57.855008: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: Relu
2023-12-24 16:15:57.855037: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Relu
2023-12-24 16:15:57.855068: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: MatrixDiagPartV2
2023-12-24 16:15:57.855096: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: MatrixDiagPartV2
2023-12-24 16:15:57.855129: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: Relu6
2023-12-24 16:15:57.855157: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Relu6
2023-12-24 16:15:57.855190: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: LeakyReluGrad
2023-12-24 16:15:57.855223: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: LeakyReluGrad
2023-12-24 16:15:57.855251: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: XlaReplicaId
2023-12-24 16:15:57.855268: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: XlaReplicaId
2023-12-24 16:15:57.855295: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: LRN
2023-12-24 16:15:57.855323: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: LRN
2023-12-24 16:15:57.855355: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: _Retval
2023-12-24 16:15:57.855382: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: _Retval
2023-12-24 16:15:57.855417: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: TensorListConcatV2
2023-12-24 16:15:57.855449: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: TensorListConcatV2
2023-12-24 16:15:57.855485: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: Reverse
2023-12-24 16:15:57.855514: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Reverse
2023-12-24 16:15:57.855547: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: Mod
2023-12-24 16:15:57.855575: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Mod
2023-12-24 16:15:57.855611: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: ReverseSequence
2023-12-24 16:15:57.855644: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: ReverseSequence
2023-12-24 16:15:57.855689: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: Cumprod
2023-12-24 16:15:57.855728: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Cumprod
2023-12-24 16:15:57.855764: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: Diag
2023-12-24 16:15:57.855792: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Diag
2023-12-24 16:15:57.855824: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: Polygamma
2023-12-24 16:15:57.855852: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Polygamma
2023-12-24 16:15:57.855888: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: ScatterNd
2023-12-24 16:15:57.855921: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: ScatterNd
2023-12-24 16:15:57.855956: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: LRNGrad
2023-12-24 16:15:57.855984: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: LRNGrad
2023-12-24 16:15:57.856011: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: TensorArrayCloseV3
2023-12-24 16:15:57.856029: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: TensorArrayCloseV3
2023-12-24 16:15:57.856059: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: TensorScatterSub
2023-12-24 16:15:57.856095: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: TensorScatterSub
2023-12-24 16:15:57.856138: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: UnsortedSegmentProd
2023-12-24 16:15:57.856178: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: UnsortedSegmentProd
2023-12-24 16:15:57.856230: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: UnsortedSegmentSum
2023-12-24 16:15:57.856271: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: UnsortedSegmentSum
2023-12-24 16:15:57.856308: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: Select
2023-12-24 16:15:57.856335: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Select
2023-12-24 16:15:57.856366: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: XlaSend
2023-12-24 16:15:57.856393: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: XlaSend
2023-12-24 16:15:57.856424: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: MatrixSetDiagV2
2023-12-24 16:15:57.856451: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: MatrixSetDiagV2
2023-12-24 16:15:57.856483: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: XlaRecv
2023-12-24 16:15:57.856510: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: XlaRecv
2023-12-24 16:15:57.856546: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: LinSpace
2023-12-24 16:15:57.856580: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: LinSpace
2023-12-24 16:15:57.856618: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: Angle
2023-12-24 16:15:57.856651: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Angle
2023-12-24 16:15:57.856685: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: Rank
2023-12-24 16:15:57.856712: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Rank
2023-12-24 16:15:57.856744: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: Asinh
2023-12-24 16:15:57.856771: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Asinh
2023-12-24 16:15:57.856807: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: ExpandDims
2023-12-24 16:15:57.856840: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: ExpandDims
2023-12-24 16:15:57.856878: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: XlaDynamicUpdateSlice
2023-12-24 16:15:57.856911: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: XlaDynamicUpdateSlice
2023-12-24 16:15:57.856948: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: UpperBound
2023-12-24 16:15:57.856982: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: UpperBound
2023-12-24 16:15:57.857023: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: Roll
2023-12-24 16:15:57.857061: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Roll
2023-12-24 16:15:57.857101: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: Squeeze
2023-12-24 16:15:57.857128: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Squeeze
2023-12-24 16:15:57.857156: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: FakeQuantWithMinMaxArgsGradient
2023-12-24 16:15:57.857174: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: FakeQuantWithMinMaxArgsGradient
2023-12-24 16:15:57.857204: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: XlaSplitND
2023-12-24 16:15:57.857232: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: XlaSplitND
2023-12-24 16:15:57.857269: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: XlaKeyValueSort
2023-12-24 16:15:57.857303: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: XlaKeyValueSort
2023-12-24 16:15:57.857341: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: SplitV
2023-12-24 16:15:57.857374: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: SplitV
2023-12-24 16:15:57.857408: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: ReadVariableXlaSplitND
2023-12-24 16:15:57.857435: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: ReadVariableXlaSplitND
2023-12-24 16:15:57.857466: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: TensorArraySplitV3
2023-12-24 16:15:57.857493: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: TensorArraySplitV3
2023-12-24 16:15:57.857529: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: MatrixInverse
2023-12-24 16:15:57.857560: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: MatrixInverse
2023-12-24 16:15:57.857593: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: XlaConcatND
2023-12-24 16:15:57.857620: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: XlaConcatND
2023-12-24 16:15:57.857653: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: Ndtri
2023-12-24 16:15:57.857681: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Ndtri
2023-12-24 16:15:57.857713: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: AssignVariableXlaConcatND
2023-12-24 16:15:57.871346: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: AssignVariableXlaConcatND
2023-12-24 16:15:57.871380: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: FakeQuantWithMinMaxVarsPerChannel
2023-12-24 16:15:57.871399: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: FakeQuantWithMinMaxVarsPerChannel
2023-12-24 16:15:57.871434: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: StatefulUniformFullInt
2023-12-24 16:15:57.871470: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: StatefulUniformFullInt
2023-12-24 16:15:57.871506: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: EnsureShape
2023-12-24 16:15:57.871534: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: EnsureShape
2023-12-24 16:15:57.871566: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: Softmax
2023-12-24 16:15:57.871594: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Softmax
2023-12-24 16:15:57.871626: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: LogSoftmax
2023-12-24 16:15:57.871654: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: LogSoftmax
2023-12-24 16:15:57.871689: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: ResourceScatterUpdate
2023-12-24 16:15:57.871723: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: ResourceScatterUpdate
2023-12-24 16:15:57.871754: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: TensorArraySizeV3
2023-12-24 16:15:57.871772: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: TensorArraySizeV3
2023-12-24 16:15:57.871797: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: XlaSort
2023-12-24 16:15:57.871825: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: XlaSort
2023-12-24 16:15:57.871860: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: Fill
2023-12-24 16:15:57.871894: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Fill
2023-12-24 16:15:57.871932: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: SpaceToBatch
2023-12-24 16:15:57.871965: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: SpaceToBatch
2023-12-24 16:15:57.872011: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: StatelessRandomNormal
2023-12-24 16:15:57.872054: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: StatelessRandomNormal
2023-12-24 16:15:57.872092: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: XlaSpmdFullToShardShape
2023-12-24 16:15:57.872120: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: XlaSpmdFullToShardShape
2023-12-24 16:15:57.872152: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: StackV2
2023-12-24 16:15:57.872179: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: StackV2
2023-12-24 16:15:57.872221: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: MirrorPad
2023-12-24 16:15:57.872256: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: MirrorPad
2023-12-24 16:15:57.872290: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: StackPushV2
2023-12-24 16:15:57.872318: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: StackPushV2
2023-12-24 16:15:57.872357: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: StatefulUniform
2023-12-24 16:15:57.872393: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: StatefulUniform
2023-12-24 16:15:57.872433: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: MaxPoolGradGrad
2023-12-24 16:15:57.872464: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: MaxPoolGradGrad
2023-12-24 16:15:57.872498: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: XlaSpmdShardToFullShape
2023-12-24 16:15:57.872525: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: XlaSpmdShardToFullShape
2023-12-24 16:15:57.872569: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: StatelessParameterizedTruncatedNormal
2023-12-24 16:15:57.872611: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: StatelessParameterizedTruncatedNormal
2023-12-24 16:15:57.872655: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: StatelessRandomUniformFullIntV2
2023-12-24 16:15:57.872691: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: StatelessRandomUniformFullIntV2
2023-12-24 16:15:57.872732: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: StatelessRandomUniformV2
2023-12-24 16:15:57.872768: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: StatelessRandomUniformV2
2023-12-24 16:15:57.872809: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: StatelessRandomUniformIntV2
2023-12-24 16:15:57.872844: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: StatelessRandomUniformIntV2
2023-12-24 16:15:57.872879: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: ToBool
2023-12-24 16:15:57.872906: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: ToBool
2023-12-24 16:15:57.872944: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: StatelessTruncatedNormalV2
2023-12-24 16:15:57.872980: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: StatelessTruncatedNormalV2
2023-12-24 16:15:57.873026: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: BatchMatMulV3
2023-12-24 16:15:57.873066: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: BatchMatMulV3
2023-12-24 16:15:57.873105: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: StatelessRandomGetKeyCounter
2023-12-24 16:15:57.873133: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: StatelessRandomGetKeyCounter
2023-12-24 16:15:57.873170: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: MaxPool3DGrad
2023-12-24 16:15:57.873207: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: MaxPool3DGrad
2023-12-24 16:15:57.873238: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: StatelessRandomGetAlg
2023-12-24 16:15:57.873256: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: StatelessRandomGetAlg
2023-12-24 16:15:57.873288: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: XlaRngBitGenerator
2023-12-24 16:15:57.873324: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: XlaRngBitGenerator
2023-12-24 16:15:57.873369: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: StatelessRandomUniform
2023-12-24 16:15:57.873411: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: StatelessRandomUniform
2023-12-24 16:15:57.873454: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: StridedSlice
2023-12-24 16:15:57.873487: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: StridedSlice
2023-12-24 16:15:57.873526: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: Tile
2023-12-24 16:15:57.873559: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Tile
2023-12-24 16:15:57.873598: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: TensorScatterUpdate
2023-12-24 16:15:57.873631: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: TensorScatterUpdate
2023-12-24 16:15:57.873668: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: SoftplusGrad
2023-12-24 16:15:57.873697: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: SoftplusGrad
2023-12-24 16:15:57.873733: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: StridedSliceGrad
2023-12-24 16:15:57.873766: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: StridedSliceGrad
2023-12-24 16:15:57.873802: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: _Arg
2023-12-24 16:15:57.873829: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: _Arg
2023-12-24 16:15:57.873865: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: ResourceStridedSliceAssign
2023-12-24 16:15:57.873898: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: ResourceStridedSliceAssign
2023-12-24 16:15:57.873933: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: ZerosLike
2023-12-24 16:15:57.873960: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: ZerosLike
2023-12-24 16:15:57.873996: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: TensorStridedSliceUpdate
2023-12-24 16:15:57.874029: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: TensorStridedSliceUpdate
2023-12-24 16:15:57.874068: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: TensorListReserve
2023-12-24 16:15:57.874101: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: TensorListReserve
2023-12-24 16:15:57.874140: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: ResourceGather
2023-12-24 16:15:57.874178: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: ResourceGather
2023-12-24 16:15:57.874225: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: BatchToSpaceND
2023-12-24 16:15:57.874264: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: BatchToSpaceND
2023-12-24 16:15:57.874304: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: Sub
2023-12-24 16:15:57.874333: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Sub
2023-12-24 16:15:57.874366: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: TensorListElementShape
2023-12-24 16:15:57.874394: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: TensorListElementShape
2023-12-24 16:15:57.874670: I tensorflow/compiler/jit/mark_for_compilation_pass.cc:1245] Starting fuel: infinity
2023-12-24 16:15:57.874687: I tensorflow/compiler/jit/mark_for_compilation_pass.cc:1250] sorted_nodes.size() = 9
2023-12-24 16:15:57.875325: I tensorflow/compiler/tf2xla/xla_op_registry.cc:153] tf_xla_cpu_global_jit = 0
2023-12-24 16:15:57.875372: I tensorflow/compiler/tf2xla/xla_op_registry.cc:51] LaunchOpHasKernelForDevice kernel_class_name: XlaLocalLaunchOp
2023-12-24 16:15:57.875412: I tensorflow/compiler/tf2xla/xla_op_registry.cc:51] LaunchOpHasKernelForDevice kernel_class_name: XlaLocalLaunchOp
2023-12-24 16:15:57.875917: I tensorflow/compiler/jit/compilability_check_util.cc:75] Found uncompilable node _arg_X_0_0 (op _Arg): top level _Arg or _Retval
2023-12-24 16:15:57.875952: I tensorflow/compiler/jit/compilability_check_util.cc:75] Found uncompilable node _retval_Sigmoid_0_0 (op _Retval): top level _Arg or _Retval
2023-12-24 16:15:57.875964: I tensorflow/compiler/jit/mark_for_compilation_pass.cc:1406] compilation_candidates_.size() = 7
2023-12-24 16:15:57.876380: I tensorflow/compiler/jit/deadness_analysis.cc:1415] Done populating frame  using the pessimistic mode.
2023-12-24 16:15:57.876426: I tensorflow/compiler/jit/deadness_analysis.cc:1563] ^Add -> #true
2023-12-24 16:15:57.876436: I tensorflow/compiler/jit/deadness_analysis.cc:1563] Add:0 -> #true
2023-12-24 16:15:57.876443: I tensorflow/compiler/jit/deadness_analysis.cc:1563] ^Bias -> #true
2023-12-24 16:15:57.876450: I tensorflow/compiler/jit/deadness_analysis.cc:1563] Bias:0 -> #true
2023-12-24 16:15:57.876457: I tensorflow/compiler/jit/deadness_analysis.cc:1563] ^Bias/read -> #true
2023-12-24 16:15:57.876464: I tensorflow/compiler/jit/deadness_analysis.cc:1563] Bias/read:0 -> #true
2023-12-24 16:15:57.876471: I tensorflow/compiler/jit/deadness_analysis.cc:1563] ^MatMul -> #true
2023-12-24 16:15:57.876479: I tensorflow/compiler/jit/deadness_analysis.cc:1563] MatMul:0 -> #true
2023-12-24 16:15:57.876486: I tensorflow/compiler/jit/deadness_analysis.cc:1563] ^Sigmoid -> #true
2023-12-24 16:15:57.876493: I tensorflow/compiler/jit/deadness_analysis.cc:1563] Sigmoid:0 -> #true
2023-12-24 16:15:57.876500: I tensorflow/compiler/jit/deadness_analysis.cc:1563] ^Weight -> #true
2023-12-24 16:15:57.876507: I tensorflow/compiler/jit/deadness_analysis.cc:1563] Weight:0 -> #true
2023-12-24 16:15:57.876514: I tensorflow/compiler/jit/deadness_analysis.cc:1563] ^Weight/read -> #true
2023-12-24 16:15:57.876522: I tensorflow/compiler/jit/deadness_analysis.cc:1563] Weight/read:0 -> #true
2023-12-24 16:15:57.876529: I tensorflow/compiler/jit/deadness_analysis.cc:1563] ^_SOURCE -> #true
2023-12-24 16:15:57.876536: I tensorflow/compiler/jit/deadness_analysis.cc:1563] ^_arg_X_0_0 -> #true
2023-12-24 16:15:57.876543: I tensorflow/compiler/jit/deadness_analysis.cc:1563] _arg_X_0_0:0 -> #true
2023-12-24 16:15:57.876550: I tensorflow/compiler/jit/deadness_analysis.cc:1563] ^_retval_Sigmoid_0_0 -> #true
2023-12-24 16:15:57.876569: I tensorflow/compiler/jit/mark_for_compilation_pass.cc:650] DeadnessAnalysis time: 357 us (cumulative: 357 us, max: 357 us, #called: 1)
2023-12-24 16:15:57.876647: I tensorflow/compiler/jit/resource_operation_safety_analysis.cc:310] _SOURCE -> {}
2023-12-24 16:15:57.876701: I tensorflow/compiler/jit/resource_operation_safety_analysis.cc:310] Bias -> {}
2023-12-24 16:15:57.876722: I tensorflow/compiler/jit/resource_operation_safety_analysis.cc:310] Bias/read -> {}
2023-12-24 16:15:57.876742: I tensorflow/compiler/jit/resource_operation_safety_analysis.cc:310] Weight -> {}
2023-12-24 16:15:57.876759: I tensorflow/compiler/jit/resource_operation_safety_analysis.cc:310] Weight/read -> {}
2023-12-24 16:15:57.876775: I tensorflow/compiler/jit/resource_operation_safety_analysis.cc:310] _arg_X_0_0 -> {}
2023-12-24 16:15:57.876791: I tensorflow/compiler/jit/resource_operation_safety_analysis.cc:310] MatMul -> {}
2023-12-24 16:15:57.876804: I tensorflow/compiler/jit/resource_operation_safety_analysis.cc:310] Add -> {}
2023-12-24 16:15:57.876818: I tensorflow/compiler/jit/resource_operation_safety_analysis.cc:310] Sigmoid -> {}
2023-12-24 16:15:57.876834: I tensorflow/compiler/jit/resource_operation_safety_analysis.cc:310] _retval_Sigmoid_0_0 -> {}
2023-12-24 16:15:57.876845: I tensorflow/compiler/jit/resource_operation_safety_analysis.cc:310] _SINK -> {}
2023-12-24 16:15:57.877167: I tensorflow/compiler/jit/mark_for_compilation_pass.cc:863] Checking idempotence
2023-12-24 16:15:57.877210: I tensorflow/compiler/jit/mark_for_compilation_pass.cc:1771] Not compiling cluster with device /job:localhost/replica:0/task:0/device:GPU:0
2023-12-24 16:15:57.877289: I tensorflow/compiler/jit/mark_for_compilation_pass.cc:1579] *** Clustering info for graph of size 11
2023-12-24 16:15:57.877311: I tensorflow/compiler/jit/mark_for_compilation_pass.cc:1580]  Built 0 clusters, size 0 / 11 (0.00%)
2023-12-24 16:15:57.877320: I tensorflow/compiler/jit/mark_for_compilation_pass.cc:1599]  Unclustered nodes: 11 / 11 (100.00%)
2023-12-24 16:15:57.877328: I tensorflow/compiler/jit/mark_for_compilation_pass.cc:1604]   Add: 1 instances
2023-12-24 16:15:57.877334: I tensorflow/compiler/jit/mark_for_compilation_pass.cc:1604]   Const: 2 instances
2023-12-24 16:15:57.877340: I tensorflow/compiler/jit/mark_for_compilation_pass.cc:1604]   Identity: 2 instances
2023-12-24 16:15:57.877346: I tensorflow/compiler/jit/mark_for_compilation_pass.cc:1604]   MatMul: 1 instances
2023-12-24 16:15:57.877352: I tensorflow/compiler/jit/mark_for_compilation_pass.cc:1604]   NoOp: 2 instances
2023-12-24 16:15:57.877358: I tensorflow/compiler/jit/mark_for_compilation_pass.cc:1604]   Sigmoid: 1 instances
2023-12-24 16:15:57.877364: I tensorflow/compiler/jit/mark_for_compilation_pass.cc:1604]   _Arg: 1 instances
2023-12-24 16:15:57.877370: I tensorflow/compiler/jit/mark_for_compilation_pass.cc:1604]   _Retval: 1 instances
2023-12-24 16:15:57.877402: I tensorflow/compiler/jit/mark_for_compilation_pass.cc:1523] MarkForCompilationPassImpl::Run time: 2.98 ms (cumulative: 2.98 ms, max: 2.98 ms, #called: 1)
2023-12-24 16:15:57.877473: I tensorflow/core/common_runtime/optimization_registry.cc:66] Running optimization phase 12
2023-12-24 16:15:57.877484: I tensorflow/core/common_runtime/optimization_registry.cc:68] Running optimization pass: ForceXlaConstantsOnHostPass
2023-12-24 16:15:57.877602: I tensorflow/core/common_runtime/optimization_registry.cc:66] Running optimization phase 20
2023-12-24 16:15:57.877611: I tensorflow/core/common_runtime/optimization_registry.cc:68] Running optimization pass: IncreaseDynamismForAutoJitPass
2023-12-24 16:15:57.877634: I tensorflow/core/common_runtime/optimization_registry.cc:66] Running optimization phase 30
2023-12-24 16:15:57.877641: I tensorflow/core/common_runtime/optimization_registry.cc:68] Running optimization pass: PartiallyDeclusterPass
2023-12-24 16:15:57.877954: I tensorflow/core/common_runtime/optimization_registry.cc:66] Running optimization phase 40
2023-12-24 16:15:57.877969: I tensorflow/core/common_runtime/optimization_registry.cc:68] Running optimization pass: ReportClusteringInfoPass
2023-12-24 16:15:57.878167: I tensorflow/compiler/jit/xla_activity_logging_listener.cc:39] Not logging: logger not ready yet.
2023-12-24 16:15:57.878191: I tensorflow/core/common_runtime/optimization_registry.cc:66] Running optimization phase 50
2023-12-24 16:15:57.878204: I tensorflow/core/common_runtime/optimization_registry.cc:68] Running optimization pass: EncapsulateSubgraphsPass
2023-12-24 16:15:57.878212: I tensorflow/compiler/jit/encapsulate_subgraphs_pass.cc:1139] EncapsulateSubgraphsPass::Run
2023-12-24 16:15:57.878390: W tensorflow/core/util/dump_graph.cc:134] Failed to dump encapsulate_subgraphs_before because dump location is not  specified through either TF_DUMP_GRAPH_PREFIX environment variable or function argument.
2023-12-24 16:15:57.878958: I tensorflow/core/graph/graph.cc:616] AddNode: no type constructor for _SOURCE
2023-12-24 16:15:57.879034: I tensorflow/core/graph/graph.cc:616] AddNode: no type constructor for _SINK
2023-12-24 16:15:57.879394: W tensorflow/core/util/dump_graph.cc:134] Failed to dump encapsulate_subgraphs_after because dump location is not  specified through either TF_DUMP_GRAPH_PREFIX environment variable or function argument.
2023-12-24 16:15:57.879603: I tensorflow/compiler/jit/xla_cluster_util.cc:559] # iterations = 1
2023-12-24 16:15:57.879680: I tensorflow/compiler/jit/xla_cluster_util.cc:559] # iterations = 1
2023-12-24 16:15:57.879690: I tensorflow/compiler/jit/xla_cluster_util.cc:591] GetNodesRelatedToRefVariables() found 0 nodes
2023-12-24 16:15:57.879794: I tensorflow/compiler/jit/encapsulate_subgraphs_pass.cc:1307] Has ref vars = 0, node: name: "_SOURCE"
op: "NoOp"
attr {
  key: "_XlaHasReferenceVars"
  value {
    b: false
  }
}

2023-12-24 16:15:57.879830: I tensorflow/compiler/jit/encapsulate_subgraphs_pass.cc:1307] Has ref vars = 0, node: name: "_SINK"
op: "NoOp"
attr {
  key: "_XlaHasReferenceVars"
  value {
    b: false
  }
}

2023-12-24 16:15:57.879929: I tensorflow/compiler/jit/encapsulate_subgraphs_pass.cc:1307] Has ref vars = 0, node: name: "Weight"
op: "Const"
device: "/device:GPU:0"
attr {
  key: "_XlaHasReferenceVars"
  value {
    b: false
  }
}
attr {
  key: "dtype"
  value {
    type: DT_FLOAT
  }
}
attr {
  key: "value"
  value {
    tensor {
      dtype: DT_FLOAT
      tensor_shape {
        dim {
          size: 5
        }
        dim {
          size: 7
        }
      }
      tensor_content: "\0004\232<\300p-\274a \205<\024\331\007;B\373g\274\223\323C;\346C\356\273\244]\260:m\331\263\273\205K\252;\345\013\350:\341\236\r<a%\230<\242\262\023<@n\033< Z\322:\362\275\222;\333\270\003\274\343\232\005\273\227@\367\273\2234\351\273\031>\002\273\317\"\035\272\327:\026<+\301T\274T\300\036\274\241g\216<U\210\262\272F\003\250\273\373\224\000\274!8\220<\200\032!<,-Z<\324I3\274\2547\210:"
    }
  }
}

2023-12-24 16:15:57.880013: I tensorflow/compiler/jit/encapsulate_subgraphs_pass.cc:1307] Has ref vars = 0, node: name: "Weight/read"
op: "Identity"
input: "Weight"
device: "/device:GPU:0"
attr {
  key: "T"
  value {
    type: DT_FLOAT
  }
}
attr {
  key: "_XlaHasReferenceVars"
  value {
    b: false
  }
}
attr {
  key: "_class"
  value {
    list {
      s: "loc:@Weight"
    }
  }
}

2023-12-24 16:15:57.880087: I tensorflow/compiler/jit/encapsulate_subgraphs_pass.cc:1307] Has ref vars = 0, node: name: "Bias"
op: "Const"
device: "/device:GPU:0"
attr {
  key: "_XlaHasReferenceVars"
  value {
    b: false
  }
}
attr {
  key: "dtype"
  value {
    type: DT_FLOAT
  }
}
attr {
  key: "value"
  value {
    tensor {
      dtype: DT_FLOAT
      tensor_shape {
        dim {
          size: 7
        }
      }
      tensor_content: "\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000"
    }
  }
}

2023-12-24 16:15:57.880163: I tensorflow/compiler/jit/encapsulate_subgraphs_pass.cc:1307] Has ref vars = 0, node: name: "Bias/read"
op: "Identity"
input: "Bias"
device: "/device:GPU:0"
attr {
  key: "T"
  value {
    type: DT_FLOAT
  }
}
attr {
  key: "_XlaHasReferenceVars"
  value {
    b: false
  }
}
attr {
  key: "_class"
  value {
    list {
      s: "loc:@Bias"
    }
  }
}

2023-12-24 16:15:57.880237: I tensorflow/compiler/jit/encapsulate_subgraphs_pass.cc:1307] Has ref vars = 0, node: name: "MatMul"
op: "MatMul"
input: "X"
input: "Weight/read"
device: "/device:GPU:0"
attr {
  key: "T"
  value {
    type: DT_FLOAT
  }
}
attr {
  key: "_XlaHasReferenceVars"
  value {
    b: false
  }
}
attr {
  key: "transpose_a"
  value {
    b: false
  }
}
attr {
  key: "transpose_b"
  value {
    b: false
  }
}

2023-12-24 16:15:57.880297: I tensorflow/compiler/jit/encapsulate_subgraphs_pass.cc:1307] Has ref vars = 0, node: name: "Add"
op: "Add"
input: "MatMul"
input: "Bias/read"
device: "/device:GPU:0"
attr {
  key: "T"
  value {
    type: DT_FLOAT
  }
}
attr {
  key: "_XlaHasReferenceVars"
  value {
    b: false
  }
}

2023-12-24 16:15:57.880349: I tensorflow/compiler/jit/encapsulate_subgraphs_pass.cc:1307] Has ref vars = 0, node: name: "Sigmoid"
op: "Sigmoid"
input: "Add"
device: "/device:GPU:0"
attr {
  key: "T"
  value {
    type: DT_FLOAT
  }
}
attr {
  key: "_XlaHasReferenceVars"
  value {
    b: false
  }
}

2023-12-24 16:15:57.880395: I tensorflow/compiler/jit/encapsulate_subgraphs_pass.cc:1307] Has ref vars = 0, node: name: "_arg_X_0_0"
op: "_Arg"
attr {
  key: "T"
  value {
    type: DT_FLOAT
  }
}
attr {
  key: "_XlaHasReferenceVars"
  value {
    b: false
  }
}
attr {
  key: "index"
  value {
    i: 0
  }
}

2023-12-24 16:15:57.880442: I tensorflow/compiler/jit/encapsulate_subgraphs_pass.cc:1307] Has ref vars = 0, node: name: "_retval_Sigmoid_0_0"
op: "_Retval"
input: "Sigmoid"
attr {
  key: "T"
  value {
    type: DT_FLOAT
  }
}
attr {
  key: "_XlaHasReferenceVars"
  value {
    b: false
  }
}
attr {
  key: "index"
  value {
    i: 0
  }
}

2023-12-24 16:15:57.880604: I tensorflow/core/common_runtime/optimization_registry.cc:66] Running optimization phase 60
2023-12-24 16:15:57.880619: I tensorflow/core/common_runtime/optimization_registry.cc:68] Running optimization pass: BuildXlaOpsPass
2023-12-24 16:15:57.880653: I tensorflow/compiler/jit/build_xla_ops_pass.cc:603] print_outputs = 0
2023-12-24 16:15:57.880660: I tensorflow/compiler/jit/build_xla_ops_pass.cc:604] check_input_numerics = 0
2023-12-24 16:15:57.880667: I tensorflow/compiler/jit/build_xla_ops_pass.cc:605] check_output_numerics = 0
2023-12-24 16:15:57.880788: W tensorflow/core/util/dump_graph.cc:134] Failed to dump build_xla_ops because dump location is not  specified through either TF_DUMP_GRAPH_PREFIX environment variable or function argument.
2023-12-24 16:15:57.880851: I tensorflow/core/common_runtime/optimization_registry.cc:87] Finished optimization of a group 2
2023-12-24 16:15:57.880949: W tensorflow/core/util/dump_graph.cc:134] Failed to dump after_grouping_2_94068957919792 because dump location is not  specified through either TF_DUMP_GRAPH_PREFIX environment variable or function argument.
2023-12-24 16:15:57.881047: I tensorflow/core/graph/graph.cc:616] AddNode: no type constructor for _SOURCE
2023-12-24 16:15:57.881090: I tensorflow/core/graph/graph.cc:616] AddNode: no type constructor for _SINK
2023-12-24 16:15:57.881884: I tensorflow/core/graph/graph_partition.cc:281] Receiving data from _arg_X_0_0 (_Arg) on /job:localhost/replica:0/task:0/device:CPU:0 in device memory for MatMul (MatMul) on /job:localhost/replica:0/task:0/device:GPU:0 in device memory
2023-12-24 16:15:57.882038: I tensorflow/core/graph/graph_partition.cc:281] Receiving data from Sigmoid (Sigmoid) on /job:localhost/replica:0/task:0/device:GPU:0 in device memory for _retval_Sigmoid_0_0 (_Retval) on /job:localhost/replica:0/task:0/device:CPU:0 in device memory
2023-12-24 16:15:57.882161: I tensorflow/core/graph/graph_partition.cc:1251] Added send/recv: controls=0, data=2
2023-12-24 16:15:57.882177: W tensorflow/core/util/dump_graph.cc:134] Failed to dump partition_/job:localhost/replica:0/task:0/device:CPU:0_94068537236088 because dump location is not  specified through either TF_DUMP_GRAPH_PREFIX environment variable or function argument.
2023-12-24 16:15:57.882194: W tensorflow/core/util/dump_graph.cc:134] Failed to dump partition_/job:localhost/replica:0/task:0/device:GPU:0_94068537867832 because dump location is not  specified through either TF_DUMP_GRAPH_PREFIX environment variable or function argument.
2023-12-24 16:15:57.882288: I tensorflow/core/graph/graph.cc:616] AddNode: no type constructor for _SOURCE
2023-12-24 16:15:57.882331: I tensorflow/core/graph/graph.cc:616] AddNode: no type constructor for _SINK
2023-12-24 16:15:57.882543: I tensorflow/core/graph/graph.cc:616] AddNode: no type constructor for _arg_X_0_0
2023-12-24 16:15:57.882623: I tensorflow/core/graph/graph.cc:616] AddNode: no type constructor for _arg_X_0_0/_0
2023-12-24 16:15:57.882675: I tensorflow/core/graph/graph.cc:616] AddNode: no type constructor for Sigmoid/_3
2023-12-24 16:15:57.882721: I tensorflow/core/graph/graph.cc:616] AddNode: no type constructor for _retval_Sigmoid_0_0
2023-12-24 16:15:57.882866: I tensorflow/core/graph/graph.cc:616] AddNode: no type constructor for _SOURCE
2023-12-24 16:15:57.882909: I tensorflow/core/graph/graph.cc:616] AddNode: no type constructor for _SINK
2023-12-24 16:15:57.883088: I tensorflow/core/graph/graph.cc:616] AddNode: no type constructor for Weight
2023-12-24 16:15:57.883163: I tensorflow/core/graph/graph.cc:616] AddNode: no type constructor for Weight/read
2023-12-24 16:15:57.883220: I tensorflow/core/graph/graph.cc:616] AddNode: no type constructor for Bias
2023-12-24 16:15:57.883268: I tensorflow/core/graph/graph.cc:616] AddNode: no type constructor for Bias/read
2023-12-24 16:15:57.883313: I tensorflow/core/graph/graph.cc:616] AddNode: no type constructor for _arg_X_0_0/_1
2023-12-24 16:15:57.883358: I tensorflow/core/graph/graph.cc:616] AddNode: no type constructor for MatMul
2023-12-24 16:15:57.883404: I tensorflow/core/graph/graph.cc:616] AddNode: no type constructor for Add
2023-12-24 16:15:57.883450: I tensorflow/core/graph/graph.cc:616] AddNode: no type constructor for Sigmoid
2023-12-24 16:15:57.883493: I tensorflow/core/graph/graph.cc:616] AddNode: no type constructor for Sigmoid/_2
2023-12-24 16:15:57.883609: I tensorflow/core/common_runtime/optimization_registry.cc:54] Starting optimization of a group 3
2023-12-24 16:15:57.883752: W tensorflow/core/util/dump_graph.cc:134] Failed to dump before_grouping_3_partition_/job:localhost/replica:0/task:0/device:GPU:0_94068946570032 because dump location is not  specified through either TF_DUMP_GRAPH_PREFIX environment variable or function argument.
2023-12-24 16:15:57.883855: W tensorflow/core/util/dump_graph.cc:134] Failed to dump before_grouping_3_partition_/job:localhost/replica:0/task:0/device:CPU:0_94068957919792 because dump location is not  specified through either TF_DUMP_GRAPH_PREFIX environment variable or function argument.
2023-12-24 16:15:57.883891: I tensorflow/core/common_runtime/optimization_registry.cc:66] Running optimization phase 1
2023-12-24 16:15:57.883900: I tensorflow/core/common_runtime/optimization_registry.cc:68] Running optimization pass: MklLayoutRewritePass
2023-12-24 16:15:57.883913: I tensorflow/core/common_runtime/function_utils.cc:78] Graph Before running MklLayoutRewritePass #nodes 11 #edges 13
2023-12-24 16:15:57.883951: I tensorflow/core/common_runtime/mkl_layout_pass.cc:1040] MklLayoutRewritePass: Skipping rewriting of the node Const, reason: User has assigned a device that is not CPU.
2023-12-24 16:15:57.883959: I tensorflow/core/common_runtime/mkl_layout_pass.cc:1040] MklLayoutRewritePass: Skipping rewriting of the node Identity, reason: User has assigned a device that is not CPU.
2023-12-24 16:15:57.883967: I tensorflow/core/common_runtime/mkl_layout_pass.cc:1040] MklLayoutRewritePass: Skipping rewriting of the node Const, reason: User has assigned a device that is not CPU.
2023-12-24 16:15:57.883974: I tensorflow/core/common_runtime/mkl_layout_pass.cc:1040] MklLayoutRewritePass: Skipping rewriting of the node Identity, reason: User has assigned a device that is not CPU.
2023-12-24 16:15:57.883981: I tensorflow/core/common_runtime/mkl_layout_pass.cc:1040] MklLayoutRewritePass: Skipping rewriting of the node _Recv, reason: User has assigned a device that is not CPU.
2023-12-24 16:15:57.883988: I tensorflow/core/common_runtime/mkl_layout_pass.cc:1040] MklLayoutRewritePass: Skipping rewriting of the node MatMul, reason: User has assigned a device that is not CPU.
2023-12-24 16:15:57.883995: I tensorflow/core/common_runtime/mkl_layout_pass.cc:1040] MklLayoutRewritePass: Skipping rewriting of the node Add, reason: User has assigned a device that is not CPU.
2023-12-24 16:15:57.884002: I tensorflow/core/common_runtime/mkl_layout_pass.cc:1040] MklLayoutRewritePass: Skipping rewriting of the node Sigmoid, reason: User has assigned a device that is not CPU.
2023-12-24 16:15:57.884009: I tensorflow/core/common_runtime/mkl_layout_pass.cc:1040] MklLayoutRewritePass: Skipping rewriting of the node _Send, reason: User has assigned a device that is not CPU.
2023-12-24 16:15:57.884017: I tensorflow/core/common_runtime/function_utils.cc:78] Graph After running MklLayoutRewritePass(NodeMerge) #nodes 11 #edges 13
2023-12-24 16:15:57.884032: I tensorflow/core/common_runtime/mkl_layout_pass.cc:1040] MklLayoutRewritePass: Skipping rewriting of the node Const, reason: User has assigned a device that is not CPU.
2023-12-24 16:15:57.884040: I tensorflow/core/common_runtime/mkl_layout_pass.cc:1040] MklLayoutRewritePass: Skipping rewriting of the node Identity, reason: User has assigned a device that is not CPU.
2023-12-24 16:15:57.884048: I tensorflow/core/common_runtime/mkl_layout_pass.cc:1040] MklLayoutRewritePass: Skipping rewriting of the node Const, reason: User has assigned a device that is not CPU.
2023-12-24 16:15:57.884055: I tensorflow/core/common_runtime/mkl_layout_pass.cc:1040] MklLayoutRewritePass: Skipping rewriting of the node Identity, reason: User has assigned a device that is not CPU.
2023-12-24 16:15:57.884061: I tensorflow/core/common_runtime/mkl_layout_pass.cc:1040] MklLayoutRewritePass: Skipping rewriting of the node _Recv, reason: User has assigned a device that is not CPU.
2023-12-24 16:15:57.884069: I tensorflow/core/common_runtime/mkl_layout_pass.cc:1040] MklLayoutRewritePass: Skipping rewriting of the node MatMul, reason: User has assigned a device that is not CPU.
2023-12-24 16:15:57.884076: I tensorflow/core/common_runtime/mkl_layout_pass.cc:1040] MklLayoutRewritePass: Skipping rewriting of the node Add, reason: User has assigned a device that is not CPU.
2023-12-24 16:15:57.884083: I tensorflow/core/common_runtime/mkl_layout_pass.cc:1040] MklLayoutRewritePass: Skipping rewriting of the node Sigmoid, reason: User has assigned a device that is not CPU.
2023-12-24 16:15:57.884090: I tensorflow/core/common_runtime/mkl_layout_pass.cc:1040] MklLayoutRewritePass: Skipping rewriting of the node _Send, reason: User has assigned a device that is not CPU.
2023-12-24 16:15:57.884097: I tensorflow/core/common_runtime/function_utils.cc:78] Graph After running MklLayoutRewritePass(NodeFusion) #nodes 11 #edges 13
2023-12-24 16:15:57.884112: I tensorflow/core/common_runtime/mkl_layout_pass.cc:1040] MklLayoutRewritePass: Skipping rewriting of the node Const, reason: User has assigned a device that is not CPU.
2023-12-24 16:15:57.884119: I tensorflow/core/common_runtime/mkl_layout_pass.cc:1040] MklLayoutRewritePass: Skipping rewriting of the node Identity, reason: User has assigned a device that is not CPU.
2023-12-24 16:15:57.884126: I tensorflow/core/common_runtime/mkl_layout_pass.cc:1040] MklLayoutRewritePass: Skipping rewriting of the node Const, reason: User has assigned a device that is not CPU.
2023-12-24 16:15:57.884133: I tensorflow/core/common_runtime/mkl_layout_pass.cc:1040] MklLayoutRewritePass: Skipping rewriting of the node Identity, reason: User has assigned a device that is not CPU.
2023-12-24 16:15:57.884140: I tensorflow/core/common_runtime/mkl_layout_pass.cc:1040] MklLayoutRewritePass: Skipping rewriting of the node _Recv, reason: User has assigned a device that is not CPU.
2023-12-24 16:15:57.884147: I tensorflow/core/common_runtime/mkl_layout_pass.cc:1040] MklLayoutRewritePass: Skipping rewriting of the node MatMul, reason: User has assigned a device that is not CPU.
2023-12-24 16:15:57.884154: I tensorflow/core/common_runtime/mkl_layout_pass.cc:1040] MklLayoutRewritePass: Skipping rewriting of the node Add, reason: User has assigned a device that is not CPU.
2023-12-24 16:15:57.884161: I tensorflow/core/common_runtime/mkl_layout_pass.cc:1040] MklLayoutRewritePass: Skipping rewriting of the node Sigmoid, reason: User has assigned a device that is not CPU.
2023-12-24 16:15:57.884168: I tensorflow/core/common_runtime/mkl_layout_pass.cc:1040] MklLayoutRewritePass: Skipping rewriting of the node _Send, reason: User has assigned a device that is not CPU.
2023-12-24 16:15:57.884175: I tensorflow/core/common_runtime/function_utils.cc:78] Graph After running MklLayoutRewritePass(NodeMerge+Rewrite) #nodes 11 #edges 13
2023-12-24 16:15:57.884184: I tensorflow/core/common_runtime/function_utils.cc:78] Graph Before running MklLayoutRewritePass #nodes 6 #edges 7
2023-12-24 16:15:57.884215: I tensorflow/core/common_runtime/function_utils.cc:78] Graph After running MklLayoutRewritePass(NodeMerge) #nodes 6 #edges 7
2023-12-24 16:15:57.884274: I tensorflow/core/common_runtime/function_utils.cc:78] Graph After running MklLayoutRewritePass(NodeFusion) #nodes 6 #edges 7
2023-12-24 16:15:57.896542: I tensorflow/core/common_runtime/function_utils.cc:78] Graph After running MklLayoutRewritePass(NodeMerge+Rewrite) #nodes 6 #edges 7
2023-12-24 16:15:57.896579: I tensorflow/core/common_runtime/optimization_registry.cc:87] Finished optimization of a group 3
2023-12-24 16:15:57.896719: W tensorflow/core/util/dump_graph.cc:134] Failed to dump after_grouping_3_partition_/job:localhost/replica:0/task:0/device:GPU:0_94068946570032 because dump location is not  specified through either TF_DUMP_GRAPH_PREFIX environment variable or function argument.
2023-12-24 16:15:57.896818: W tensorflow/core/util/dump_graph.cc:134] Failed to dump after_grouping_3_partition_/job:localhost/replica:0/task:0/device:CPU:0_94068957919792 because dump location is not  specified through either TF_DUMP_GRAPH_PREFIX environment variable or function argument.
2023-12-24 16:15:57.897081: I tensorflow/core/framework/log_memory.cc:34] __LOG_MEMORY__ MemoryLogTensorAllocation { step_id: -6 kernel_name: "Unknown (from Proto)" tensor { dtype: DT_FLOAT shape { dim { size: 7 } } allocation_description { requested_bytes: 28 allocated_bytes: 28 allocator_name: "mklcpu" allocation_id: 2 has_single_reference: true ptr: 94069282980864 } } }
2023-12-24 16:15:57.897138: I tensorflow/core/framework/log_memory.cc:34] __LOG_MEMORY__ MemoryLogTensorDeallocation { allocation_id: 2 allocator_name: "mklcpu" }
2023-12-24 16:15:57.897256: I tensorflow/core/framework/log_memory.cc:34] __LOG_MEMORY__ MemoryLogTensorAllocation { step_id: -6 kernel_name: "Unknown (from Proto)" tensor { dtype: DT_FLOAT shape { dim { size: 5 } dim { size: 7 } } allocation_description { requested_bytes: 140 allocated_bytes: 140 allocator_name: "mklcpu" allocation_id: 3 has_single_reference: true ptr: 94069282982080 } } }
2023-12-24 16:15:57.897289: I tensorflow/core/framework/log_memory.cc:34] __LOG_MEMORY__ MemoryLogTensorDeallocation { allocation_id: 3 allocator_name: "mklcpu" }
2023-12-24 16:15:57.897436: I tensorflow/core/common_runtime/direct_session.cc:1731] Created 
() -> () {
  n4 = Const[_XlaHasReferenceVars=false, dtype=float, value=Tensor<type: float shape: [7] values: 0 0 0...>, device=GPU:0]()
  n5 = Identity[T=float, _XlaHasReferenceVars=false, _class=["loc:@Bias"], device=GPU:0](n4)
  n2 = Const[_XlaHasReferenceVars=false, dtype=float, value=Tensor<type: float shape: [5,7] values: [0.0188236237 -0.0105859637 0.016250791...]...>, device=GPU:0]()
  n3 = Identity[T=float, _XlaHasReferenceVars=false, _class=["loc:@Weight"], device=GPU:0](n2)
  n6 = _Recv[_dst="MatMul", _src="_arg_X_0_0", client_terminated=false, recv_device="/job:localhost/replica:0/task:0/device:GPU:0", send_device="/job:localhost/replica:0/task:0/device:CPU:0", send_device_incarnation=1, tensor_name="edge_13__arg_X_0_0", tensor_type=float, device=GPU:0]()
  n7 = MatMul[T=float, _XlaHasReferenceVars=false, transpose_a=false, transpose_b=false, device=GPU:0](n6, n3)
  n8 = Add[T=float, _XlaHasReferenceVars=false, device=GPU:0](n7, n5)
  n9 = Sigmoid[T=float, _XlaHasReferenceVars=false, device=GPU:0](n8)
  n10 = _Send[T=float, _dst="_retval_Sigmoid_0_0", _src="Sigmoid", client_terminated=false, recv_device="/job:localhost/replica:0/task:0/device:CPU:0", send_device="/job:localhost/replica:0/task:0/device:GPU:0", send_device_incarnation=1, tensor_name="edge_14_Sigmoid", device=GPU:0](n9)
}
 for /job:localhost/replica:0/task:0/device:GPU:0
2023-12-24 16:15:57.897639: I tensorflow/core/common_runtime/direct_session.cc:1731] Created 
(n2:float@CPU:0) -> (n4:float@CPU:0) {
  n4 = _Recv[_dst="_retval_Sigmoid_0_0", _src="Sigmoid", client_terminated=false, recv_device="/job:localhost/replica:0/task:0/device:CPU:0", send_device="/job:localhost/replica:0/task:0/device:GPU:0", send_device_incarnation=1, tensor_name="edge_14_Sigmoid", tensor_type=float, device=CPU:0]()
  n3 = _Send[T=float, _dst="MatMul", _src="_arg_X_0_0", client_terminated=false, recv_device="/job:localhost/replica:0/task:0/device:GPU:0", send_device="/job:localhost/replica:0/task:0/device:CPU:0", send_device_incarnation=1, tensor_name="edge_13__arg_X_0_0", device=CPU:0](n2)
}
 for /job:localhost/replica:0/task:0/device:CPU:0
2023-12-24 16:15:57.897928: I tensorflow/core/common_runtime/function_utils.cc:78] Graph Initial #nodes 11 #edges 13
2023-12-24 16:15:57.897945: I tensorflow/core/common_runtime/function_utils.cc:164] Removing list array converter
2023-12-24 16:15:57.898016: I tensorflow/core/graph/graph.cc:616] AddNode: no type constructor for _SOURCE
2023-12-24 16:15:57.898058: I tensorflow/core/graph/graph.cc:616] AddNode: no type constructor for _SINK
2023-12-24 16:15:57.898174: I tensorflow/core/common_runtime/function_utils.cc:78] Graph ReCopy #nodes 11 #edges 14
2023-12-24 16:15:57.898224: I tensorflow/core/framework/op_kernel.cc:1356] No device-specific kernels found for NodeDef '{{node _SOURCE}}'Will fall back to a default kernel.

2023-12-24 16:15:57.898264: I tensorflow/core/framework/op_kernel.cc:1356] No device-specific kernels found for NodeDef '{{node _SINK}}'Will fall back to a default kernel.

2023-12-24 16:15:57.898323: I tensorflow/core/common_runtime/memory_types.cc:75] out mvec 2 0 0
2023-12-24 16:15:57.898383: I tensorflow/core/common_runtime/memory_types.cc:71] inp mvec 3 0 0
2023-12-24 16:15:57.898394: I tensorflow/core/common_runtime/memory_types.cc:75] out mvec 3 0 0
2023-12-24 16:15:57.898433: I tensorflow/core/common_runtime/memory_types.cc:75] out mvec 4 0 0
2023-12-24 16:15:57.898477: I tensorflow/core/common_runtime/memory_types.cc:71] inp mvec 5 0 0
2023-12-24 16:15:57.898487: I tensorflow/core/common_runtime/memory_types.cc:75] out mvec 5 0 0
2023-12-24 16:15:57.898505: I tensorflow/core/framework/op_kernel.cc:1356] No device-specific kernels found for NodeDef '{{node _arg_X_0_0/_1}}'Will fall back to a default kernel.

2023-12-24 16:15:57.898527: I tensorflow/core/common_runtime/memory_types.cc:75] out mvec 6 0 0
2023-12-24 16:15:57.898563: I tensorflow/core/common_runtime/memory_types.cc:71] inp mvec 7 0 0
2023-12-24 16:15:57.898573: I tensorflow/core/common_runtime/memory_types.cc:71] inp mvec 7 1 0
2023-12-24 16:15:57.898580: I tensorflow/core/common_runtime/memory_types.cc:75] out mvec 7 0 0
2023-12-24 16:15:57.898616: I tensorflow/core/common_runtime/memory_types.cc:71] inp mvec 8 0 0
2023-12-24 16:15:57.898626: I tensorflow/core/common_runtime/memory_types.cc:71] inp mvec 8 1 0
2023-12-24 16:15:57.898633: I tensorflow/core/common_runtime/memory_types.cc:75] out mvec 8 0 0
2023-12-24 16:15:57.898662: I tensorflow/core/common_runtime/memory_types.cc:71] inp mvec 9 0 0
2023-12-24 16:15:57.898673: I tensorflow/core/common_runtime/memory_types.cc:75] out mvec 9 0 0
2023-12-24 16:15:57.898690: I tensorflow/core/framework/op_kernel.cc:1356] No device-specific kernels found for NodeDef '{{node Sigmoid/_2}}'Will fall back to a default kernel.

2023-12-24 16:15:57.898712: I tensorflow/core/common_runtime/memory_types.cc:71] inp mvec 10 0 0
2023-12-24 16:15:57.898726: I tensorflow/core/common_runtime/memory_types.cc:87] 2:0 -> 3:0: 0 -> 0
2023-12-24 16:15:57.898735: I tensorflow/core/common_runtime/memory_types.cc:87] 4:0 -> 5:0: 0 -> 0
2023-12-24 16:15:57.898743: I tensorflow/core/common_runtime/memory_types.cc:87] 6:0 -> 7:0: 0 -> 0
2023-12-24 16:15:57.898751: I tensorflow/core/common_runtime/memory_types.cc:87] 3:0 -> 7:1: 0 -> 0
2023-12-24 16:15:57.898758: I tensorflow/core/common_runtime/memory_types.cc:87] 7:0 -> 8:0: 0 -> 0
2023-12-24 16:15:57.898766: I tensorflow/core/common_runtime/memory_types.cc:87] 5:0 -> 8:1: 0 -> 0
2023-12-24 16:15:57.898773: I tensorflow/core/common_runtime/memory_types.cc:87] 8:0 -> 9:0: 0 -> 0
2023-12-24 16:15:57.898781: I tensorflow/core/common_runtime/memory_types.cc:87] 9:0 -> 10:0: 0 -> 0
2023-12-24 16:15:57.898919: W tensorflow/core/util/dump_graph.cc:134] Failed to dump EnsureMemoryTypes because dump location is not  specified through either TF_DUMP_GRAPH_PREFIX environment variable or function argument.
2023-12-24 16:15:57.898968: I tensorflow/core/common_runtime/memory_types.cc:210] Dumped graph after EnsureMemoryTypes to (failed to create writable file: INVALID_ARGUMENT: TF_DUMP_GRAPH_PREFIX not specified)
2023-12-24 16:15:57.899003: I tensorflow/core/framework/op_kernel.cc:1356] No device-specific kernels found for NodeDef '{{node _SOURCE}}'Will fall back to a default kernel.

2023-12-24 16:15:57.899038: I tensorflow/core/framework/op_kernel.cc:1356] No device-specific kernels found for NodeDef '{{node _SINK}}'Will fall back to a default kernel.

2023-12-24 16:15:57.899091: I tensorflow/core/common_runtime/memory_types.cc:75] out mvec 2 0 0
2023-12-24 16:15:57.899142: I tensorflow/core/common_runtime/memory_types.cc:71] inp mvec 3 0 0
2023-12-24 16:15:57.899152: I tensorflow/core/common_runtime/memory_types.cc:75] out mvec 3 0 0
2023-12-24 16:15:57.899190: I tensorflow/core/common_runtime/memory_types.cc:75] out mvec 4 0 0
2023-12-24 16:15:57.899242: I tensorflow/core/common_runtime/memory_types.cc:71] inp mvec 5 0 0
2023-12-24 16:15:57.899251: I tensorflow/core/common_runtime/memory_types.cc:75] out mvec 5 0 0
2023-12-24 16:15:57.899269: I tensorflow/core/framework/op_kernel.cc:1356] No device-specific kernels found for NodeDef '{{node _arg_X_0_0/_1}}'Will fall back to a default kernel.

2023-12-24 16:15:57.899291: I tensorflow/core/common_runtime/memory_types.cc:75] out mvec 6 0 0
2023-12-24 16:15:57.899327: I tensorflow/core/common_runtime/memory_types.cc:71] inp mvec 7 0 0
2023-12-24 16:15:57.899337: I tensorflow/core/common_runtime/memory_types.cc:71] inp mvec 7 1 0
2023-12-24 16:15:57.899345: I tensorflow/core/common_runtime/memory_types.cc:75] out mvec 7 0 0
2023-12-24 16:15:57.899380: I tensorflow/core/common_runtime/memory_types.cc:71] inp mvec 8 0 0
2023-12-24 16:15:57.899389: I tensorflow/core/common_runtime/memory_types.cc:71] inp mvec 8 1 0
2023-12-24 16:15:57.899397: I tensorflow/core/common_runtime/memory_types.cc:75] out mvec 8 0 0
2023-12-24 16:15:57.899427: I tensorflow/core/common_runtime/memory_types.cc:71] inp mvec 9 0 0
2023-12-24 16:15:57.899437: I tensorflow/core/common_runtime/memory_types.cc:75] out mvec 9 0 0
2023-12-24 16:15:57.899454: I tensorflow/core/framework/op_kernel.cc:1356] No device-specific kernels found for NodeDef '{{node Sigmoid/_2}}'Will fall back to a default kernel.

2023-12-24 16:15:57.899476: I tensorflow/core/common_runtime/memory_types.cc:71] inp mvec 10 0 0
2023-12-24 16:15:57.899489: I tensorflow/core/common_runtime/memory_types.cc:87] 2:0 -> 3:0: 0 -> 0
2023-12-24 16:15:57.899498: I tensorflow/core/common_runtime/memory_types.cc:87] 4:0 -> 5:0: 0 -> 0
2023-12-24 16:15:57.899506: I tensorflow/core/common_runtime/memory_types.cc:87] 6:0 -> 7:0: 0 -> 0
2023-12-24 16:15:57.899514: I tensorflow/core/common_runtime/memory_types.cc:87] 3:0 -> 7:1: 0 -> 0
2023-12-24 16:15:57.899522: I tensorflow/core/common_runtime/memory_types.cc:87] 7:0 -> 8:0: 0 -> 0
2023-12-24 16:15:57.899529: I tensorflow/core/common_runtime/memory_types.cc:87] 5:0 -> 8:1: 0 -> 0
2023-12-24 16:15:57.899537: I tensorflow/core/common_runtime/memory_types.cc:87] 8:0 -> 9:0: 0 -> 0
2023-12-24 16:15:57.899544: I tensorflow/core/common_runtime/memory_types.cc:87] 9:0 -> 10:0: 0 -> 0
2023-12-24 16:15:57.899896: I tensorflow/core/framework/op_kernel.cc:1604] Instantiating kernel for node: {{node _SOURCE}} = NoOp[]()
2023-12-24 16:15:57.899935: I tensorflow/core/framework/op_kernel.cc:1356] No device-specific kernels found for NodeDef '{{node _SOURCE}}'Will fall back to a default kernel.

2023-12-24 16:15:57.899953: I tensorflow/core/framework/op_kernel.cc:1356] No device-specific kernels found for NodeDef '{{node _SOURCE}}'Will fall back to a default kernel.

2023-12-24 16:15:57.900104: I tensorflow/core/framework/log_memory.cc:34] __LOG_MEMORY__ MemoryLogTensorAllocation { step_id: -6 kernel_name: "Unknown (from Proto)" tensor { dtype: DT_FLOAT shape { dim { size: 5 } dim { size: 7 } } allocation_description { requested_bytes: 140 allocated_bytes: 140 allocator_name: "mklcpu" allocation_id: 4 has_single_reference: true ptr: 94069282909568 } } }
2023-12-24 16:15:57.900147: I tensorflow/core/framework/log_memory.cc:34] __LOG_MEMORY__ MemoryLogTensorDeallocation { allocation_id: 4 allocator_name: "mklcpu" }
2023-12-24 16:15:57.900168: I tensorflow/core/framework/op_kernel.cc:1604] Instantiating kernel for node: {{node Weight}} = Const[_XlaHasReferenceVars=false, dtype=DT_FLOAT, value=Tensor<type: float shape: [5,7] values: [0.0188236237 -0.0105859637 0.016250791...]...>, _device="/job:localhost/replica:0/task:0/device:GPU:0"]()
2023-12-24 16:15:57.900363: I tensorflow/core/common_runtime/bfc_allocator.cc:260] AllocateRaw gpu_host_bfc  140
2023-12-24 16:15:57.900389: I tensorflow/stream_executor/cuda/cuda_driver.cc:151] ScopedActivateContext switching to 1
2023-12-24 16:15:57.902090: I tensorflow/stream_executor/stream_executor_pimpl.cc:577] Called StreamExecutor::HostMemoryAllocate(size=2097152) returns 0x7f2c9e000000
2023-12-24 16:15:57.902113: I tensorflow/core/common_runtime/bfc_allocator.cc:157] Extending allocation by 2.00MiB bytes for gpu_host_bfc.
2023-12-24 16:15:57.902121: I tensorflow/core/common_runtime/bfc_allocator.cc:162] Total allocated bytes: 2.00MiB
2023-12-24 16:15:57.902128: I tensorflow/core/common_runtime/bfc_allocator.cc:165] Allocated memory at 0x7f2c9e000000 to 0x7f2c9e200000
2023-12-24 16:15:57.902213: I tensorflow/core/common_runtime/bfc_allocator.cc:593] New Peak memory usage of 256 bytes for gpu_host_bfc
2023-12-24 16:15:57.902223: I tensorflow/core/common_runtime/bfc_allocator.cc:307] AllocateRaw gpu_host_bfc  140 0x7f2c9e000000
2023-12-24 16:15:57.902267: I tensorflow/core/framework/log_memory.cc:34] __LOG_MEMORY__ MemoryLogTensorAllocation { step_id: -6 kernel_name: "Unknown (from Proto)" tensor { dtype: DT_FLOAT shape { dim { size: 5 } dim { size: 7 } } allocation_description { requested_bytes: 140 allocated_bytes: 256 allocator_name: "gpu_host_bfc" allocation_id: 1 has_single_reference: true ptr: 139829606088704 } } }
2023-12-24 16:15:57.902292: I tensorflow/core/common_runtime/bfc_allocator.cc:260] AllocateRaw GPU_0_bfc  140
2023-12-24 16:15:57.902305: I tensorflow/stream_executor/cuda/cuda_driver.cc:151] ScopedActivateContext switching to 1
2023-12-24 16:15:57.902827: I tensorflow/stream_executor/cuda/cuda_driver.cc:745] allocated 0x7f2c9e200000 for context 0x558e09f8ebb0 of 2097152 bytes
2023-12-24 16:15:57.902843: I tensorflow/stream_executor/stream_executor_pimpl.cc:530] Called StreamExecutor::Allocate(size=2097152, memory_space=0) returns 0x7f2c9e200000
2023-12-24 16:15:57.902854: I tensorflow/core/common_runtime/bfc_allocator.cc:157] Extending allocation by 2.00MiB bytes for GPU_0_bfc.
2023-12-24 16:15:57.902861: I tensorflow/core/common_runtime/bfc_allocator.cc:162] Total allocated bytes: 2.00MiB
2023-12-24 16:15:57.902868: I tensorflow/core/common_runtime/bfc_allocator.cc:165] Allocated memory at 0x7f2c9e200000 to 0x7f2c9e400000
2023-12-24 16:15:57.902918: I tensorflow/core/common_runtime/bfc_allocator.cc:593] New Peak memory usage of 256 bytes for GPU_0_bfc
2023-12-24 16:15:57.902928: I tensorflow/core/common_runtime/bfc_allocator.cc:307] AllocateRaw GPU_0_bfc  140 0x7f2c9e200000
2023-12-24 16:15:57.902964: I tensorflow/core/framework/log_memory.cc:34] __LOG_MEMORY__ MemoryLogTensorAllocation { step_id: -6 kernel_name: "Unknown (with attributes)" tensor { dtype: DT_FLOAT shape { dim { size: 5 } dim { size: 7 } } allocation_description { requested_bytes: 140 allocated_bytes: 256 allocator_name: "GPU_0_bfc" allocation_id: 1 has_single_reference: true ptr: 139829608185856 } } }
2023-12-24 16:15:57.902988: I tensorflow/core/common_runtime/gpu/gpu_util.cc:315] CopyCPUTensorToGPU
2023-12-24 16:15:57.903014: I tensorflow/stream_executor/stream.cc:1202] [stream=0x558e2617ff20,impl=0x558e0bbead30] Called Stream::ThenWaitFor(other=0x558e0bbeba30)
2023-12-24 16:15:57.903026: I tensorflow/stream_executor/cuda/cuda_driver.cc:151] ScopedActivateContext switching to 1
2023-12-24 16:15:57.903042: I tensorflow/stream_executor/cuda/cuda_driver.cc:151] ScopedActivateContext switching to 1
2023-12-24 16:15:57.903063: I tensorflow/stream_executor/stream.cc:4037] [stream=0x558e2617ff20,impl=0x558e0bbead30] Called Stream::ThenMemcpy(gpu_dst=0x7f2c9e200000, host_src=0x7f2c9e000000, size=140)
2023-12-24 16:15:57.903072: I tensorflow/stream_executor/cuda/cuda_driver.cc:151] ScopedActivateContext switching to 1
2023-12-24 16:15:57.903100: I tensorflow/stream_executor/cuda/cuda_driver.cc:1189] successfully enqueued async memcpy h2d of 140 bytes on stream 0x558e2e542dd0
2023-12-24 16:15:57.903116: I tensorflow/core/common_runtime/device/device_event_mgr.cc:170] QueueInUse  free_events_ 0 used_events_ 0
2023-12-24 16:15:57.903142: I tensorflow/stream_executor/cuda/cuda_driver.cc:151] ScopedActivateContext switching to 1
2023-12-24 16:15:57.903155: I tensorflow/stream_executor/stream.cc:330] [stream=0x558e2617ff20,impl=0x558e0bbead30] Called Stream::ThenRecordEvent(event=0x558e36311dd0)
2023-12-24 16:15:57.903162: I tensorflow/stream_executor/cuda/cuda_driver.cc:151] ScopedActivateContext switching to 1
2023-12-24 16:15:57.903176: I tensorflow/core/common_runtime/device/device_event_mgr.cc:208] PollEvents  free_events_ 0 used_events_ 1
2023-12-24 16:15:57.903185: I tensorflow/stream_executor/cuda/cuda_driver.cc:151] ScopedActivateContext switching to 1
2023-12-24 16:15:57.903252: I tensorflow/core/common_runtime/device/device_event_mgr.cc:208] PollEvents  free_events_ 1 used_events_ 0
2023-12-24 16:15:57.903303: I tensorflow/core/framework/log_memory.cc:34] __LOG_MEMORY__ MemoryLogTensorDeallocation { allocation_id: 1 allocator_name: "gpu_host_bfc" }
2023-12-24 16:15:57.903316: I tensorflow/core/common_runtime/bfc_allocator.cc:673] DeallocateRaw gpu_host_bfc 140
2023-12-24 16:15:57.903433: I tensorflow/core/framework/op_kernel.cc:1604] Instantiating kernel for node: {{node Weight/read}} = Identity[T=DT_FLOAT, _XlaHasReferenceVars=false, _class=["loc:@Weight"], _device="/job:localhost/replica:0/task:0/device:GPU:0"](Weight)
2023-12-24 16:15:57.903671: I tensorflow/core/framework/log_memory.cc:34] __LOG_MEMORY__ MemoryLogTensorAllocation { step_id: -6 kernel_name: "Unknown (from Proto)" tensor { dtype: DT_FLOAT shape { dim { size: 7 } } allocation_description { requested_bytes: 28 allocated_bytes: 28 allocator_name: "mklcpu" allocation_id: 5 has_single_reference: true ptr: 94069282971968 } } }
2023-12-24 16:15:57.903713: I tensorflow/core/framework/log_memory.cc:34] __LOG_MEMORY__ MemoryLogTensorDeallocation { allocation_id: 5 allocator_name: "mklcpu" }
2023-12-24 16:15:57.903744: I tensorflow/core/framework/op_kernel.cc:1604] Instantiating kernel for node: {{node Bias}} = Const[_XlaHasReferenceVars=false, dtype=DT_FLOAT, value=Tensor<type: float shape: [7] values: 0 0 0...>, _device="/job:localhost/replica:0/task:0/device:GPU:0"]()
2023-12-24 16:15:57.903936: I tensorflow/core/common_runtime/bfc_allocator.cc:260] AllocateRaw gpu_host_bfc  28
2023-12-24 16:15:57.903963: I tensorflow/core/common_runtime/bfc_allocator.cc:307] AllocateRaw gpu_host_bfc  28 0x7f2c9e000000
2023-12-24 16:15:57.903998: I tensorflow/core/framework/log_memory.cc:34] __LOG_MEMORY__ MemoryLogTensorAllocation { step_id: -6 kernel_name: "Unknown (from Proto)" tensor { dtype: DT_FLOAT shape { dim { size: 7 } } allocation_description { requested_bytes: 28 allocated_bytes: 256 allocator_name: "gpu_host_bfc" allocation_id: 2 has_single_reference: true ptr: 139829606088704 } } }
2023-12-24 16:15:57.904016: I tensorflow/core/common_runtime/bfc_allocator.cc:260] AllocateRaw GPU_0_bfc  28
2023-12-24 16:15:57.904031: I tensorflow/core/common_runtime/bfc_allocator.cc:593] New Peak memory usage of 512 bytes for GPU_0_bfc
2023-12-24 16:15:57.904039: I tensorflow/core/common_runtime/bfc_allocator.cc:307] AllocateRaw GPU_0_bfc  28 0x7f2c9e200100
2023-12-24 16:15:57.904064: I tensorflow/core/framework/log_memory.cc:34] __LOG_MEMORY__ MemoryLogTensorAllocation { step_id: -6 kernel_name: "Unknown (with attributes)" tensor { dtype: DT_FLOAT shape { dim { size: 7 } } allocation_description { requested_bytes: 28 allocated_bytes: 256 allocator_name: "GPU_0_bfc" allocation_id: 2 has_single_reference: true ptr: 139829608186112 } } }
2023-12-24 16:15:57.904083: I tensorflow/core/common_runtime/gpu/gpu_util.cc:315] CopyCPUTensorToGPU
2023-12-24 16:15:57.904105: I tensorflow/stream_executor/stream.cc:1202] [stream=0x558e2617ff20,impl=0x558e0bbead30] Called Stream::ThenWaitFor(other=0x558e0bbeba30)
2023-12-24 16:15:57.904121: I tensorflow/stream_executor/cuda/cuda_driver.cc:151] ScopedActivateContext switching to 1
2023-12-24 16:15:57.904139: I tensorflow/stream_executor/cuda/cuda_driver.cc:151] ScopedActivateContext switching to 1
2023-12-24 16:15:57.904160: I tensorflow/stream_executor/stream.cc:4037] [stream=0x558e2617ff20,impl=0x558e0bbead30] Called Stream::ThenMemcpy(gpu_dst=0x7f2c9e200100, host_src=0x7f2c9e000000, size=28)
2023-12-24 16:15:57.904169: I tensorflow/stream_executor/cuda/cuda_driver.cc:151] ScopedActivateContext switching to 1
2023-12-24 16:15:57.904192: I tensorflow/stream_executor/cuda/cuda_driver.cc:1189] successfully enqueued async memcpy h2d of 28 bytes on stream 0x558e2e542dd0
2023-12-24 16:15:57.904210: I tensorflow/core/common_runtime/device/device_event_mgr.cc:170] QueueInUse  free_events_ 1 used_events_ 0
2023-12-24 16:15:57.904226: I tensorflow/stream_executor/stream.cc:330] [stream=0x558e2617ff20,impl=0x558e0bbead30] Called Stream::ThenRecordEvent(event=0x558e36311dd0)
2023-12-24 16:15:57.904235: I tensorflow/stream_executor/cuda/cuda_driver.cc:151] ScopedActivateContext switching to 1
2023-12-24 16:15:57.904247: I tensorflow/core/common_runtime/device/device_event_mgr.cc:208] PollEvents  free_events_ 0 used_events_ 1
2023-12-24 16:15:57.904256: I tensorflow/stream_executor/cuda/cuda_driver.cc:151] ScopedActivateContext switching to 1
2023-12-24 16:15:57.904293: I tensorflow/core/common_runtime/device/device_event_mgr.cc:208] PollEvents  free_events_ 1 used_events_ 0
2023-12-24 16:15:57.904321: I tensorflow/core/framework/log_memory.cc:34] __LOG_MEMORY__ MemoryLogTensorDeallocation { allocation_id: 2 allocator_name: "gpu_host_bfc" }
2023-12-24 16:15:57.904337: I tensorflow/core/common_runtime/bfc_allocator.cc:673] DeallocateRaw gpu_host_bfc 28
2023-12-24 16:15:57.904454: I tensorflow/core/framework/op_kernel.cc:1604] Instantiating kernel for node: {{node Bias/read}} = Identity[T=DT_FLOAT, _XlaHasReferenceVars=false, _class=["loc:@Bias"], _device="/job:localhost/replica:0/task:0/device:GPU:0"](Bias)
2023-12-24 16:15:57.904728: I tensorflow/core/framework/op_kernel.cc:1604] Instantiating kernel for node: {{node _arg_X_0_0/_1}} = _Recv[_dst="MatMul", _src="_arg_X_0_0", client_terminated=false, recv_device="/job:localhost/replica:0/task:0/device:GPU:0", send_device="/job:localhost/replica:0/task:0/device:CPU:0", send_device_incarnation=1, tensor_name="edge_13__arg_X_0_0", tensor_type=DT_FLOAT, _device="/job:localhost/replica:0/task:0/device:GPU:0"]()
2023-12-24 16:15:57.904794: I tensorflow/core/framework/op_kernel.cc:1356] No device-specific kernels found for NodeDef '{{node _arg_X_0_0/_1}}'Will fall back to a default kernel.

2023-12-24 16:15:57.904814: I tensorflow/core/framework/op_kernel.cc:1356] No device-specific kernels found for NodeDef '{{node _arg_X_0_0/_1}}'Will fall back to a default kernel.

2023-12-24 16:15:57.904979: I tensorflow/core/framework/op_kernel.cc:1604] Instantiating kernel for node: {{node MatMul}} = MatMul[T=DT_FLOAT, _XlaHasReferenceVars=false, transpose_a=false, transpose_b=false, _device="/job:localhost/replica:0/task:0/device:GPU:0"](_arg_X_0_0/_1, Weight/read)
2023-12-24 16:15:57.905137: I tensorflow/core/framework/op_kernel.cc:1604] Instantiating kernel for node: {{node Add}} = Add[T=DT_FLOAT, _XlaHasReferenceVars=false, _device="/job:localhost/replica:0/task:0/device:GPU:0"](MatMul, Bias/read)
2023-12-24 16:15:57.905280: I tensorflow/core/framework/op_kernel.cc:1604] Instantiating kernel for node: {{node Sigmoid}} = Sigmoid[T=DT_FLOAT, _XlaHasReferenceVars=false, _device="/job:localhost/replica:0/task:0/device:GPU:0"](Add)
2023-12-24 16:15:57.905420: I tensorflow/core/framework/op_kernel.cc:1604] Instantiating kernel for node: {{node Sigmoid/_2}} = _Send[T=DT_FLOAT, _dst="_retval_Sigmoid_0_0", _src="Sigmoid", client_terminated=false, recv_device="/job:localhost/replica:0/task:0/device:CPU:0", send_device="/job:localhost/replica:0/task:0/device:GPU:0", send_device_incarnation=1, tensor_name="edge_14_Sigmoid", _device="/job:localhost/replica:0/task:0/device:GPU:0"](Sigmoid)
2023-12-24 16:15:57.905479: I tensorflow/core/framework/op_kernel.cc:1356] No device-specific kernels found for NodeDef '{{node Sigmoid/_2}}'Will fall back to a default kernel.

2023-12-24 16:15:57.905498: I tensorflow/core/framework/op_kernel.cc:1356] No device-specific kernels found for NodeDef '{{node Sigmoid/_2}}'Will fall back to a default kernel.

2023-12-24 16:15:57.905645: I tensorflow/core/common_runtime/graph_view.cc:381] default alloc case local type GPU remote type CPU
2023-12-24 16:15:57.905669: I tensorflow/core/common_runtime/graph_view.cc:408] default alloc case local type GPU remote type CPU
2023-12-24 16:15:57.905782: I tensorflow/core/common_runtime/function_utils.cc:78] Graph Initial #nodes 6 #edges 7
2023-12-24 16:15:57.905793: I tensorflow/core/common_runtime/function_utils.cc:164] Removing list array converter
2023-12-24 16:15:57.905887: I tensorflow/core/graph/graph.cc:616] AddNode: no type constructor for _SOURCE
2023-12-24 16:15:57.905953: I tensorflow/core/graph/graph.cc:616] AddNode: no type constructor for _SINK
2023-12-24 16:15:57.906091: I tensorflow/core/common_runtime/function_utils.cc:78] Graph ReCopy #nodes 6 #edges 8
2023-12-24 16:15:57.906226: W tensorflow/core/util/dump_graph.cc:134] Failed to dump EnsureMemoryTypes because dump location is not  specified through either TF_DUMP_GRAPH_PREFIX environment variable or function argument.
2023-12-24 16:15:57.906267: I tensorflow/core/common_runtime/memory_types.cc:210] Dumped graph after EnsureMemoryTypes to (failed to create writable file: INVALID_ARGUMENT: TF_DUMP_GRAPH_PREFIX not specified)
2023-12-24 16:15:57.906525: I tensorflow/core/framework/op_kernel.cc:1604] Instantiating kernel for node: {{node _SOURCE}} = NoOp[]()
2023-12-24 16:15:57.906563: I tensorflow/core/framework/op_kernel.cc:1356] No device-specific kernels found for NodeDef '{{node _SOURCE}}'Will fall back to a default kernel.

2023-12-24 16:15:57.906581: I tensorflow/core/framework/op_kernel.cc:1356] No device-specific kernels found for NodeDef '{{node _SOURCE}}'Will fall back to a default kernel.

2023-12-24 16:15:57.906670: I tensorflow/core/framework/op_kernel.cc:1604] Instantiating kernel for node: {{node _arg_X_0_0}} = _Arg[T=DT_FLOAT, _XlaHasReferenceVars=false, index=0, _device="/job:localhost/replica:0/task:0/device:CPU:0"]()
2023-12-24 16:15:57.906817: I tensorflow/core/framework/op_kernel.cc:1604] Instantiating kernel for node: {{node _arg_X_0_0/_0}} = _Send[T=DT_FLOAT, _dst="MatMul", _src="_arg_X_0_0", client_terminated=false, recv_device="/job:localhost/replica:0/task:0/device:GPU:0", send_device="/job:localhost/replica:0/task:0/device:CPU:0", send_device_incarnation=1, tensor_name="edge_13__arg_X_0_0", _device="/job:localhost/replica:0/task:0/device:CPU:0"](_arg_X_0_0)
2023-12-24 16:15:57.906996: I tensorflow/core/framework/op_kernel.cc:1604] Instantiating kernel for node: {{node Sigmoid/_3}} = _Recv[_dst="_retval_Sigmoid_0_0", _src="Sigmoid", client_terminated=false, recv_device="/job:localhost/replica:0/task:0/device:CPU:0", send_device="/job:localhost/replica:0/task:0/device:GPU:0", send_device_incarnation=1, tensor_name="edge_14_Sigmoid", tensor_type=DT_FLOAT, _device="/job:localhost/replica:0/task:0/device:CPU:0"]()
2023-12-24 16:15:57.907155: I tensorflow/core/framework/op_kernel.cc:1604] Instantiating kernel for node: {{node _retval_Sigmoid_0_0}} = _Retval[T=DT_FLOAT, _XlaHasReferenceVars=false, index=0, _device="/job:localhost/replica:0/task:0/device:CPU:0"](Sigmoid/_3)
2023-12-24 16:15:57.907299: I tensorflow/core/common_runtime/graph_view.cc:406] node _arg_X_0_0 is the source of a cpu->gpu copy
2023-12-24 16:15:57.907326: I tensorflow/core/common_runtime/graph_view.cc:379] node Sigmoid/_3 is the sink of a gpu->cpu copy
2023-12-24 16:15:57.907507: I tensorflow/core/framework/log_memory.cc:34] __LOG_MEMORY__ MemoryLogStep { step_id: 1 handle: "X:0->Sigmoid:0//0/;0" }
2023-12-24 16:15:57.907794: I tensorflow/core/common_runtime/executor.cc:783] Process node: 0 step 1 {{node _SOURCE}} = NoOp[]() device: /job:localhost/replica:0/task:0/device:CPU:0
2023-12-24 16:15:57.907828: I tensorflow/core/common_runtime/executor.cc:783] Process node: 0 step 1 {{node _SOURCE}} = NoOp[]() device: /job:localhost/replica:0/task:0/device:GPU:0
2023-12-24 16:15:57.907858: I tensorflow/core/common_runtime/executor.cc:836] Synchronous kernel done: 0 step 1 {{node _SOURCE}} = NoOp[]() device: /job:localhost/replica:0/task:0/device:CPU:0
2023-12-24 16:15:57.907870: I tensorflow/core/common_runtime/executor.cc:836] Synchronous kernel done: 0 step 1 {{node _SOURCE}} = NoOp[]() device: /job:localhost/replica:0/task:0/device:GPU:0
2023-12-24 16:15:57.907906: I tensorflow/core/common_runtime/executor.cc:783] Process node: 2 step 1 {{node Weight}} = Const[dtype=DT_FLOAT, _device="/job:localhost/replica:0/task:0/device:GPU:0"]() device: /job:localhost/replica:0/task:0/device:GPU:0
2023-12-24 16:15:57.907921: I tensorflow/core/common_runtime/executor.cc:836] Synchronous kernel done: 2 step 1 {{node Weight}} = Const[dtype=DT_FLOAT, _device="/job:localhost/replica:0/task:0/device:GPU:0"]() device: /job:localhost/replica:0/task:0/device:GPU:0
2023-12-24 16:15:57.907928: I tensorflow/core/common_runtime/executor.cc:783] Process node: 2 step 1 {{node _arg_X_0_0}} = _Arg[T=DT_FLOAT, _XlaHasReferenceVars=false, index=0, _device="/job:localhost/replica:0/task:0/device:CPU:0"]() device: /job:localhost/replica:0/task:0/device:CPU:0
2023-12-24 16:15:57.907938: I tensorflow/core/common_runtime/executor.cc:783] Process node: 4 step 1 {{node Bias}} = Const[dtype=DT_FLOAT, _device="/job:localhost/replica:0/task:0/device:GPU:0"]() device: /job:localhost/replica:0/task:0/device:GPU:0
2023-12-24 16:15:57.907950: I tensorflow/core/common_runtime/executor.cc:836] Synchronous kernel done: 4 step 1 {{node Bias}} = Const[dtype=DT_FLOAT, _device="/job:localhost/replica:0/task:0/device:GPU:0"]() device: /job:localhost/replica:0/task:0/device:GPU:0
2023-12-24 16:15:57.907981: I tensorflow/core/common_runtime/executor.cc:783] Process node: 4 step 1 {{node Sigmoid/_3}} = _Recv[_dst="_retval_Sigmoid_0_0", _src="Sigmoid", client_terminated=false, recv_device="/job:localhost/replica:0/task:0/device:CPU:0", send_device="/job:localhost/replica:0/task:0/device:GPU:0", send_device_incarnation=1, tensor_name="edge_14_Sigmoid", tensor_type=DT_FLOAT, _device="/job:localhost/replica:0/task:0/device:CPU:0"]() device: /job:localhost/replica:0/task:0/device:CPU:0
2023-12-24 16:15:57.908006: I tensorflow/core/common_runtime/executor.cc:783] Process node: 6 step 1 {{node _arg_X_0_0/_1}} = _Recv[_dst="MatMul", _src="_arg_X_0_0", client_terminated=false, recv_device="/job:localhost/replica:0/task:0/device:GPU:0", send_device="/job:localhost/replica:0/task:0/device:CPU:0", send_device_incarnation=1, tensor_name="edge_13__arg_X_0_0", tensor_type=DT_FLOAT, _device="/job:localhost/replica:0/task:0/device:GPU:0"]() device: /job:localhost/replica:0/task:0/device:GPU:0
2023-12-24 16:15:57.908033: I tensorflow/core/kernels/sendrecv_ops.cc:203] Recv /job:localhost/replica:0/task:0/device:GPU:0;0000000000000001;/job:localhost/replica:0/task:0/device:CPU:0;edge_14_Sigmoid;0:0 using 94069282906000
2023-12-24 16:15:57.908043: I tensorflow/core/framework/log_memory.cc:34] __LOG_MEMORY__ MemoryLogTensorOutput { step_id: 1 kernel_name: "_arg_X_0_0" tensor { dtype: DT_FLOAT shape { dim { size: 3 } dim { size: 5 } } allocation_description { requested_bytes: 60 allocated_bytes: 60 allocator_name: "mklcpu" allocation_id: 1 ptr: 94068540294144 } } }
2023-12-24 16:15:57.908060: I tensorflow/core/common_runtime/bfc_allocator.cc:260] AllocateRaw GPU_0_bfc  1028
2023-12-24 16:15:57.908075: I tensorflow/core/common_runtime/rendezvous_mgr.cc:174] IntraProcessRendezvous Recv 0x558e36311f90 /job:localhost/replica:0/task:0/device:GPU:0;0000000000000001;/job:localhost/replica:0/task:0/device:CPU:0;edge_14_Sigmoid;0:0
2023-12-24 16:15:57.908083: I tensorflow/core/common_runtime/executor.cc:836] Synchronous kernel done: 2 step 1 {{node _arg_X_0_0}} = _Arg[T=DT_FLOAT, _XlaHasReferenceVars=false, index=0, _device="/job:localhost/replica:0/task:0/device:CPU:0"]() device: /job:localhost/replica:0/task:0/device:CPU:0
2023-12-24 16:15:57.908094: I tensorflow/core/common_runtime/bfc_allocator.cc:593] New Peak memory usage of 1792 bytes for GPU_0_bfc
2023-12-24 16:15:57.908104: I tensorflow/core/common_runtime/rendezvous_mgr.cc:125] IntraProcessRendezvous Recv 0x558e36311fb0 /job:localhost/replica:0/task:0/device:GPU:0;0000000000000001;/job:localhost/replica:0/task:0/device:CPU:0;edge_14_Sigmoid;0:0
2023-12-24 16:15:57.908116: I tensorflow/core/common_runtime/bfc_allocator.cc:307] AllocateRaw GPU_0_bfc  1028 0x7f2c9e200200
2023-12-24 16:15:57.908127: I tensorflow/core/common_runtime/executor.cc:783] Process node: 3 step 1 {{node _arg_X_0_0/_0}} = _Send[T=DT_FLOAT, _dst="MatMul", _src="_arg_X_0_0", client_terminated=false, recv_device="/job:localhost/replica:0/task:0/device:GPU:0", send_device="/job:localhost/replica:0/task:0/device:CPU:0", send_device_incarnation=1, tensor_name="edge_13__arg_X_0_0", _device="/job:localhost/replica:0/task:0/device:CPU:0"](_arg_X_0_0) device: /job:localhost/replica:0/task:0/device:CPU:0
2023-12-24 16:15:57.908139: I tensorflow/stream_executor/stream_executor_pimpl.cc:619] Called StreamExecutor::SynchronousMemZero(location=0x7f2cbaff5b80, size=1028)
2023-12-24 16:15:57.908151: I tensorflow/core/kernels/sendrecv_ops.cc:96] Send /job:localhost/replica:0/task:0/device:CPU:0;0000000000000001;/job:localhost/replica:0/task:0/device:GPU:0;edge_13__arg_X_0_0;0:0 using 94069282906000
2023-12-24 16:15:57.908164: I tensorflow/stream_executor/cuda/cuda_driver.cc:151] ScopedActivateContext switching to 1
2023-12-24 16:15:57.908173: I tensorflow/core/common_runtime/rendezvous_mgr.cc:167] IntraProcessRendezvous Send 0x558e36311f90 /job:localhost/replica:0/task:0/device:CPU:0;0000000000000001;/job:localhost/replica:0/task:0/device:GPU:0;edge_13__arg_X_0_0;0:0
2023-12-24 16:15:57.908213: I tensorflow/core/common_runtime/executor.cc:836] Synchronous kernel done: 3 step 1 {{node _arg_X_0_0/_0}} = _Send[T=DT_FLOAT, _dst="MatMul", _src="_arg_X_0_0", client_terminated=false, recv_device="/job:localhost/replica:0/task:0/device:GPU:0", send_device="/job:localhost/replica:0/task:0/device:CPU:0", send_device_incarnation=1, tensor_name="edge_13__arg_X_0_0", _device="/job:localhost/replica:0/task:0/device:CPU:0"](_arg_X_0_0) device: /job:localhost/replica:0/task:0/device:CPU:0
2023-12-24 16:15:57.909369: I tensorflow/core/common_runtime/gpu/gpu_device.cc:748] GpuDevice::ComputeAsync _arg_X_0_0/_1 op _Recv on GPU0 stream[0]
2023-12-24 16:15:57.909393: I tensorflow/stream_executor/cuda/cuda_driver.cc:151] ScopedActivateContext switching to 1
2023-12-24 16:15:57.909403: I tensorflow/core/kernels/sendrecv_ops.cc:203] Recv /job:localhost/replica:0/task:0/device:CPU:0;0000000000000001;/job:localhost/replica:0/task:0/device:GPU:0;edge_13__arg_X_0_0;0:0 using 94069282906000
2023-12-24 16:15:57.909412: I tensorflow/core/common_runtime/rendezvous_mgr.cc:174] IntraProcessRendezvous Recv 0x558e36311f90 /job:localhost/replica:0/task:0/device:CPU:0;0000000000000001;/job:localhost/replica:0/task:0/device:GPU:0;edge_13__arg_X_0_0;0:0
2023-12-24 16:15:57.909420: I tensorflow/core/common_runtime/rendezvous_mgr.cc:125] IntraProcessRendezvous Recv 0x558e36311fb0 /job:localhost/replica:0/task:0/device:CPU:0;0000000000000001;/job:localhost/replica:0/task:0/device:GPU:0;edge_13__arg_X_0_0;0:0
2023-12-24 16:15:57.909457: I tensorflow/core/common_runtime/bfc_allocator.cc:260] AllocateRaw GPU_0_bfc  60
2023-12-24 16:15:57.909485: I tensorflow/core/common_runtime/bfc_allocator.cc:593] New Peak memory usage of 2048 bytes for GPU_0_bfc
2023-12-24 16:15:57.909494: I tensorflow/core/common_runtime/bfc_allocator.cc:307] AllocateRaw GPU_0_bfc  60 0x7f2c9e200700
2023-12-24 16:15:57.909545: I tensorflow/core/framework/log_memory.cc:34] __LOG_MEMORY__ MemoryLogTensorAllocation { step_id: -6 kernel_name: "Unknown (with attributes)" tensor { dtype: DT_FLOAT shape { dim { size: 3 } dim { size: 5 } } allocation_description { requested_bytes: 60 allocated_bytes: 256 allocator_name: "GPU_0_bfc" allocation_id: 4 has_single_reference: true ptr: 139829608187648 } } }
2023-12-24 16:15:57.909562: I tensorflow/core/common_runtime/copy_tensor.cc:211] Copy edge_13__arg_X_0_0
2023-12-24 16:15:57.909578: I tensorflow/core/common_runtime/gpu/gpu_util.cc:315] CopyCPUTensorToGPU
2023-12-24 16:15:57.909597: I tensorflow/stream_executor/stream.cc:1202] [stream=0x558e2617ff20,impl=0x558e0bbead30] Called Stream::ThenWaitFor(other=0x558e0bbeba30)
2023-12-24 16:15:57.909626: I tensorflow/stream_executor/stream.cc:4037] [stream=0x558e2617ff20,impl=0x558e0bbead30] Called Stream::ThenMemcpy(gpu_dst=0x7f2c9e200700, host_src=0x558e09edc400, size=60)
2023-12-24 16:15:57.909654: I tensorflow/stream_executor/cuda/cuda_driver.cc:1189] successfully enqueued async memcpy h2d of 60 bytes on stream 0x558e2e542dd0
2023-12-24 16:15:57.909665: I tensorflow/core/common_runtime/device/device_event_mgr.cc:170] QueueInUse  free_events_ 1 used_events_ 0
2023-12-24 16:15:57.909678: I tensorflow/stream_executor/stream.cc:330] [stream=0x558e2617ff20,impl=0x558e0bbead30] Called Stream::ThenRecordEvent(event=0x558e36311dd0)
2023-12-24 16:15:57.909694: I tensorflow/core/common_runtime/device/device_event_mgr.cc:208] PollEvents  free_events_ 0 used_events_ 1
2023-12-24 16:15:57.909730: I tensorflow/core/common_runtime/device/device_event_mgr.cc:208] PollEvents  free_events_ 1 used_events_ 0
2023-12-24 16:15:57.909775: I tensorflow/core/common_runtime/executor.cc:783] Process node: 3 step 1 {{node Weight/read}} = Identity[T=DT_FLOAT, _XlaHasReferenceVars=false, _class=["loc:@Weight"], _device="/job:localhost/replica:0/task:0/device:GPU:0"](Weight) device: /job:localhost/replica:0/task:0/device:GPU:0
2023-12-24 16:15:57.909806: I tensorflow/core/framework/log_memory.cc:34] __LOG_MEMORY__ MemoryLogTensorOutput { step_id: 1 kernel_name: "_arg_X_0_0/_1" tensor { dtype: DT_FLOAT shape { dim { size: 3 } dim { size: 5 } } allocation_description { requested_bytes: 60 allocated_bytes: 256 allocator_name: "GPU_0_bfc" allocation_id: 4 ptr: 139829608187648 } } }
2023-12-24 16:15:57.909828: I tensorflow/core/common_runtime/gpu/gpu_device.cc:660] GpuDevice::ComputeHelper Weight/read op Identity on GPU 0 stream[0]
2023-12-24 16:15:57.909840: I tensorflow/stream_executor/cuda/cuda_driver.cc:151] ScopedActivateContext switching to 1
2023-12-24 16:15:57.909862: I tensorflow/core/common_runtime/gpu/gpu_device.cc:697] GpuDevice::ComputeHelper scheduled Weight/read op Identity on GPU 0 stream[0]
2023-12-24 16:15:57.909874: I tensorflow/core/common_runtime/executor.cc:626] Async kernel done: 6 step 1 {{node _arg_X_0_0/_1}} = _Recv[_dst="MatMul", _src="_arg_X_0_0", client_terminated=false, recv_device="/job:localhost/replica:0/task:0/device:GPU:0", send_device="/job:localhost/replica:0/task:0/device:CPU:0", send_device_incarnation=1, tensor_name="edge_13__arg_X_0_0", tensor_type=DT_FLOAT, _device="/job:localhost/replica:0/task:0/device:GPU:0"]() device: /job:localhost/replica:0/task:0/device:GPU:0
2023-12-24 16:15:57.909916: I tensorflow/core/framework/log_memory.cc:34] __LOG_MEMORY__ MemoryLogTensorOutput { step_id: 1 kernel_name: "Weight/read" tensor { dtype: DT_FLOAT shape { dim { size: 5 } dim { size: 7 } } allocation_description { requested_bytes: 140 allocated_bytes: 256 allocator_name: "GPU_0_bfc" allocation_id: 1 ptr: 139829608185856 } } }
2023-12-24 16:15:57.909952: I tensorflow/core/common_runtime/executor.cc:836] Synchronous kernel done: 3 step 1 {{node Weight/read}} = Identity[T=DT_FLOAT, _XlaHasReferenceVars=false, _class=["loc:@Weight"], _device="/job:localhost/replica:0/task:0/device:GPU:0"](Weight) device: /job:localhost/replica:0/task:0/device:GPU:0
2023-12-24 16:15:57.909986: I tensorflow/core/common_runtime/executor.cc:783] Process node: 5 step 1 {{node Bias/read}} = Identity[T=DT_FLOAT, _XlaHasReferenceVars=false, _class=["loc:@Bias"], _device="/job:localhost/replica:0/task:0/device:GPU:0"](Bias) device: /job:localhost/replica:0/task:0/device:GPU:0
2023-12-24 16:15:57.910018: I tensorflow/core/common_runtime/gpu/gpu_device.cc:660] GpuDevice::ComputeHelper Bias/read op Identity on GPU 0 stream[0]
2023-12-24 16:15:57.910028: I tensorflow/stream_executor/cuda/cuda_driver.cc:151] ScopedActivateContext switching to 1
2023-12-24 16:15:57.910047: I tensorflow/core/common_runtime/gpu/gpu_device.cc:697] GpuDevice::ComputeHelper scheduled Bias/read op Identity on GPU 0 stream[0]
2023-12-24 16:15:57.910082: I tensorflow/core/framework/log_memory.cc:34] __LOG_MEMORY__ MemoryLogTensorOutput { step_id: 1 kernel_name: "Bias/read" tensor { dtype: DT_FLOAT shape { dim { size: 7 } } allocation_description { requested_bytes: 28 allocated_bytes: 256 allocator_name: "GPU_0_bfc" allocation_id: 2 ptr: 139829608186112 } } }
2023-12-24 16:15:57.910110: I tensorflow/core/common_runtime/executor.cc:836] Synchronous kernel done: 5 step 1 {{node Bias/read}} = Identity[T=DT_FLOAT, _XlaHasReferenceVars=false, _class=["loc:@Bias"], _device="/job:localhost/replica:0/task:0/device:GPU:0"](Bias) device: /job:localhost/replica:0/task:0/device:GPU:0
2023-12-24 16:15:57.910137: I tensorflow/core/common_runtime/executor.cc:783] Process node: 7 step 1 {{node MatMul}} = MatMul[T=DT_FLOAT, _XlaHasReferenceVars=false, transpose_a=false, transpose_b=false, _device="/job:localhost/replica:0/task:0/device:GPU:0"](_arg_X_0_0/_1, Weight/read) device: /job:localhost/replica:0/task:0/device:GPU:0
2023-12-24 16:15:57.910165: I tensorflow/core/common_runtime/gpu/gpu_device.cc:660] GpuDevice::ComputeHelper MatMul op MatMul on GPU 0 stream[0]
2023-12-24 16:15:57.910174: I tensorflow/stream_executor/cuda/cuda_driver.cc:151] ScopedActivateContext switching to 1
2023-12-24 16:15:57.910231: I tensorflow/core/common_runtime/bfc_allocator.cc:260] AllocateRaw GPU_0_bfc  84
2023-12-24 16:15:57.910250: I tensorflow/core/common_runtime/bfc_allocator.cc:593] New Peak memory usage of 2304 bytes for GPU_0_bfc
2023-12-24 16:15:57.910259: I tensorflow/core/common_runtime/bfc_allocator.cc:307] AllocateRaw GPU_0_bfc  84 0x7f2c9e200800
2023-12-24 16:15:57.910292: I tensorflow/core/framework/log_memory.cc:34] __LOG_MEMORY__ MemoryLogTensorAllocation { step_id: 1 kernel_name: "MatMul" tensor { dtype: DT_FLOAT shape { dim { size: 3 } dim { size: 7 } } allocation_description { requested_bytes: 84 allocated_bytes: 256 allocator_name: "GPU_0_bfc" allocation_id: 5 has_single_reference: true ptr: 139829608187904 } } }
2023-12-24 16:15:57.910347: I tensorflow/stream_executor/plugin_registry.cc:246] Selecting default BLAS plugin, cuBLAS
2023-12-24 16:15:57.910405: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11
2023-12-24 16:15:58.405592: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11
2023-12-24 16:15:58.406157: I tensorflow/stream_executor/cuda/cuda_blas.cc:1821] doing cuBLAS SGEMM: at=0 bt=0 m=7 n=3 k=5 alpha=0x7f2cbaff5800 a=0x7f2c9e200000 lda=7 b=0x7f2c9e200700 ldb=5 beta=0x7f2cbaff5810 c=0x7f2c9e200800 ldc=7
2023-12-24 16:15:58.406340: I tensorflow/core/common_runtime/gpu/gpu_device.cc:697] GpuDevice::ComputeHelper scheduled MatMul op MatMul on GPU 0 stream[0]
2023-12-24 16:15:58.406463: I tensorflow/core/framework/log_memory.cc:34] __LOG_MEMORY__ MemoryLogTensorOutput { step_id: 1 kernel_name: "MatMul" tensor { dtype: DT_FLOAT shape { dim { size: 3 } dim { size: 7 } } allocation_description { requested_bytes: 84 allocated_bytes: 256 allocator_name: "GPU_0_bfc" allocation_id: 5 has_single_reference: true ptr: 139829608187904 } } }
2023-12-24 16:15:58.406545: I tensorflow/core/common_runtime/executor.cc:836] Synchronous kernel done: 7 step 1 {{node MatMul}} = MatMul[T=DT_FLOAT, _XlaHasReferenceVars=false, transpose_a=false, transpose_b=false, _device="/job:localhost/replica:0/task:0/device:GPU:0"](_arg_X_0_0/_1, Weight/read) device: /job:localhost/replica:0/task:0/device:GPU:0
2023-12-24 16:15:58.406562: I tensorflow/core/framework/log_memory.cc:34] __LOG_MEMORY__ MemoryLogTensorDeallocation { allocation_id: 4 allocator_name: "GPU_0_bfc" }
2023-12-24 16:15:58.406574: I tensorflow/core/common_runtime/bfc_allocator.cc:673] DeallocateRaw GPU_0_bfc 60
2023-12-24 16:15:58.406640: I tensorflow/core/common_runtime/executor.cc:783] Process node: 8 step 1 {{node Add}} = Add[T=DT_FLOAT, _XlaHasReferenceVars=false, _device="/job:localhost/replica:0/task:0/device:GPU:0"](MatMul, Bias/read) device: /job:localhost/replica:0/task:0/device:GPU:0
2023-12-24 16:15:58.406707: I tensorflow/core/common_runtime/gpu/gpu_device.cc:660] GpuDevice::ComputeHelper Add op Add on GPU 0 stream[0]
2023-12-24 16:15:58.406722: I tensorflow/stream_executor/cuda/cuda_driver.cc:151] ScopedActivateContext switching to 1
2023-12-24 16:15:58.407142: I tensorflow/core/common_runtime/gpu/gpu_device.cc:697] GpuDevice::ComputeHelper scheduled Add op Add on GPU 0 stream[0]
2023-12-24 16:15:58.407226: I tensorflow/core/framework/log_memory.cc:34] __LOG_MEMORY__ MemoryLogTensorOutput { step_id: 1 kernel_name: "Add" tensor { dtype: DT_FLOAT shape { dim { size: 3 } dim { size: 7 } } allocation_description { requested_bytes: 84 allocated_bytes: 256 allocator_name: "GPU_0_bfc" allocation_id: 5 ptr: 139829608187904 } } }
2023-12-24 16:15:58.407276: I tensorflow/core/common_runtime/executor.cc:836] Synchronous kernel done: 8 step 1 {{node Add}} = Add[T=DT_FLOAT, _XlaHasReferenceVars=false, _device="/job:localhost/replica:0/task:0/device:GPU:0"](MatMul, Bias/read) device: /job:localhost/replica:0/task:0/device:GPU:0
2023-12-24 16:15:58.407315: I tensorflow/core/common_runtime/executor.cc:783] Process node: 9 step 1 {{node Sigmoid}} = Sigmoid[T=DT_FLOAT, _XlaHasReferenceVars=false, _device="/job:localhost/replica:0/task:0/device:GPU:0"](Add) device: /job:localhost/replica:0/task:0/device:GPU:0
2023-12-24 16:15:58.407363: I tensorflow/core/common_runtime/gpu/gpu_device.cc:660] GpuDevice::ComputeHelper Sigmoid op Sigmoid on GPU 0 stream[0]
2023-12-24 16:15:58.407375: I tensorflow/stream_executor/cuda/cuda_driver.cc:151] ScopedActivateContext switching to 1
2023-12-24 16:15:58.407586: I tensorflow/core/common_runtime/gpu/gpu_device.cc:697] GpuDevice::ComputeHelper scheduled Sigmoid op Sigmoid on GPU 0 stream[0]
2023-12-24 16:15:58.407639: I tensorflow/core/framework/log_memory.cc:34] __LOG_MEMORY__ MemoryLogTensorOutput { step_id: 1 kernel_name: "Sigmoid" tensor { dtype: DT_FLOAT shape { dim { size: 3 } dim { size: 7 } } allocation_description { requested_bytes: 84 allocated_bytes: 256 allocator_name: "GPU_0_bfc" allocation_id: 5 ptr: 139829608187904 } } }
2023-12-24 16:15:58.407675: I tensorflow/core/common_runtime/executor.cc:836] Synchronous kernel done: 9 step 1 {{node Sigmoid}} = Sigmoid[T=DT_FLOAT, _XlaHasReferenceVars=false, _device="/job:localhost/replica:0/task:0/device:GPU:0"](Add) device: /job:localhost/replica:0/task:0/device:GPU:0
2023-12-24 16:15:58.407723: I tensorflow/core/common_runtime/executor.cc:783] Process node: 10 step 1 {{node Sigmoid/_2}} = _Send[T=DT_FLOAT, _dst="_retval_Sigmoid_0_0", _src="Sigmoid", client_terminated=false, recv_device="/job:localhost/replica:0/task:0/device:CPU:0", send_device="/job:localhost/replica:0/task:0/device:GPU:0", send_device_incarnation=1, tensor_name="edge_14_Sigmoid", _device="/job:localhost/replica:0/task:0/device:GPU:0"](Sigmoid) device: /job:localhost/replica:0/task:0/device:GPU:0
2023-12-24 16:15:58.407761: I tensorflow/core/common_runtime/gpu/gpu_device.cc:660] GpuDevice::ComputeHelper Sigmoid/_2 op _Send on GPU 0 stream[0]
2023-12-24 16:15:58.407772: I tensorflow/stream_executor/cuda/cuda_driver.cc:151] ScopedActivateContext switching to 1
2023-12-24 16:15:58.407787: I tensorflow/core/kernels/sendrecv_ops.cc:96] Send /job:localhost/replica:0/task:0/device:GPU:0;0000000000000001;/job:localhost/replica:0/task:0/device:CPU:0;edge_14_Sigmoid;0:0 using 94069282906000
2023-12-24 16:15:58.407797: I tensorflow/core/common_runtime/rendezvous_mgr.cc:167] IntraProcessRendezvous Send 0x558e36311f90 /job:localhost/replica:0/task:0/device:GPU:0;0000000000000001;/job:localhost/replica:0/task:0/device:CPU:0;edge_14_Sigmoid;0:0
2023-12-24 16:15:58.407848: I tensorflow/core/common_runtime/bfc_allocator.cc:260] AllocateRaw gpu_host_bfc  84
2023-12-24 16:15:58.407871: I tensorflow/core/common_runtime/bfc_allocator.cc:307] AllocateRaw gpu_host_bfc  84 0x7f2c9e000000
2023-12-24 16:15:58.407906: I tensorflow/core/framework/log_memory.cc:34] __LOG_MEMORY__ MemoryLogTensorAllocation { step_id: -6 kernel_name: "Unknown (with attributes)" tensor { dtype: DT_FLOAT shape { dim { size: 3 } dim { size: 7 } } allocation_description { requested_bytes: 84 allocated_bytes: 256 allocator_name: "gpu_host_bfc" allocation_id: 3 has_single_reference: true ptr: 139829606088704 } } }
2023-12-24 16:15:58.407924: I tensorflow/core/common_runtime/copy_tensor.cc:211] Copy edge_14_Sigmoid
2023-12-24 16:15:58.407938: I tensorflow/core/common_runtime/gpu/gpu_util.cc:270] CopyGPUTensorToCPU
2023-12-24 16:15:58.407958: I tensorflow/stream_executor/stream.cc:1202] [stream=0x558e0bbeb4a0,impl=0x558e35b0f460] Called Stream::ThenWaitFor(other=0x558e0bbeba30)
2023-12-24 16:15:58.407984: I tensorflow/stream_executor/stream.cc:4029] [stream=0x558e0bbeb4a0,impl=0x558e35b0f460] Called Stream::ThenMemcpy(host_dst=0x7f2c9e000000, gpu_src=0x7f2c9e200800, size=84)
2023-12-24 16:15:58.408011: I tensorflow/stream_executor/cuda/cuda_driver.cc:1169] successfully enqueued async memcpy d2h of 84 bytes from 0x7f2c9e200800 to 0x7f2c9e000000 on stream 0x558e361a7ee0
2023-12-24 16:15:58.408024: I tensorflow/core/common_runtime/device/device_event_mgr.cc:170] QueueInUse  free_events_ 1 used_events_ 0
2023-12-24 16:15:58.408037: I tensorflow/stream_executor/stream.cc:330] [stream=0x558e0bbeb4a0,impl=0x558e35b0f460] Called Stream::ThenRecordEvent(event=0x558e36311dd0)
2023-12-24 16:15:58.408055: I tensorflow/core/common_runtime/device/device_event_mgr.cc:208] PollEvents  free_events_ 0 used_events_ 1
2023-12-24 16:15:58.408109: I tensorflow/core/common_runtime/device/device_event_mgr.cc:208] PollEvents  free_events_ 1 used_events_ 0
2023-12-24 16:15:58.408144: I tensorflow/core/common_runtime/gpu/gpu_device.cc:697] GpuDevice::ComputeHelper scheduled Sigmoid/_2 op _Send on GPU 0 stream[0]
2023-12-24 16:15:58.408202: I tensorflow/core/common_runtime/executor.cc:836] Synchronous kernel done: 10 step 1 {{node Sigmoid/_2}} = _Send[T=DT_FLOAT, _dst="_retval_Sigmoid_0_0", _src="Sigmoid", client_terminated=false, recv_device="/job:localhost/replica:0/task:0/device:CPU:0", send_device="/job:localhost/replica:0/task:0/device:GPU:0", send_device_incarnation=1, tensor_name="edge_14_Sigmoid", _device="/job:localhost/replica:0/task:0/device:GPU:0"](Sigmoid) device: /job:localhost/replica:0/task:0/device:GPU:0
2023-12-24 16:15:58.408220: I tensorflow/core/framework/log_memory.cc:34] __LOG_MEMORY__ MemoryLogTensorOutput { step_id: 1 kernel_name: "Sigmoid/_3" tensor { dtype: DT_FLOAT shape { dim { size: 3 } dim { size: 7 } } allocation_description { requested_bytes: 84 allocated_bytes: 256 allocator_name: "gpu_host_bfc" allocation_id: 3 ptr: 139829606088704 } } }
2023-12-24 16:15:58.408244: I tensorflow/core/framework/log_memory.cc:34] __LOG_MEMORY__ MemoryLogTensorDeallocation { allocation_id: 5 allocator_name: "GPU_0_bfc" }
2023-12-24 16:15:58.408255: I tensorflow/core/common_runtime/bfc_allocator.cc:673] DeallocateRaw GPU_0_bfc 84
2023-12-24 16:15:58.408285: I tensorflow/core/common_runtime/propagator_state.cc:357] Delete frame 0
2023-12-24 16:15:58.408297: I tensorflow/core/common_runtime/executor.cc:626] Async kernel done: 4 step 1 {{node Sigmoid/_3}} = _Recv[_dst="_retval_Sigmoid_0_0", _src="Sigmoid", client_terminated=false, recv_device="/job:localhost/replica:0/task:0/device:CPU:0", send_device="/job:localhost/replica:0/task:0/device:GPU:0", send_device_incarnation=1, tensor_name="edge_14_Sigmoid", tensor_type=DT_FLOAT, _device="/job:localhost/replica:0/task:0/device:CPU:0"]() device: /job:localhost/replica:0/task:0/device:CPU:0
2023-12-24 16:15:58.408332: I tensorflow/stream_executor/stream.cc:4508] [stream=0x558e0bbeba30,impl=0x558e35b0f520] Called Stream::BlockHostUntilDone()
2023-12-24 16:15:58.408344: I tensorflow/stream_executor/temporary_memory_manager.cc:64] deallocated 0 finalized temporaries
2023-12-24 16:15:58.408355: I tensorflow/stream_executor/cuda/cuda_driver.cc:151] ScopedActivateContext switching to 1
2023-12-24 16:15:58.408421: I tensorflow/core/common_runtime/executor.cc:783] Process node: 5 step 1 {{node _retval_Sigmoid_0_0}} = _Retval[T=DT_FLOAT, _XlaHasReferenceVars=false, index=0, _device="/job:localhost/replica:0/task:0/device:CPU:0"](Sigmoid/_3) device: /job:localhost/replica:0/task:0/device:CPU:0
2023-12-24 16:15:58.408476: I tensorflow/core/common_runtime/executor.cc:836] Synchronous kernel done: 5 step 1 {{node _retval_Sigmoid_0_0}} = _Retval[T=DT_FLOAT, _XlaHasReferenceVars=false, index=0, _device="/job:localhost/replica:0/task:0/device:CPU:0"](Sigmoid/_3) device: /job:localhost/replica:0/task:0/device:CPU:0
2023-12-24 16:15:58.408493: I tensorflow/core/common_runtime/propagator_state.cc:357] Delete frame 0
Successfully ran session! model=test_model_v1


Output Sigmoid:0:
Tensor<type: float shape: [3,7] values: [0.502891481 0.496973246 0.506602883...]...>
>> 0.502891 0.496973 0.506603 0.499616 0.500628 0.50228 0.499679 
>> 0.505233 0.496343 0.507333 0.497482 0.496421 0.507325 0.499214 
>> 0.501607 0.498184 0.504358 0.497508 0.499114 0.506465 0.500591 

FINISHED
2023-12-24 16:15:58.408796: I tensorflow/core/framework/log_memory.cc:34] __LOG_MEMORY__ MemoryLogTensorDeallocation { allocation_id: 3 allocator_name: "gpu_host_bfc" }
2023-12-24 16:15:58.408816: I tensorflow/core/common_runtime/bfc_allocator.cc:673] DeallocateRaw gpu_host_bfc 84
2023-12-24 16:15:58.408849: I tensorflow/core/framework/log_memory.cc:34] __LOG_MEMORY__ MemoryLogTensorDeallocation { allocation_id: 1 allocator_name: "mklcpu" }
son.nguyen@n234-182-031:~/workspace/dtf/tfsession$ 