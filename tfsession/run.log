son.nguyen@n238-046-199:~/workspace/dtf/tfsession$ ./run.sh 
LD_LIBRARY_PATH:
/usr/lib/x86_64-linux-gnu
/data00/home/son.nguyen/workspace/common/cpp3rdlib/protobuf/lib
/data00/home/son.nguyen/workspace/common/cpp3rdlib/icu/lib
/data00/home/son.nguyen/workspace/common/cpp3rdlib/cuda/lib
/data00/home/son.nguyen/workspace/common/cpp3rdlib/tensorflow/lib
2023-12-23 05:27:49.559163: I tensorflow/core/platform/cloud/gcs_file_system.cc:805] GCS cache max size = 0 ; block size = 67108864 ; max staleness = 0
2023-12-23 05:27:49.559256: I ./tensorflow/core/platform/cloud/ram_file_block_cache.h:64] GCS file block cache is disabled
2023-12-23 05:27:49.559271: I tensorflow/core/platform/cloud/gcs_file_system.cc:845] GCS DNS cache is disabled, because GCS_RESOLVE_REFRESH_SECS = 0 (or is not set)
2023-12-23 05:27:49.559283: I tensorflow/core/platform/cloud/gcs_file_system.cc:875] GCS additional header DISABLED. No environment variable set.
2023-12-23 05:27:49.565790: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0
2023-12-23 05:27:49.594861: I tensorflow/compiler/tf2tensorrt/convert/trt_optimization_pass.cc:268] Constructing a CustomOptimizationPass registration object for TensorRTOptimizer
2023-12-23 05:27:49.601696: I tensorflow/core/platform/cloud/gcs_file_system.cc:805] GCS cache max size = 0 ; block size = 67108864 ; max staleness = 0
2023-12-23 05:27:49.601727: I ./tensorflow/core/platform/cloud/ram_file_block_cache.h:64] GCS file block cache is disabled
2023-12-23 05:27:49.601737: I tensorflow/core/platform/cloud/gcs_file_system.cc:845] GCS DNS cache is disabled, because GCS_RESOLVE_REFRESH_SECS = 0 (or is not set)
2023-12-23 05:27:49.601744: I tensorflow/core/platform/cloud/gcs_file_system.cc:875] GCS additional header DISABLED. No environment variable set.
Graph file: models/test/test_model_v1/gpu/graph.pb




========================================================================================================================
1. Create a new TF Session object
========================================================================================================================
2023-12-23 05:27:49.608097: I tensorflow/core/common_runtime/session_factory.cc:75] SessionFactory type DIRECT_SESSION accepts target: 
2023-12-23 05:27:49.608179: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX512F
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-12-23 05:27:49.608391: I tensorflow/compiler/xla/parse_flags_from_env.cc:199] For env var TF_XLA_FLAGS found arguments:
2023-12-23 05:27:49.608416: I tensorflow/compiler/xla/parse_flags_from_env.cc:201]   argv[0] = <argv[0]>
2023-12-23 05:27:49.608425: I tensorflow/compiler/jit/xla_cpu_device.cc:54] Not creating XLA devices, tf_xla_enable_xla_devices not set
2023-12-23 05:27:49.609299: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcuda.so.1
2023-12-23 05:27:49.777055: I tensorflow/stream_executor/executor_cache.cc:54] building executor
2023-12-23 05:27:49.777204: I tensorflow/stream_executor/cuda/cuda_driver.cc:439] CreateContext with device_ordinal:0 CUDA device id: 0 CUDA context id: 0 with SMs: 0
2023-12-23 05:27:49.861711: I tensorflow/stream_executor/cuda/cuda_driver.cc:537] created or reused context 0x1eafff0 for this thread
2023-12-23 05:27:49.861744: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:149] GpuExecutor Create Context[impl]: 0x24260e0
2023-12-23 05:27:49.861765: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 0
2023-12-23 05:27:49.861775: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 0
2023-12-23 05:27:49.861786: I tensorflow/stream_executor/executor_cache.cc:54] building executor
2023-12-23 05:27:49.861912: I tensorflow/stream_executor/cuda/cuda_driver.cc:439] CreateContext with device_ordinal:1 CUDA device id: 1 CUDA context id: 0 with SMs: 0
2023-12-23 05:27:49.950190: I tensorflow/stream_executor/cuda/cuda_driver.cc:537] created or reused context 0x1ea2bd0 for this thread
2023-12-23 05:27:49.950227: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:149] GpuExecutor Create Context[impl]: 0x2a7cf80
2023-12-23 05:27:49.950244: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 1
2023-12-23 05:27:49.950263: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 2
2023-12-23 05:27:49.950286: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 1
2023-12-23 05:27:49.951746: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 0
2023-12-23 05:27:49.951779: I tensorflow/stream_executor/executor_cache.cc:54] building executor
2023-12-23 05:27:49.951894: I tensorflow/stream_executor/cuda/cuda_driver.cc:439] CreateContext with device_ordinal:2 CUDA device id: 2 CUDA context id: 0 with SMs: 0
2023-12-23 05:27:50.040114: I tensorflow/stream_executor/cuda/cuda_driver.cc:537] created or reused context 0x1edd0a0 for this thread
2023-12-23 05:27:50.040150: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:149] GpuExecutor Create Context[impl]: 0x30dbf80
2023-12-23 05:27:50.040167: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 1
2023-12-23 05:27:50.040175: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 3
2023-12-23 05:27:50.040185: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 1
2023-12-23 05:27:50.041396: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 0
2023-12-23 05:27:50.041427: I tensorflow/stream_executor/executor_cache.cc:54] building executor
2023-12-23 05:27:50.041544: I tensorflow/stream_executor/cuda/cuda_driver.cc:439] CreateContext with device_ordinal:3 CUDA device id: 3 CUDA context id: 0 with SMs: 0
2023-12-23 05:27:50.134562: I tensorflow/stream_executor/cuda/cuda_driver.cc:537] created or reused context 0x1ee36a0 for this thread
2023-12-23 05:27:50.134599: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:149] GpuExecutor Create Context[impl]: 0x373d950
2023-12-23 05:27:50.134617: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 1
2023-12-23 05:27:50.134625: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 4
2023-12-23 05:27:50.134635: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 1
2023-12-23 05:27:50.135851: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 0
2023-12-23 05:27:50.135879: I tensorflow/stream_executor/executor_cache.cc:54] building executor
2023-12-23 05:27:50.135998: I tensorflow/stream_executor/cuda/cuda_driver.cc:439] CreateContext with device_ordinal:4 CUDA device id: 4 CUDA context id: 0 with SMs: 0
2023-12-23 05:27:50.239788: I tensorflow/stream_executor/cuda/cuda_driver.cc:537] created or reused context 0x1ee9ca0 for this thread
2023-12-23 05:27:50.239825: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:149] GpuExecutor Create Context[impl]: 0x3da85e0
2023-12-23 05:27:50.239843: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 1
2023-12-23 05:27:50.239851: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 5
2023-12-23 05:27:50.239861: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 1
2023-12-23 05:27:50.241091: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 0
2023-12-23 05:27:50.241125: I tensorflow/stream_executor/executor_cache.cc:54] building executor
2023-12-23 05:27:50.241251: I tensorflow/stream_executor/cuda/cuda_driver.cc:439] CreateContext with device_ordinal:5 CUDA device id: 5 CUDA context id: 0 with SMs: 0
2023-12-23 05:27:50.343995: I tensorflow/stream_executor/cuda/cuda_driver.cc:537] created or reused context 0x1ef02a0 for this thread
2023-12-23 05:27:50.344040: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:149] GpuExecutor Create Context[impl]: 0x441a930
2023-12-23 05:27:50.344058: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 1
2023-12-23 05:27:50.344065: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 6
2023-12-23 05:27:50.344075: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 1
2023-12-23 05:27:50.345311: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 0
2023-12-23 05:27:50.345345: I tensorflow/stream_executor/executor_cache.cc:54] building executor
2023-12-23 05:27:50.345463: I tensorflow/stream_executor/cuda/cuda_driver.cc:439] CreateContext with device_ordinal:6 CUDA device id: 6 CUDA context id: 0 with SMs: 0
2023-12-23 05:27:50.455848: I tensorflow/stream_executor/cuda/cuda_driver.cc:537] created or reused context 0x1ef68a0 for this thread
2023-12-23 05:27:50.455880: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:149] GpuExecutor Create Context[impl]: 0x4a9ed80
2023-12-23 05:27:50.455898: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 1
2023-12-23 05:27:50.455906: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 7
2023-12-23 05:27:50.455916: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 1
2023-12-23 05:27:50.457171: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 0
2023-12-23 05:27:50.457199: I tensorflow/stream_executor/executor_cache.cc:54] building executor
2023-12-23 05:27:50.457303: I tensorflow/stream_executor/cuda/cuda_driver.cc:439] CreateContext with device_ordinal:7 CUDA device id: 7 CUDA context id: 0 with SMs: 0
2023-12-23 05:27:50.573842: I tensorflow/stream_executor/cuda/cuda_driver.cc:537] created or reused context 0x1efcea0 for this thread
2023-12-23 05:27:50.573879: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:149] GpuExecutor Create Context[impl]: 0x5121370
2023-12-23 05:27:50.573897: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 1
2023-12-23 05:27:50.573905: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 8
2023-12-23 05:27:50.573915: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 1
2023-12-23 05:27:50.575164: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 1
2023-12-23 05:27:50.575194: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 0
2023-12-23 05:27:50.575203: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 2
2023-12-23 05:27:50.575212: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 1
2023-12-23 05:27:50.575221: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 2
2023-12-23 05:27:50.575232: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 1
2023-12-23 05:27:50.575239: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 1
2023-12-23 05:27:50.575246: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 1
2023-12-23 05:27:50.575253: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 2
2023-12-23 05:27:50.575260: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 2
2023-12-23 05:27:50.575267: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 3
2023-12-23 05:27:50.575276: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 2
2023-12-23 05:27:50.576461: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 1
2023-12-23 05:27:50.576479: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 3
2023-12-23 05:27:50.576486: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 2
2023-12-23 05:27:50.576494: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 4
2023-12-23 05:27:50.576502: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 2
2023-12-23 05:27:50.577666: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 1
2023-12-23 05:27:50.577686: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 4
2023-12-23 05:27:50.577694: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 2
2023-12-23 05:27:50.577702: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 5
2023-12-23 05:27:50.577710: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 2
2023-12-23 05:27:50.578881: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 1
2023-12-23 05:27:50.578901: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 5
2023-12-23 05:27:50.578909: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 2
2023-12-23 05:27:50.578917: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 6
2023-12-23 05:27:50.578925: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 2
2023-12-23 05:27:50.580100: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 1
2023-12-23 05:27:50.580124: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 6
2023-12-23 05:27:50.580132: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 2
2023-12-23 05:27:50.580140: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 7
2023-12-23 05:27:50.580149: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 2
2023-12-23 05:27:50.581358: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 1
2023-12-23 05:27:50.581380: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 7
2023-12-23 05:27:50.581389: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 2
2023-12-23 05:27:50.581397: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 8
2023-12-23 05:27:50.581406: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 2
2023-12-23 05:27:50.582681: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 2
2023-12-23 05:27:50.582701: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 0
2023-12-23 05:27:50.582709: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 3
2023-12-23 05:27:50.582718: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 1
2023-12-23 05:27:50.582727: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 3
2023-12-23 05:27:50.582738: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 2
2023-12-23 05:27:50.582746: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 1
2023-12-23 05:27:50.582754: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 3
2023-12-23 05:27:50.582762: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 2
2023-12-23 05:27:50.582770: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 3
2023-12-23 05:27:50.582781: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 2
2023-12-23 05:27:50.582789: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 2
2023-12-23 05:27:50.582797: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 2
2023-12-23 05:27:50.582805: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 3
2023-12-23 05:27:50.582813: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 3
2023-12-23 05:27:50.582822: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 4
2023-12-23 05:27:50.582831: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 3
2023-12-23 05:27:50.584002: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 2
2023-12-23 05:27:50.584026: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 4
2023-12-23 05:27:50.584034: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 3
2023-12-23 05:27:50.584041: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 5
2023-12-23 05:27:50.584050: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 3
2023-12-23 05:27:50.585210: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 2
2023-12-23 05:27:50.585232: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 5
2023-12-23 05:27:50.585240: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 3
2023-12-23 05:27:50.585249: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 6
2023-12-23 05:27:50.585258: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 3
2023-12-23 05:27:50.586435: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 2
2023-12-23 05:27:50.586451: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 6
2023-12-23 05:27:50.586459: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 3
2023-12-23 05:27:50.586467: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 7
2023-12-23 05:27:50.586477: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 3
2023-12-23 05:27:50.587710: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 2
2023-12-23 05:27:50.587728: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 7
2023-12-23 05:27:50.587736: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 3
2023-12-23 05:27:50.587745: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 8
2023-12-23 05:27:50.587754: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 3
2023-12-23 05:27:50.588901: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 3
2023-12-23 05:27:50.588915: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 0
2023-12-23 05:27:50.588923: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 4
2023-12-23 05:27:50.588931: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 1
2023-12-23 05:27:50.588940: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 4
2023-12-23 05:27:50.588951: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 3
2023-12-23 05:27:50.588959: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 1
2023-12-23 05:27:50.588966: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 4
2023-12-23 05:27:50.588974: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 2
2023-12-23 05:27:50.588983: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 4
2023-12-23 05:27:50.588994: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 3
2023-12-23 05:27:50.589007: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 2
2023-12-23 05:27:50.589015: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 4
2023-12-23 05:27:50.589023: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 3
2023-12-23 05:27:50.589032: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 4
2023-12-23 05:27:50.589044: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 3
2023-12-23 05:27:50.589053: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 3
2023-12-23 05:27:50.589062: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 3
2023-12-23 05:27:50.589070: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 4
2023-12-23 05:27:50.589081: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 4
2023-12-23 05:27:50.589090: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 5
2023-12-23 05:27:50.589099: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 4
2023-12-23 05:27:50.590552: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 3
2023-12-23 05:27:50.590569: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 5
2023-12-23 05:27:50.590578: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 4
2023-12-23 05:27:50.590586: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 6
2023-12-23 05:27:50.590596: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 4
2023-12-23 05:27:50.591782: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 3
2023-12-23 05:27:50.591802: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 6
2023-12-23 05:27:50.591810: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 4
2023-12-23 05:27:50.591819: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 7
2023-12-23 05:27:50.591829: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 4
2023-12-23 05:27:50.593038: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 3
2023-12-23 05:27:50.593055: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 7
2023-12-23 05:27:50.593063: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 4
2023-12-23 05:27:50.593071: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 8
2023-12-23 05:27:50.593080: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 4
2023-12-23 05:27:50.594237: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 4
2023-12-23 05:27:50.594252: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 0
2023-12-23 05:27:50.594260: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 5
2023-12-23 05:27:50.594268: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 1
2023-12-23 05:27:50.594277: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 5
2023-12-23 05:27:50.594288: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 4
2023-12-23 05:27:50.594296: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 1
2023-12-23 05:27:50.594303: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 5
2023-12-23 05:27:50.594311: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 2
2023-12-23 05:27:50.594319: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 5
2023-12-23 05:27:50.594330: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 4
2023-12-23 05:27:50.594339: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 2
2023-12-23 05:27:50.594347: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 5
2023-12-23 05:27:50.594355: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 3
2023-12-23 05:27:50.594364: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 5
2023-12-23 05:27:50.594373: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 4
2023-12-23 05:27:50.594380: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 3
2023-12-23 05:27:50.594386: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 5
2023-12-23 05:27:50.594394: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 4
2023-12-23 05:27:50.594401: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 5
2023-12-23 05:27:50.594411: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 4
2023-12-23 05:27:50.594419: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 4
2023-12-23 05:27:50.594426: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 4
2023-12-23 05:27:50.594433: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 5
2023-12-23 05:27:50.594440: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 5
2023-12-23 05:27:50.594447: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 6
2023-12-23 05:27:50.594454: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 5
2023-12-23 05:27:50.595751: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 4
2023-12-23 05:27:50.595769: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 6
2023-12-23 05:27:50.595778: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 5
2023-12-23 05:27:50.595787: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 7
2023-12-23 05:27:50.595797: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 5
2023-12-23 05:27:50.596954: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 4
2023-12-23 05:27:50.596973: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 7
2023-12-23 05:27:50.596982: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 5
2023-12-23 05:27:50.596991: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 8
2023-12-23 05:27:50.597001: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 5
2023-12-23 05:27:50.598169: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 5
2023-12-23 05:27:50.598185: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 0
2023-12-23 05:27:50.598193: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 6
2023-12-23 05:27:50.598201: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 1
2023-12-23 05:27:50.598211: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 6
2023-12-23 05:27:50.598222: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 5
2023-12-23 05:27:50.598231: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 1
2023-12-23 05:27:50.598238: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 6
2023-12-23 05:27:50.598246: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 2
2023-12-23 05:27:50.598255: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 6
2023-12-23 05:27:50.598267: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 5
2023-12-23 05:27:50.598276: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 2
2023-12-23 05:27:50.598284: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 6
2023-12-23 05:27:50.598293: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 3
2023-12-23 05:27:50.598302: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 6
2023-12-23 05:27:50.598313: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 5
2023-12-23 05:27:50.598322: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 3
2023-12-23 05:27:50.598330: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 6
2023-12-23 05:27:50.598338: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 4
2023-12-23 05:27:50.598348: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 6
2023-12-23 05:27:50.598359: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 5
2023-12-23 05:27:50.598368: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 4
2023-12-23 05:27:50.598376: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 6
2023-12-23 05:27:50.598384: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 5
2023-12-23 05:27:50.598393: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 6
2023-12-23 05:27:50.598405: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 5
2023-12-23 05:27:50.598414: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 5
2023-12-23 05:27:50.598422: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 5
2023-12-23 05:27:50.598430: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 6
2023-12-23 05:27:50.598439: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 6
2023-12-23 05:27:50.598447: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 7
2023-12-23 05:27:50.598456: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 6
2023-12-23 05:27:50.599598: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 5
2023-12-23 05:27:50.599616: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 7
2023-12-23 05:27:50.599624: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 6
2023-12-23 05:27:50.599632: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 8
2023-12-23 05:27:50.599641: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 6
2023-12-23 05:27:50.600916: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 6
2023-12-23 05:27:50.600933: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 0
2023-12-23 05:27:50.600942: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 7
2023-12-23 05:27:50.600950: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 1
2023-12-23 05:27:50.600960: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 7
2023-12-23 05:27:50.600971: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 6
2023-12-23 05:27:50.600979: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 1
2023-12-23 05:27:50.600987: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 7
2023-12-23 05:27:50.600994: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 2
2023-12-23 05:27:50.601008: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 7
2023-12-23 05:27:50.601020: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 6
2023-12-23 05:27:50.601028: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 2
2023-12-23 05:27:50.601036: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 7
2023-12-23 05:27:50.601043: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 3
2023-12-23 05:27:50.601051: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 7
2023-12-23 05:27:50.601060: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 6
2023-12-23 05:27:50.601068: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 3
2023-12-23 05:27:50.601074: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 7
2023-12-23 05:27:50.601081: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 4
2023-12-23 05:27:50.601089: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 7
2023-12-23 05:27:50.601099: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 6
2023-12-23 05:27:50.601107: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 4
2023-12-23 05:27:50.601115: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 7
2023-12-23 05:27:50.601122: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 5
2023-12-23 05:27:50.601131: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 7
2023-12-23 05:27:50.601141: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 6
2023-12-23 05:27:50.601149: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 5
2023-12-23 05:27:50.601157: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 7
2023-12-23 05:27:50.601165: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 6
2023-12-23 05:27:50.601173: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 7
2023-12-23 05:27:50.601183: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 6
2023-12-23 05:27:50.601191: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 6
2023-12-23 05:27:50.601199: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 6
2023-12-23 05:27:50.601207: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 7
2023-12-23 05:27:50.601214: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 7
2023-12-23 05:27:50.601222: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 8
2023-12-23 05:27:50.601230: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 7
2023-12-23 05:27:50.602433: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 7
2023-12-23 05:27:50.602450: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 0
2023-12-23 05:27:50.602459: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 8
2023-12-23 05:27:50.602467: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 1
2023-12-23 05:27:50.602477: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 8
2023-12-23 05:27:50.602489: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 7
2023-12-23 05:27:50.602497: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 1
2023-12-23 05:27:50.602504: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 8
2023-12-23 05:27:50.602512: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 2
2023-12-23 05:27:50.602521: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 8
2023-12-23 05:27:50.602532: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 7
2023-12-23 05:27:50.602541: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 2
2023-12-23 05:27:50.602549: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 8
2023-12-23 05:27:50.602557: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 3
2023-12-23 05:27:50.602567: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 8
2023-12-23 05:27:50.602577: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 7
2023-12-23 05:27:50.602586: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 3
2023-12-23 05:27:50.602594: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 8
2023-12-23 05:27:50.602602: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 4
2023-12-23 05:27:50.602611: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 8
2023-12-23 05:27:50.602622: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 7
2023-12-23 05:27:50.602631: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 4
2023-12-23 05:27:50.602639: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 8
2023-12-23 05:27:50.602647: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 5
2023-12-23 05:27:50.602656: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 8
2023-12-23 05:27:50.602667: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 7
2023-12-23 05:27:50.602676: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 5
2023-12-23 05:27:50.602684: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 8
2023-12-23 05:27:50.602692: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 6
2023-12-23 05:27:50.602701: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 8
2023-12-23 05:27:50.602712: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 7
2023-12-23 05:27:50.602720: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 6
2023-12-23 05:27:50.602728: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 8
2023-12-23 05:27:50.602737: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 7
2023-12-23 05:27:50.602746: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 8
2023-12-23 05:27:50.602756: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 7
2023-12-23 05:27:50.602765: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 7
2023-12-23 05:27:50.602797: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:252] found DLL info with name: /usr/lib/x86_64-linux-gnu/libcuda.so.1
2023-12-23 05:27:50.602819: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:257] found DLL info with resolved path: /usr/lib/x86_64-linux-gnu/libcuda.so.450.51.05
2023-12-23 05:27:50.602835: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:106] version string "450.51.05" made value 450.51.5
2023-12-23 05:27:50.602854: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:915] trying to read NUMA node for device ordinal: 0
2023-12-23 05:27:50.604189: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1777] Found device 0 with properties: 
pciBusID: 0000:3d:00.0 name: Tesla T4 computeCapability: 7.5
coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s
2023-12-23 05:27:50.604211: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:252] found DLL info with name: /usr/lib/x86_64-linux-gnu/libcuda.so.1
2023-12-23 05:27:50.604230: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:257] found DLL info with resolved path: /usr/lib/x86_64-linux-gnu/libcuda.so.450.51.05
2023-12-23 05:27:50.604242: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:106] version string "450.51.05" made value 450.51.5
2023-12-23 05:27:50.604255: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:915] trying to read NUMA node for device ordinal: 1
2023-12-23 05:27:50.605585: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1777] Found device 1 with properties: 
pciBusID: 0000:3e:00.0 name: Tesla T4 computeCapability: 7.5
coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s
2023-12-23 05:27:50.605611: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:252] found DLL info with name: /usr/lib/x86_64-linux-gnu/libcuda.so.1
2023-12-23 05:27:50.605629: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:257] found DLL info with resolved path: /usr/lib/x86_64-linux-gnu/libcuda.so.450.51.05
2023-12-23 05:27:50.605641: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:106] version string "450.51.05" made value 450.51.5
2023-12-23 05:27:50.605654: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:915] trying to read NUMA node for device ordinal: 2
2023-12-23 05:27:50.606970: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1777] Found device 2 with properties: 
pciBusID: 0000:40:00.0 name: Tesla T4 computeCapability: 7.5
coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s
2023-12-23 05:27:50.606994: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:252] found DLL info with name: /usr/lib/x86_64-linux-gnu/libcuda.so.1
2023-12-23 05:27:50.607014: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:257] found DLL info with resolved path: /usr/lib/x86_64-linux-gnu/libcuda.so.450.51.05
2023-12-23 05:27:50.607026: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:106] version string "450.51.05" made value 450.51.5
2023-12-23 05:27:50.607037: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:915] trying to read NUMA node for device ordinal: 3
2023-12-23 05:27:50.608372: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1777] Found device 3 with properties: 
pciBusID: 0000:41:00.0 name: Tesla T4 computeCapability: 7.5
coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s
2023-12-23 05:27:50.608394: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:252] found DLL info with name: /usr/lib/x86_64-linux-gnu/libcuda.so.1
2023-12-23 05:27:50.608408: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:257] found DLL info with resolved path: /usr/lib/x86_64-linux-gnu/libcuda.so.450.51.05
2023-12-23 05:27:50.608419: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:106] version string "450.51.05" made value 450.51.5
2023-12-23 05:27:50.608430: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:915] trying to read NUMA node for device ordinal: 4
2023-12-23 05:27:50.609629: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1777] Found device 4 with properties: 
pciBusID: 0000:b1:00.0 name: Tesla T4 computeCapability: 7.5
coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s
2023-12-23 05:27:50.609646: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:252] found DLL info with name: /usr/lib/x86_64-linux-gnu/libcuda.so.1
2023-12-23 05:27:50.609660: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:257] found DLL info with resolved path: /usr/lib/x86_64-linux-gnu/libcuda.so.450.51.05
2023-12-23 05:27:50.609670: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:106] version string "450.51.05" made value 450.51.5
2023-12-23 05:27:50.609681: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:915] trying to read NUMA node for device ordinal: 5
2023-12-23 05:27:50.610974: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1777] Found device 5 with properties: 
pciBusID: 0000:b2:00.0 name: Tesla T4 computeCapability: 7.5
coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s
2023-12-23 05:27:50.610995: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:252] found DLL info with name: /usr/lib/x86_64-linux-gnu/libcuda.so.1
2023-12-23 05:27:50.611013: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:257] found DLL info with resolved path: /usr/lib/x86_64-linux-gnu/libcuda.so.450.51.05
2023-12-23 05:27:50.611024: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:106] version string "450.51.05" made value 450.51.5
2023-12-23 05:27:50.611035: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:915] trying to read NUMA node for device ordinal: 6
2023-12-23 05:27:50.612349: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1777] Found device 6 with properties: 
pciBusID: 0000:b4:00.0 name: Tesla T4 computeCapability: 7.5
coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s
2023-12-23 05:27:50.612369: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:252] found DLL info with name: /usr/lib/x86_64-linux-gnu/libcuda.so.1
2023-12-23 05:27:50.612384: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:257] found DLL info with resolved path: /usr/lib/x86_64-linux-gnu/libcuda.so.450.51.05
2023-12-23 05:27:50.612394: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:106] version string "450.51.05" made value 450.51.5
2023-12-23 05:27:50.612405: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:915] trying to read NUMA node for device ordinal: 7
2023-12-23 05:27:50.613687: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1777] Found device 7 with properties: 
pciBusID: 0000:b5:00.0 name: Tesla T4 computeCapability: 7.5
coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s
2023-12-23 05:27:50.613716: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0
2023-12-23 05:27:50.621390: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11
2023-12-23 05:27:50.621438: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11
2023-12-23 05:27:50.624134: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcufft.so.10
2023-12-23 05:27:50.624768: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcurand.so.10
2023-12-23 05:27:50.627258: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusolver.so.10
2023-12-23 05:27:50.628099: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusparse.so.11
2023-12-23 05:27:50.628260: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudnn.so.8
2023-12-23 05:27:50.628282: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:252] found DLL info with name: /usr/lib/x86_64-linux-gnu/libcuda.so.1
2023-12-23 05:27:50.628299: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:257] found DLL info with resolved path: /usr/lib/x86_64-linux-gnu/libcuda.so.450.51.05
2023-12-23 05:27:50.628312: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:106] version string "450.51.05" made value 450.51.5
2023-12-23 05:27:50.628326: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:915] trying to read NUMA node for device ordinal: 0
2023-12-23 05:27:50.629613: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:252] found DLL info with name: /usr/lib/x86_64-linux-gnu/libcuda.so.1
2023-12-23 05:27:50.629631: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:257] found DLL info with resolved path: /usr/lib/x86_64-linux-gnu/libcuda.so.450.51.05
2023-12-23 05:27:50.629641: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:106] version string "450.51.05" made value 450.51.5
2023-12-23 05:27:50.629653: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:915] trying to read NUMA node for device ordinal: 1
2023-12-23 05:27:50.630885: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:252] found DLL info with name: /usr/lib/x86_64-linux-gnu/libcuda.so.1
2023-12-23 05:27:50.630908: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:257] found DLL info with resolved path: /usr/lib/x86_64-linux-gnu/libcuda.so.450.51.05
2023-12-23 05:27:50.630920: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:106] version string "450.51.05" made value 450.51.5
2023-12-23 05:27:50.630932: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:915] trying to read NUMA node for device ordinal: 2
2023-12-23 05:27:50.632193: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:252] found DLL info with name: /usr/lib/x86_64-linux-gnu/libcuda.so.1
2023-12-23 05:27:50.632211: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:257] found DLL info with resolved path: /usr/lib/x86_64-linux-gnu/libcuda.so.450.51.05
2023-12-23 05:27:50.632221: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:106] version string "450.51.05" made value 450.51.5
2023-12-23 05:27:50.632232: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:915] trying to read NUMA node for device ordinal: 3
2023-12-23 05:27:50.633535: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:252] found DLL info with name: /usr/lib/x86_64-linux-gnu/libcuda.so.1
2023-12-23 05:27:50.633560: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:257] found DLL info with resolved path: /usr/lib/x86_64-linux-gnu/libcuda.so.450.51.05
2023-12-23 05:27:50.633571: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:106] version string "450.51.05" made value 450.51.5
2023-12-23 05:27:50.633583: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:915] trying to read NUMA node for device ordinal: 4
2023-12-23 05:27:50.634852: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:252] found DLL info with name: /usr/lib/x86_64-linux-gnu/libcuda.so.1
2023-12-23 05:27:50.634871: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:257] found DLL info with resolved path: /usr/lib/x86_64-linux-gnu/libcuda.so.450.51.05
2023-12-23 05:27:50.634881: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:106] version string "450.51.05" made value 450.51.5
2023-12-23 05:27:50.634892: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:915] trying to read NUMA node for device ordinal: 5
2023-12-23 05:27:50.636155: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:252] found DLL info with name: /usr/lib/x86_64-linux-gnu/libcuda.so.1
2023-12-23 05:27:50.636172: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:257] found DLL info with resolved path: /usr/lib/x86_64-linux-gnu/libcuda.so.450.51.05
2023-12-23 05:27:50.636182: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:106] version string "450.51.05" made value 450.51.5
2023-12-23 05:27:50.636192: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:915] trying to read NUMA node for device ordinal: 6
2023-12-23 05:27:50.637473: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:252] found DLL info with name: /usr/lib/x86_64-linux-gnu/libcuda.so.1
2023-12-23 05:27:50.637494: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:257] found DLL info with resolved path: /usr/lib/x86_64-linux-gnu/libcuda.so.450.51.05
2023-12-23 05:27:50.637505: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:106] version string "450.51.05" made value 450.51.5
2023-12-23 05:27:50.637516: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:915] trying to read NUMA node for device ordinal: 7
2023-12-23 05:27:50.638864: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:252] found DLL info with name: /usr/lib/x86_64-linux-gnu/libcuda.so.1
2023-12-23 05:27:50.638886: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:257] found DLL info with resolved path: /usr/lib/x86_64-linux-gnu/libcuda.so.450.51.05
2023-12-23 05:27:50.638897: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:106] version string "450.51.05" made value 450.51.5
2023-12-23 05:27:50.638908: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:915] trying to read NUMA node for device ordinal: 0
2023-12-23 05:27:50.640195: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:252] found DLL info with name: /usr/lib/x86_64-linux-gnu/libcuda.so.1
2023-12-23 05:27:50.640216: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:257] found DLL info with resolved path: /usr/lib/x86_64-linux-gnu/libcuda.so.450.51.05
2023-12-23 05:27:50.640226: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:106] version string "450.51.05" made value 450.51.5
2023-12-23 05:27:50.640237: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:915] trying to read NUMA node for device ordinal: 1
2023-12-23 05:27:50.641493: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:252] found DLL info with name: /usr/lib/x86_64-linux-gnu/libcuda.so.1
2023-12-23 05:27:50.641509: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:257] found DLL info with resolved path: /usr/lib/x86_64-linux-gnu/libcuda.so.450.51.05
2023-12-23 05:27:50.641519: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:106] version string "450.51.05" made value 450.51.5
2023-12-23 05:27:50.641530: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:915] trying to read NUMA node for device ordinal: 2
2023-12-23 05:27:50.642823: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:252] found DLL info with name: /usr/lib/x86_64-linux-gnu/libcuda.so.1
2023-12-23 05:27:50.642844: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:257] found DLL info with resolved path: /usr/lib/x86_64-linux-gnu/libcuda.so.450.51.05
2023-12-23 05:27:50.642854: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:106] version string "450.51.05" made value 450.51.5
2023-12-23 05:27:50.642865: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:915] trying to read NUMA node for device ordinal: 3
2023-12-23 05:27:50.644172: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:252] found DLL info with name: /usr/lib/x86_64-linux-gnu/libcuda.so.1
2023-12-23 05:27:50.644192: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:257] found DLL info with resolved path: /usr/lib/x86_64-linux-gnu/libcuda.so.450.51.05
2023-12-23 05:27:50.644203: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:106] version string "450.51.05" made value 450.51.5
2023-12-23 05:27:50.644214: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:915] trying to read NUMA node for device ordinal: 4
2023-12-23 05:27:50.645507: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:252] found DLL info with name: /usr/lib/x86_64-linux-gnu/libcuda.so.1
2023-12-23 05:27:50.645528: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:257] found DLL info with resolved path: /usr/lib/x86_64-linux-gnu/libcuda.so.450.51.05
2023-12-23 05:27:50.645539: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:106] version string "450.51.05" made value 450.51.5
2023-12-23 05:27:50.645550: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:915] trying to read NUMA node for device ordinal: 5
2023-12-23 05:27:50.646724: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:252] found DLL info with name: /usr/lib/x86_64-linux-gnu/libcuda.so.1
2023-12-23 05:27:50.646740: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:257] found DLL info with resolved path: /usr/lib/x86_64-linux-gnu/libcuda.so.450.51.05
2023-12-23 05:27:50.646750: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:106] version string "450.51.05" made value 450.51.5
2023-12-23 05:27:50.646761: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:915] trying to read NUMA node for device ordinal: 6
2023-12-23 05:27:50.648047: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:252] found DLL info with name: /usr/lib/x86_64-linux-gnu/libcuda.so.1
2023-12-23 05:27:50.648072: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:257] found DLL info with resolved path: /usr/lib/x86_64-linux-gnu/libcuda.so.450.51.05
2023-12-23 05:27:50.648084: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:106] version string "450.51.05" made value 450.51.5
2023-12-23 05:27:50.648095: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:915] trying to read NUMA node for device ordinal: 7
2023-12-23 05:27:50.649432: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1915] Adding visible gpu devices: 0, 1, 2, 3, 4, 5, 6, 7
2023-12-23 05:27:50.649468: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0
2023-12-23 05:27:51.221362: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1211] Cuda stream priority range on GPU(7): -2,0
2023-12-23 05:27:51.710360: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1211] Cuda stream priority range on GPU(7): -2,0
2023-12-23 05:27:52.246628: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1211] Cuda stream priority range on GPU(7): -2,0
2023-12-23 05:27:52.746775: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1211] Cuda stream priority range on GPU(7): -2,0
2023-12-23 05:27:53.262011: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1211] Cuda stream priority range on GPU(7): -2,0
2023-12-23 05:27:53.802732: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1211] Cuda stream priority range on GPU(7): -2,0
2023-12-23 05:27:54.342433: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1211] Cuda stream priority range on GPU(7): -2,0
2023-12-23 05:27:54.867515: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1211] Cuda stream priority range on GPU(7): -2,0
2023-12-23 05:27:54.867567: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1262] TensorFlow compiled with CUDA 11.0 and cuDNN 8.0.5
2023-12-23 05:27:54.867591: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 0
2023-12-23 05:27:54.867598: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 0
2023-12-23 05:27:54.867607: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 0
2023-12-23 05:27:54.867614: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 1
2023-12-23 05:27:54.867624: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 1
2023-12-23 05:27:54.867635: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 2
2023-12-23 05:27:54.867648: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 0
2023-12-23 05:27:54.867657: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 2
2023-12-23 05:27:54.867665: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 1
2023-12-23 05:27:54.867673: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 3
2023-12-23 05:27:54.867682: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 0
2023-12-23 05:27:54.867690: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 3
2023-12-23 05:27:54.867697: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 1
2023-12-23 05:27:54.867705: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 4
2023-12-23 05:27:54.867714: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 0
2023-12-23 05:27:54.867724: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 4
2023-12-23 05:27:54.867732: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 1
2023-12-23 05:27:54.867739: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 5
2023-12-23 05:27:54.867749: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 0
2023-12-23 05:27:54.867756: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 5
2023-12-23 05:27:54.867763: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 1
2023-12-23 05:27:54.867772: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 6
2023-12-23 05:27:54.867779: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 0
2023-12-23 05:27:54.867788: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 6
2023-12-23 05:27:54.867796: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 1
2023-12-23 05:27:54.867805: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 7
2023-12-23 05:27:54.867814: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 0
2023-12-23 05:27:54.867824: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 7
2023-12-23 05:27:54.867835: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 1
2023-12-23 05:27:54.867846: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 8
2023-12-23 05:27:54.867855: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 1
2023-12-23 05:27:54.867864: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 0
2023-12-23 05:27:54.867872: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 2
2023-12-23 05:27:54.867880: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 1
2023-12-23 05:27:54.867889: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 1
2023-12-23 05:27:54.867897: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 1
2023-12-23 05:27:54.867905: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 1
2023-12-23 05:27:54.867913: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 2
2023-12-23 05:27:54.867921: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 2
2023-12-23 05:27:54.867930: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 3
2023-12-23 05:27:54.867939: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 1
2023-12-23 05:27:54.867947: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 3
2023-12-23 05:27:54.867955: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 2
2023-12-23 05:27:54.867964: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 4
2023-12-23 05:27:54.867973: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 1
2023-12-23 05:27:54.867981: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 4
2023-12-23 05:27:54.867989: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 2
2023-12-23 05:27:54.867998: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 5
2023-12-23 05:27:54.868013: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 1
2023-12-23 05:27:54.868022: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 5
2023-12-23 05:27:54.868030: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 2
2023-12-23 05:27:54.868038: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 6
2023-12-23 05:27:54.868048: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 1
2023-12-23 05:27:54.868057: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 6
2023-12-23 05:27:54.868065: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 2
2023-12-23 05:27:54.868074: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 7
2023-12-23 05:27:54.868083: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 1
2023-12-23 05:27:54.868092: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 7
2023-12-23 05:27:54.868100: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 2
2023-12-23 05:27:54.868109: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 8
2023-12-23 05:27:54.868118: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 2
2023-12-23 05:27:54.868126: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 0
2023-12-23 05:27:54.868134: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 3
2023-12-23 05:27:54.868143: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 1
2023-12-23 05:27:54.868152: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 2
2023-12-23 05:27:54.868160: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 1
2023-12-23 05:27:54.868168: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 3
2023-12-23 05:27:54.868177: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 2
2023-12-23 05:27:54.868186: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 2
2023-12-23 05:27:54.868195: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 2
2023-12-23 05:27:54.868203: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 2
2023-12-23 05:27:54.868211: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 3
2023-12-23 05:27:54.868219: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 3
2023-12-23 05:27:54.868228: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 4
2023-12-23 05:27:54.868237: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 2
2023-12-23 05:27:54.868246: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 4
2023-12-23 05:27:54.868253: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 3
2023-12-23 05:27:54.868262: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 5
2023-12-23 05:27:54.868271: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 2
2023-12-23 05:27:54.868279: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 5
2023-12-23 05:27:54.868288: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 3
2023-12-23 05:27:54.868296: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 6
2023-12-23 05:27:54.868305: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 2
2023-12-23 05:27:54.868314: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 6
2023-12-23 05:27:54.868321: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 3
2023-12-23 05:27:54.868330: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 7
2023-12-23 05:27:54.868339: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 2
2023-12-23 05:27:54.868347: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 7
2023-12-23 05:27:54.868355: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 3
2023-12-23 05:27:54.868363: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 8
2023-12-23 05:27:54.868372: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 3
2023-12-23 05:27:54.868381: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 0
2023-12-23 05:27:54.868389: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 4
2023-12-23 05:27:54.868397: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 1
2023-12-23 05:27:54.868406: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 3
2023-12-23 05:27:54.868415: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 1
2023-12-23 05:27:54.868423: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 4
2023-12-23 05:27:54.868431: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 2
2023-12-23 05:27:54.868442: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 3
2023-12-23 05:27:54.868451: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 2
2023-12-23 05:27:54.868459: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 4
2023-12-23 05:27:54.868467: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 3
2023-12-23 05:27:54.868477: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 3
2023-12-23 05:27:54.868485: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 3
2023-12-23 05:27:54.868493: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 3
2023-12-23 05:27:54.868501: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 4
2023-12-23 05:27:54.868510: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 4
2023-12-23 05:27:54.868518: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 5
2023-12-23 05:27:54.868527: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 3
2023-12-23 05:27:54.868536: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 5
2023-12-23 05:27:54.868544: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 4
2023-12-23 05:27:54.868553: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 6
2023-12-23 05:27:54.868562: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 3
2023-12-23 05:27:54.868570: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 6
2023-12-23 05:27:54.868578: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 4
2023-12-23 05:27:54.868587: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 7
2023-12-23 05:27:54.868596: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 3
2023-12-23 05:27:54.868604: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 7
2023-12-23 05:27:54.868612: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 4
2023-12-23 05:27:54.868621: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 8
2023-12-23 05:27:54.868630: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 4
2023-12-23 05:27:54.868638: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 0
2023-12-23 05:27:54.868646: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 5
2023-12-23 05:27:54.868654: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 1
2023-12-23 05:27:54.868663: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 4
2023-12-23 05:27:54.868672: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 1
2023-12-23 05:27:54.868680: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 5
2023-12-23 05:27:54.868689: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 2
2023-12-23 05:27:54.868698: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 4
2023-12-23 05:27:54.868706: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 2
2023-12-23 05:27:54.868714: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 5
2023-12-23 05:27:54.868723: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 3
2023-12-23 05:27:54.868732: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 4
2023-12-23 05:27:54.868740: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 3
2023-12-23 05:27:54.868748: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 5
2023-12-23 05:27:54.868757: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 4
2023-12-23 05:27:54.868766: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 4
2023-12-23 05:27:54.868774: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 4
2023-12-23 05:27:54.868782: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 4
2023-12-23 05:27:54.868791: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 5
2023-12-23 05:27:54.868799: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 5
2023-12-23 05:27:54.868807: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 6
2023-12-23 05:27:54.868816: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 4
2023-12-23 05:27:54.868825: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 6
2023-12-23 05:27:54.868833: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 5
2023-12-23 05:27:54.868842: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 7
2023-12-23 05:27:54.868851: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 4
2023-12-23 05:27:54.868860: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 7
2023-12-23 05:27:54.868867: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 5
2023-12-23 05:27:54.868876: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 8
2023-12-23 05:27:54.868885: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 5
2023-12-23 05:27:54.868894: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 0
2023-12-23 05:27:54.868902: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 6
2023-12-23 05:27:54.868910: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 1
2023-12-23 05:27:54.868919: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 5
2023-12-23 05:27:54.868928: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 1
2023-12-23 05:27:54.868936: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 6
2023-12-23 05:27:54.868944: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 2
2023-12-23 05:27:54.868954: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 5
2023-12-23 05:27:54.868962: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 2
2023-12-23 05:27:54.868970: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 6
2023-12-23 05:27:54.868978: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 3
2023-12-23 05:27:54.868988: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 5
2023-12-23 05:27:54.868996: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 3
2023-12-23 05:27:54.869009: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 6
2023-12-23 05:27:54.869018: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 4
2023-12-23 05:27:54.869027: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 5
2023-12-23 05:27:54.869036: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 4
2023-12-23 05:27:54.869044: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 6
2023-12-23 05:27:54.869052: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 5
2023-12-23 05:27:54.869061: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 5
2023-12-23 05:27:54.869070: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 5
2023-12-23 05:27:54.869078: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 5
2023-12-23 05:27:54.869086: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 6
2023-12-23 05:27:54.869094: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 6
2023-12-23 05:27:54.869103: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 7
2023-12-23 05:27:54.869112: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 5
2023-12-23 05:27:54.869121: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 7
2023-12-23 05:27:54.869129: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 6
2023-12-23 05:27:54.869137: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 8
2023-12-23 05:27:54.869147: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 6
2023-12-23 05:27:54.869155: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 0
2023-12-23 05:27:54.869163: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 7
2023-12-23 05:27:54.869172: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 1
2023-12-23 05:27:54.869181: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 6
2023-12-23 05:27:54.869189: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 1
2023-12-23 05:27:54.869197: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 7
2023-12-23 05:27:54.869206: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 2
2023-12-23 05:27:54.869215: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 6
2023-12-23 05:27:54.869224: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 2
2023-12-23 05:27:54.869232: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 7
2023-12-23 05:27:54.869241: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 3
2023-12-23 05:27:54.869250: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 6
2023-12-23 05:27:54.869258: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 3
2023-12-23 05:27:54.869267: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 7
2023-12-23 05:27:54.869275: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 4
2023-12-23 05:27:54.869286: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 6
2023-12-23 05:27:54.869294: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 4
2023-12-23 05:27:54.869303: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 7
2023-12-23 05:27:54.869312: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 5
2023-12-23 05:27:54.869320: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 6
2023-12-23 05:27:54.869329: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 5
2023-12-23 05:27:54.869337: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 7
2023-12-23 05:27:54.869346: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 6
2023-12-23 05:27:54.869355: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 6
2023-12-23 05:27:54.869363: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 6
2023-12-23 05:27:54.869372: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 6
2023-12-23 05:27:54.869380: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 7
2023-12-23 05:27:54.869388: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 7
2023-12-23 05:27:54.869397: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 8
2023-12-23 05:27:54.869406: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 7
2023-12-23 05:27:54.869415: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 0
2023-12-23 05:27:54.869423: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 8
2023-12-23 05:27:54.869431: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 1
2023-12-23 05:27:54.869441: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 7
2023-12-23 05:27:54.869449: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 1
2023-12-23 05:27:54.869457: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 8
2023-12-23 05:27:54.869466: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 2
2023-12-23 05:27:54.869475: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 7
2023-12-23 05:27:54.869483: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 2
2023-12-23 05:27:54.869492: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 8
2023-12-23 05:27:54.869500: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 3
2023-12-23 05:27:54.869510: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 7
2023-12-23 05:27:54.869518: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 3
2023-12-23 05:27:54.869526: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 8
2023-12-23 05:27:54.869534: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 4
2023-12-23 05:27:54.869544: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 7
2023-12-23 05:27:54.869552: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 4
2023-12-23 05:27:54.869560: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 8
2023-12-23 05:27:54.869569: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 5
2023-12-23 05:27:54.869578: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 7
2023-12-23 05:27:54.869586: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 5
2023-12-23 05:27:54.869595: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 8
2023-12-23 05:27:54.869603: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 6
2023-12-23 05:27:54.869612: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 7
2023-12-23 05:27:54.869621: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 6
2023-12-23 05:27:54.869629: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 8
2023-12-23 05:27:54.869637: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 7
2023-12-23 05:27:54.869647: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 7
2023-12-23 05:27:54.869655: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 7
2023-12-23 05:27:54.869678: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1274] Device interconnect StreamExecutor with strength 1 edge matrix:
2023-12-23 05:27:54.869690: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280]      0 1 2 3 4 5 6 7 
2023-12-23 05:27:54.869702: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1293] 0:   N Y Y Y Y Y Y Y 
2023-12-23 05:27:54.869711: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1293] 1:   Y N Y Y Y Y Y Y 
2023-12-23 05:27:54.869719: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1293] 2:   Y Y N Y Y Y Y Y 
2023-12-23 05:27:54.869727: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1293] 3:   Y Y Y N Y Y Y Y 
2023-12-23 05:27:54.869735: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1293] 4:   Y Y Y Y N Y Y Y 
2023-12-23 05:27:54.869744: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1293] 5:   Y Y Y Y Y N Y Y 
2023-12-23 05:27:54.869752: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1293] 6:   Y Y Y Y Y Y N Y 
2023-12-23 05:27:54.869760: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1293] 7:   Y Y Y Y Y Y Y N 
2023-12-23 05:27:54.869779: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 0
2023-12-23 05:27:54.869789: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 1
2023-12-23 05:27:54.869923: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:252] found DLL info with name: /usr/lib/x86_64-linux-gnu/libcuda.so.1
2023-12-23 05:27:54.869950: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:257] found DLL info with resolved path: /usr/lib/x86_64-linux-gnu/libcuda.so.450.51.05
2023-12-23 05:27:54.869965: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:106] version string "450.51.05" made value 450.51.5
2023-12-23 05:27:54.869980: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:915] trying to read NUMA node for device ordinal: 0
2023-12-23 05:27:54.871331: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 1
2023-12-23 05:27:54.871350: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 2
2023-12-23 05:27:54.871407: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:252] found DLL info with name: /usr/lib/x86_64-linux-gnu/libcuda.so.1
2023-12-23 05:27:54.871427: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:257] found DLL info with resolved path: /usr/lib/x86_64-linux-gnu/libcuda.so.450.51.05
2023-12-23 05:27:54.871439: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:106] version string "450.51.05" made value 450.51.5
2023-12-23 05:27:54.871451: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:915] trying to read NUMA node for device ordinal: 1
2023-12-23 05:27:54.872753: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 2
2023-12-23 05:27:54.872777: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 3
2023-12-23 05:27:54.872825: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:252] found DLL info with name: /usr/lib/x86_64-linux-gnu/libcuda.so.1
2023-12-23 05:27:54.872842: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:257] found DLL info with resolved path: /usr/lib/x86_64-linux-gnu/libcuda.so.450.51.05
2023-12-23 05:27:54.872853: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:106] version string "450.51.05" made value 450.51.5
2023-12-23 05:27:54.872864: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:915] trying to read NUMA node for device ordinal: 2
2023-12-23 05:27:54.874312: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 3
2023-12-23 05:27:54.874340: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 4
2023-12-23 05:27:54.874393: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:252] found DLL info with name: /usr/lib/x86_64-linux-gnu/libcuda.so.1
2023-12-23 05:27:54.874412: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:257] found DLL info with resolved path: /usr/lib/x86_64-linux-gnu/libcuda.so.450.51.05
2023-12-23 05:27:54.874424: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:106] version string "450.51.05" made value 450.51.5
2023-12-23 05:27:54.874436: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:915] trying to read NUMA node for device ordinal: 3
2023-12-23 05:27:54.875901: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 4
2023-12-23 05:27:54.875924: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 5
2023-12-23 05:27:54.875971: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:252] found DLL info with name: /usr/lib/x86_64-linux-gnu/libcuda.so.1
2023-12-23 05:27:54.875988: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:257] found DLL info with resolved path: /usr/lib/x86_64-linux-gnu/libcuda.so.450.51.05
2023-12-23 05:27:54.875999: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:106] version string "450.51.05" made value 450.51.5
2023-12-23 05:27:54.876015: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:915] trying to read NUMA node for device ordinal: 4
2023-12-23 05:27:54.877210: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 5
2023-12-23 05:27:54.877225: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 6
2023-12-23 05:27:54.877268: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:252] found DLL info with name: /usr/lib/x86_64-linux-gnu/libcuda.so.1
2023-12-23 05:27:54.877285: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:257] found DLL info with resolved path: /usr/lib/x86_64-linux-gnu/libcuda.so.450.51.05
2023-12-23 05:27:54.877296: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:106] version string "450.51.05" made value 450.51.5
2023-12-23 05:27:54.877308: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:915] trying to read NUMA node for device ordinal: 5
2023-12-23 05:27:54.878602: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 6
2023-12-23 05:27:54.878620: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 7
2023-12-23 05:27:54.878665: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:252] found DLL info with name: /usr/lib/x86_64-linux-gnu/libcuda.so.1
2023-12-23 05:27:54.878683: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:257] found DLL info with resolved path: /usr/lib/x86_64-linux-gnu/libcuda.so.450.51.05
2023-12-23 05:27:54.878695: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:106] version string "450.51.05" made value 450.51.5
2023-12-23 05:27:54.878706: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:915] trying to read NUMA node for device ordinal: 6
2023-12-23 05:27:54.879994: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 7
2023-12-23 05:27:54.880020: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 8
2023-12-23 05:27:54.880061: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:252] found DLL info with name: /usr/lib/x86_64-linux-gnu/libcuda.so.1
2023-12-23 05:27:54.880078: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:257] found DLL info with resolved path: /usr/lib/x86_64-linux-gnu/libcuda.so.450.51.05
2023-12-23 05:27:54.880089: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:106] version string "450.51.05" made value 450.51.5
2023-12-23 05:27:54.880100: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:915] trying to read NUMA node for device ordinal: 7
2023-12-23 05:27:54.881361: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:252] found DLL info with name: /usr/lib/x86_64-linux-gnu/libcuda.so.1
2023-12-23 05:27:54.881379: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:257] found DLL info with resolved path: /usr/lib/x86_64-linux-gnu/libcuda.so.450.51.05
2023-12-23 05:27:54.881389: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:106] version string "450.51.05" made value 450.51.5
2023-12-23 05:27:54.881400: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:915] trying to read NUMA node for device ordinal: 0
2023-12-23 05:27:54.882963: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1588] GPUDevice PlatformDeviceId 0 TfDeviceId 0 on bus 1 numa: 0 pci: 0000:3d:00.0 DeviceLocality: bus_id: 1
links {
  link {
    device_id: 1
    type: "StreamExecutor"
    strength: 1
  }
  link {
    device_id: 2
    type: "StreamExecutor"
    strength: 1
  }
  link {
    device_id: 3
    type: "StreamExecutor"
    strength: 1
  }
  link {
    device_id: 4
    type: "StreamExecutor"
    strength: 1
  }
  link {
    device_id: 5
    type: "StreamExecutor"
    strength: 1
  }
  link {
    device_id: 6
    type: "StreamExecutor"
    strength: 1
  }
  link {
    device_id: 7
    type: "StreamExecutor"
    strength: 1
  }
}

2023-12-23 05:27:54.883028: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:252] found DLL info with name: /usr/lib/x86_64-linux-gnu/libcuda.so.1
2023-12-23 05:27:54.883046: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:257] found DLL info with resolved path: /usr/lib/x86_64-linux-gnu/libcuda.so.450.51.05
2023-12-23 05:27:54.883056: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:106] version string "450.51.05" made value 450.51.5
2023-12-23 05:27:54.883067: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:915] trying to read NUMA node for device ordinal: 1
2023-12-23 05:27:54.884409: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1588] GPUDevice PlatformDeviceId 1 TfDeviceId 1 on bus 1 numa: 0 pci: 0000:3e:00.0 DeviceLocality: bus_id: 1
links {
  link {
    type: "StreamExecutor"
    strength: 1
  }
  link {
    device_id: 2
    type: "StreamExecutor"
    strength: 1
  }
  link {
    device_id: 3
    type: "StreamExecutor"
    strength: 1
  }
  link {
    device_id: 4
    type: "StreamExecutor"
    strength: 1
  }
  link {
    device_id: 5
    type: "StreamExecutor"
    strength: 1
  }
  link {
    device_id: 6
    type: "StreamExecutor"
    strength: 1
  }
  link {
    device_id: 7
    type: "StreamExecutor"
    strength: 1
  }
}

2023-12-23 05:27:54.884475: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:252] found DLL info with name: /usr/lib/x86_64-linux-gnu/libcuda.so.1
2023-12-23 05:27:54.884491: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:257] found DLL info with resolved path: /usr/lib/x86_64-linux-gnu/libcuda.so.450.51.05
2023-12-23 05:27:54.884502: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:106] version string "450.51.05" made value 450.51.5
2023-12-23 05:27:54.884513: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:915] trying to read NUMA node for device ordinal: 2
2023-12-23 05:27:54.885816: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1588] GPUDevice PlatformDeviceId 2 TfDeviceId 2 on bus 1 numa: 0 pci: 0000:40:00.0 DeviceLocality: bus_id: 1
links {
  link {
    type: "StreamExecutor"
    strength: 1
  }
  link {
    device_id: 1
    type: "StreamExecutor"
    strength: 1
  }
  link {
    device_id: 3
    type: "StreamExecutor"
    strength: 1
  }
  link {
    device_id: 4
    type: "StreamExecutor"
    strength: 1
  }
  link {
    device_id: 5
    type: "StreamExecutor"
    strength: 1
  }
  link {
    device_id: 6
    type: "StreamExecutor"
    strength: 1
  }
  link {
    device_id: 7
    type: "StreamExecutor"
    strength: 1
  }
}

2023-12-23 05:27:54.885871: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:252] found DLL info with name: /usr/lib/x86_64-linux-gnu/libcuda.so.1
2023-12-23 05:27:54.885889: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:257] found DLL info with resolved path: /usr/lib/x86_64-linux-gnu/libcuda.so.450.51.05
2023-12-23 05:27:54.885900: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:106] version string "450.51.05" made value 450.51.5
2023-12-23 05:27:54.885913: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:915] trying to read NUMA node for device ordinal: 3
2023-12-23 05:27:54.887196: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1588] GPUDevice PlatformDeviceId 3 TfDeviceId 3 on bus 1 numa: 0 pci: 0000:41:00.0 DeviceLocality: bus_id: 1
links {
  link {
    type: "StreamExecutor"
    strength: 1
  }
  link {
    device_id: 1
    type: "StreamExecutor"
    strength: 1
  }
  link {
    device_id: 2
    type: "StreamExecutor"
    strength: 1
  }
  link {
    device_id: 4
    type: "StreamExecutor"
    strength: 1
  }
  link {
    device_id: 5
    type: "StreamExecutor"
    strength: 1
  }
  link {
    device_id: 6
    type: "StreamExecutor"
    strength: 1
  }
  link {
    device_id: 7
    type: "StreamExecutor"
    strength: 1
  }
}

2023-12-23 05:27:54.887253: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:252] found DLL info with name: /usr/lib/x86_64-linux-gnu/libcuda.so.1
2023-12-23 05:27:54.887271: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:257] found DLL info with resolved path: /usr/lib/x86_64-linux-gnu/libcuda.so.450.51.05
2023-12-23 05:27:54.887282: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:106] version string "450.51.05" made value 450.51.5
2023-12-23 05:27:54.887294: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:915] trying to read NUMA node for device ordinal: 4
2023-12-23 05:27:54.888608: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1588] GPUDevice PlatformDeviceId 4 TfDeviceId 4 on bus 3 numa: 2 pci: 0000:b1:00.0 DeviceLocality: bus_id: 3
numa_node: 2
links {
  link {
    type: "StreamExecutor"
    strength: 1
  }
  link {
    device_id: 1
    type: "StreamExecutor"
    strength: 1
  }
  link {
    device_id: 2
    type: "StreamExecutor"
    strength: 1
  }
  link {
    device_id: 3
    type: "StreamExecutor"
    strength: 1
  }
  link {
    device_id: 5
    type: "StreamExecutor"
    strength: 1
  }
  link {
    device_id: 6
    type: "StreamExecutor"
    strength: 1
  }
  link {
    device_id: 7
    type: "StreamExecutor"
    strength: 1
  }
}

2023-12-23 05:27:54.888664: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:252] found DLL info with name: /usr/lib/x86_64-linux-gnu/libcuda.so.1
2023-12-23 05:27:54.888683: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:257] found DLL info with resolved path: /usr/lib/x86_64-linux-gnu/libcuda.so.450.51.05
2023-12-23 05:27:54.888694: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:106] version string "450.51.05" made value 450.51.5
2023-12-23 05:27:54.888706: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:915] trying to read NUMA node for device ordinal: 5
2023-12-23 05:27:54.890030: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1588] GPUDevice PlatformDeviceId 5 TfDeviceId 5 on bus 3 numa: 2 pci: 0000:b2:00.0 DeviceLocality: bus_id: 3
numa_node: 2
links {
  link {
    type: "StreamExecutor"
    strength: 1
  }
  link {
    device_id: 1
    type: "StreamExecutor"
    strength: 1
  }
  link {
    device_id: 2
    type: "StreamExecutor"
    strength: 1
  }
  link {
    device_id: 3
    type: "StreamExecutor"
    strength: 1
  }
  link {
    device_id: 4
    type: "StreamExecutor"
    strength: 1
  }
  link {
    device_id: 6
    type: "StreamExecutor"
    strength: 1
  }
  link {
    device_id: 7
    type: "StreamExecutor"
    strength: 1
  }
}

2023-12-23 05:27:54.890098: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:252] found DLL info with name: /usr/lib/x86_64-linux-gnu/libcuda.so.1
2023-12-23 05:27:54.890115: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:257] found DLL info with resolved path: /usr/lib/x86_64-linux-gnu/libcuda.so.450.51.05
2023-12-23 05:27:54.890125: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:106] version string "450.51.05" made value 450.51.5
2023-12-23 05:27:54.890135: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:915] trying to read NUMA node for device ordinal: 6
2023-12-23 05:27:54.891534: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1588] GPUDevice PlatformDeviceId 6 TfDeviceId 6 on bus 3 numa: 2 pci: 0000:b4:00.0 DeviceLocality: bus_id: 3
numa_node: 2
links {
  link {
    type: "StreamExecutor"
    strength: 1
  }
  link {
    device_id: 1
    type: "StreamExecutor"
    strength: 1
  }
  link {
    device_id: 2
    type: "StreamExecutor"
    strength: 1
  }
  link {
    device_id: 3
    type: "StreamExecutor"
    strength: 1
  }
  link {
    device_id: 4
    type: "StreamExecutor"
    strength: 1
  }
  link {
    device_id: 5
    type: "StreamExecutor"
    strength: 1
  }
  link {
    device_id: 7
    type: "StreamExecutor"
    strength: 1
  }
}

2023-12-23 05:27:54.891594: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:252] found DLL info with name: /usr/lib/x86_64-linux-gnu/libcuda.so.1
2023-12-23 05:27:54.891613: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:257] found DLL info with resolved path: /usr/lib/x86_64-linux-gnu/libcuda.so.450.51.05
2023-12-23 05:27:54.891625: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:106] version string "450.51.05" made value 450.51.5
2023-12-23 05:27:54.891637: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:915] trying to read NUMA node for device ordinal: 7
2023-12-23 05:27:54.892911: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1588] GPUDevice PlatformDeviceId 7 TfDeviceId 7 on bus 3 numa: 2 pci: 0000:b5:00.0 DeviceLocality: bus_id: 3
numa_node: 2
links {
  link {
    type: "StreamExecutor"
    strength: 1
  }
  link {
    device_id: 1
    type: "StreamExecutor"
    strength: 1
  }
  link {
    device_id: 2
    type: "StreamExecutor"
    strength: 1
  }
  link {
    device_id: 3
    type: "StreamExecutor"
    strength: 1
  }
  link {
    device_id: 4
    type: "StreamExecutor"
    strength: 1
  }
  link {
    device_id: 5
    type: "StreamExecutor"
    strength: 1
  }
  link {
    device_id: 6
    type: "StreamExecutor"
    strength: 1
  }
}

2023-12-23 05:27:54.892967: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:252] found DLL info with name: /usr/lib/x86_64-linux-gnu/libcuda.so.1
2023-12-23 05:27:54.892985: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:257] found DLL info with resolved path: /usr/lib/x86_64-linux-gnu/libcuda.so.450.51.05
2023-12-23 05:27:54.892996: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:106] version string "450.51.05" made value 450.51.5
2023-12-23 05:27:54.893012: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:915] trying to read NUMA node for device ordinal: 0
2023-12-23 05:27:54.894313: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 0
2023-12-23 05:27:54.894334: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 0
2023-12-23 05:27:54.894350: I tensorflow/core/common_runtime/bfc_allocator.cc:78] Creating bin of max chunk size 256B
2023-12-23 05:27:54.894359: I tensorflow/core/common_runtime/bfc_allocator.cc:78] Creating bin of max chunk size 512B
2023-12-23 05:27:54.894369: I tensorflow/core/common_runtime/bfc_allocator.cc:78] Creating bin of max chunk size 1.0KiB
2023-12-23 05:27:54.894377: I tensorflow/core/common_runtime/bfc_allocator.cc:78] Creating bin of max chunk size 2.0KiB
2023-12-23 05:27:54.894385: I tensorflow/core/common_runtime/bfc_allocator.cc:78] Creating bin of max chunk size 4.0KiB
2023-12-23 05:27:54.894393: I tensorflow/core/common_runtime/bfc_allocator.cc:78] Creating bin of max chunk size 8.0KiB
2023-12-23 05:27:54.894402: I tensorflow/core/common_runtime/bfc_allocator.cc:78] Creating bin of max chunk size 16.0KiB
2023-12-23 05:27:54.894410: I tensorflow/core/common_runtime/bfc_allocator.cc:78] Creating bin of max chunk size 32.0KiB
2023-12-23 05:27:54.894419: I tensorflow/core/common_runtime/bfc_allocator.cc:78] Creating bin of max chunk size 64.0KiB
2023-12-23 05:27:54.894427: I tensorflow/core/common_runtime/bfc_allocator.cc:78] Creating bin of max chunk size 128.0KiB
2023-12-23 05:27:54.894436: I tensorflow/core/common_runtime/bfc_allocator.cc:78] Creating bin of max chunk size 256.0KiB
2023-12-23 05:27:54.894445: I tensorflow/core/common_runtime/bfc_allocator.cc:78] Creating bin of max chunk size 512.0KiB
2023-12-23 05:27:54.894453: I tensorflow/core/common_runtime/bfc_allocator.cc:78] Creating bin of max chunk size 1.00MiB
2023-12-23 05:27:54.894461: I tensorflow/core/common_runtime/bfc_allocator.cc:78] Creating bin of max chunk size 2.00MiB
2023-12-23 05:27:54.894469: I tensorflow/core/common_runtime/bfc_allocator.cc:78] Creating bin of max chunk size 4.00MiB
2023-12-23 05:27:54.894477: I tensorflow/core/common_runtime/bfc_allocator.cc:78] Creating bin of max chunk size 8.00MiB
2023-12-23 05:27:54.894484: I tensorflow/core/common_runtime/bfc_allocator.cc:78] Creating bin of max chunk size 16.00MiB
2023-12-23 05:27:54.894491: I tensorflow/core/common_runtime/bfc_allocator.cc:78] Creating bin of max chunk size 32.00MiB
2023-12-23 05:27:54.894500: I tensorflow/core/common_runtime/bfc_allocator.cc:78] Creating bin of max chunk size 64.00MiB
2023-12-23 05:27:54.894508: I tensorflow/core/common_runtime/bfc_allocator.cc:78] Creating bin of max chunk size 128.00MiB
2023-12-23 05:27:54.894517: I tensorflow/core/common_runtime/bfc_allocator.cc:78] Creating bin of max chunk size 256.00MiB
2023-12-23 05:27:54.894551: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1462] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 6346 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:3d:00.0, compute capability: 7.5)
2023-12-23 05:27:54.894562: I tensorflow/core/common_runtime/gpu/gpu_device.cc:441] BaseGPUDevice::Init device_id: 0x0
2023-12-23 05:27:54.894571: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 0
2023-12-23 05:27:54.894597: I tensorflow/stream_executor/stream.cc:256] [stream=0x5a9132e0,impl=0x1c418c40] Called Stream::Stream(parent=0x1e9b600)
2023-12-23 05:27:54.894607: I tensorflow/stream_executor/stream.cc:298] [stream=0x5a9132e0,impl=0x1c418c40] Called Stream::Init()
2023-12-23 05:27:54.894617: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 1
2023-12-23 05:27:54.894675: I tensorflow/stream_executor/cuda/cuda_driver.cc:844] successfully created stream 0x36fea820 for context 0x1eafff0 on thread
2023-12-23 05:27:54.894684: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 1
2023-12-23 05:27:54.894696: I tensorflow/core/common_runtime/gpu/gpu_device.cc:254] Created stream[0] = 0x5a9132e0 with priority: 0
2023-12-23 05:27:54.894707: I tensorflow/stream_executor/stream.cc:256] [stream=0x5a6e0670,impl=0x5a6dcd30] Called Stream::Stream(parent=0x1e9b600)
2023-12-23 05:27:54.894717: I tensorflow/stream_executor/stream.cc:298] [stream=0x5a6e0670,impl=0x5a6dcd30] Called Stream::Init()
2023-12-23 05:27:54.894724: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 1
2023-12-23 05:27:54.894735: I tensorflow/stream_executor/cuda/cuda_driver.cc:844] successfully created stream 0x3fea7d80 for context 0x1eafff0 on thread
2023-12-23 05:27:54.894744: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 1
2023-12-23 05:27:54.894753: I tensorflow/core/common_runtime/gpu/gpu_device.cc:273] Created host_to_device_stream[0] = 0x5a6e0670
2023-12-23 05:27:54.894763: I tensorflow/stream_executor/stream.cc:256] [stream=0x51838640,impl=0x5a6e0f10] Called Stream::Stream(parent=0x1e9b600)
2023-12-23 05:27:54.894773: I tensorflow/stream_executor/stream.cc:298] [stream=0x51838640,impl=0x5a6e0f10] Called Stream::Init()
2023-12-23 05:27:54.894781: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 1
2023-12-23 05:27:54.895217: I tensorflow/stream_executor/cuda/cuda_driver.cc:844] successfully created stream 0x3f6cbe90 for context 0x1eafff0 on thread
2023-12-23 05:27:54.895234: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 1
2023-12-23 05:27:54.895248: I tensorflow/core/common_runtime/gpu/gpu_device.cc:278] Created device_to_host_stream[0] = 0x51838640
2023-12-23 05:27:54.895263: I tensorflow/stream_executor/stream.cc:256] [stream=0x5a6f1270,impl=0x5590200] Called Stream::Stream(parent=0x1e9b600)
2023-12-23 05:27:54.895273: I tensorflow/stream_executor/stream.cc:298] [stream=0x5a6f1270,impl=0x5590200] Called Stream::Init()
2023-12-23 05:27:54.895282: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 1
2023-12-23 05:27:54.895297: I tensorflow/stream_executor/cuda/cuda_driver.cc:844] successfully created stream 0x3f6d13c0 for context 0x1eafff0 on thread
2023-12-23 05:27:54.895306: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 1
2023-12-23 05:27:54.895316: I tensorflow/core/common_runtime/gpu/gpu_device.cc:294] Created device_to_device_stream[0] = 0x5a6f1270
2023-12-23 05:27:54.895549: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:252] found DLL info with name: /usr/lib/x86_64-linux-gnu/libcuda.so.1
2023-12-23 05:27:54.895567: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:257] found DLL info with resolved path: /usr/lib/x86_64-linux-gnu/libcuda.so.450.51.05
2023-12-23 05:27:54.895577: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:106] version string "450.51.05" made value 450.51.5
2023-12-23 05:27:54.895588: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:915] trying to read NUMA node for device ordinal: 1
2023-12-23 05:27:54.896851: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 1
2023-12-23 05:27:54.896864: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 1
2023-12-23 05:27:54.896877: I tensorflow/core/common_runtime/bfc_allocator.cc:78] Creating bin of max chunk size 256B
2023-12-23 05:27:54.896885: I tensorflow/core/common_runtime/bfc_allocator.cc:78] Creating bin of max chunk size 512B
2023-12-23 05:27:54.896894: I tensorflow/core/common_runtime/bfc_allocator.cc:78] Creating bin of max chunk size 1.0KiB
2023-12-23 05:27:54.896902: I tensorflow/core/common_runtime/bfc_allocator.cc:78] Creating bin of max chunk size 2.0KiB
2023-12-23 05:27:54.896909: I tensorflow/core/common_runtime/bfc_allocator.cc:78] Creating bin of max chunk size 4.0KiB
2023-12-23 05:27:54.896918: I tensorflow/core/common_runtime/bfc_allocator.cc:78] Creating bin of max chunk size 8.0KiB
2023-12-23 05:27:54.896925: I tensorflow/core/common_runtime/bfc_allocator.cc:78] Creating bin of max chunk size 16.0KiB
2023-12-23 05:27:54.896934: I tensorflow/core/common_runtime/bfc_allocator.cc:78] Creating bin of max chunk size 32.0KiB
2023-12-23 05:27:54.896943: I tensorflow/core/common_runtime/bfc_allocator.cc:78] Creating bin of max chunk size 64.0KiB
2023-12-23 05:27:54.896951: I tensorflow/core/common_runtime/bfc_allocator.cc:78] Creating bin of max chunk size 128.0KiB
2023-12-23 05:27:54.896960: I tensorflow/core/common_runtime/bfc_allocator.cc:78] Creating bin of max chunk size 256.0KiB
2023-12-23 05:27:54.896969: I tensorflow/core/common_runtime/bfc_allocator.cc:78] Creating bin of max chunk size 512.0KiB
2023-12-23 05:27:54.896978: I tensorflow/core/common_runtime/bfc_allocator.cc:78] Creating bin of max chunk size 1.00MiB
2023-12-23 05:27:54.896986: I tensorflow/core/common_runtime/bfc_allocator.cc:78] Creating bin of max chunk size 2.00MiB
2023-12-23 05:27:54.896994: I tensorflow/core/common_runtime/bfc_allocator.cc:78] Creating bin of max chunk size 4.00MiB
2023-12-23 05:27:54.897003: I tensorflow/core/common_runtime/bfc_allocator.cc:78] Creating bin of max chunk size 8.00MiB
2023-12-23 05:27:54.897017: I tensorflow/core/common_runtime/bfc_allocator.cc:78] Creating bin of max chunk size 16.00MiB
2023-12-23 05:27:54.897025: I tensorflow/core/common_runtime/bfc_allocator.cc:78] Creating bin of max chunk size 32.00MiB
2023-12-23 05:27:54.897034: I tensorflow/core/common_runtime/bfc_allocator.cc:78] Creating bin of max chunk size 64.00MiB
2023-12-23 05:27:54.897042: I tensorflow/core/common_runtime/bfc_allocator.cc:78] Creating bin of max chunk size 128.00MiB
2023-12-23 05:27:54.897051: I tensorflow/core/common_runtime/bfc_allocator.cc:78] Creating bin of max chunk size 256.00MiB
2023-12-23 05:27:54.897077: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1462] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 6346 MB memory) -> physical GPU (device: 1, name: Tesla T4, pci bus id: 0000:3e:00.0, compute capability: 7.5)
2023-12-23 05:27:54.897088: I tensorflow/core/common_runtime/gpu/gpu_device.cc:441] BaseGPUDevice::Init device_id: 0x1
2023-12-23 05:27:54.897098: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 1
2023-12-23 05:27:54.897113: I tensorflow/stream_executor/stream.cc:256] [stream=0x5a703460,impl=0x5a702ac0] Called Stream::Stream(parent=0x2427440)
2023-12-23 05:27:54.897124: I tensorflow/stream_executor/stream.cc:298] [stream=0x5a703460,impl=0x5a702ac0] Called Stream::Init()
2023-12-23 05:27:54.897134: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 2
2023-12-23 05:27:54.897167: I tensorflow/stream_executor/cuda/cuda_driver.cc:844] successfully created stream 0x3fe6f8f0 for context 0x1ea2bd0 on thread
2023-12-23 05:27:54.897177: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 2
2023-12-23 05:27:54.897186: I tensorflow/core/common_runtime/gpu/gpu_device.cc:254] Created stream[0] = 0x5a703460 with priority: 0
2023-12-23 05:27:54.897197: I tensorflow/stream_executor/stream.cc:256] [stream=0x5a703770,impl=0x5a702a30] Called Stream::Stream(parent=0x2427440)
2023-12-23 05:27:54.897207: I tensorflow/stream_executor/stream.cc:298] [stream=0x5a703770,impl=0x5a702a30] Called Stream::Init()
2023-12-23 05:27:54.897215: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 2
2023-12-23 05:27:54.897227: I tensorflow/stream_executor/cuda/cuda_driver.cc:844] successfully created stream 0x2e123330 for context 0x1ea2bd0 on thread
2023-12-23 05:27:54.897236: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 2
2023-12-23 05:27:54.897246: I tensorflow/core/common_runtime/gpu/gpu_device.cc:273] Created host_to_device_stream[0] = 0x5a703770
2023-12-23 05:27:54.897256: I tensorflow/stream_executor/stream.cc:256] [stream=0x5a703970,impl=0x5a702a60] Called Stream::Stream(parent=0x2427440)
2023-12-23 05:27:54.897267: I tensorflow/stream_executor/stream.cc:298] [stream=0x5a703970,impl=0x5a702a60] Called Stream::Init()
2023-12-23 05:27:54.897275: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 2
2023-12-23 05:27:54.897624: I tensorflow/stream_executor/cuda/cuda_driver.cc:844] successfully created stream 0x51c51ca0 for context 0x1ea2bd0 on thread
2023-12-23 05:27:54.897639: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 2
2023-12-23 05:27:54.897649: I tensorflow/core/common_runtime/gpu/gpu_device.cc:278] Created device_to_host_stream[0] = 0x5a703970
2023-12-23 05:27:54.897660: I tensorflow/stream_executor/stream.cc:256] [stream=0x5a70b6d0,impl=0x5a702a90] Called Stream::Stream(parent=0x2427440)
2023-12-23 05:27:54.897669: I tensorflow/stream_executor/stream.cc:298] [stream=0x5a70b6d0,impl=0x5a702a90] Called Stream::Init()
2023-12-23 05:27:54.897677: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 2
2023-12-23 05:27:54.897689: I tensorflow/stream_executor/cuda/cuda_driver.cc:844] successfully created stream 0x48d132f0 for context 0x1ea2bd0 on thread
2023-12-23 05:27:54.897698: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 2
2023-12-23 05:27:54.897708: I tensorflow/core/common_runtime/gpu/gpu_device.cc:294] Created device_to_device_stream[0] = 0x5a70b6d0
2023-12-23 05:27:54.897895: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:252] found DLL info with name: /usr/lib/x86_64-linux-gnu/libcuda.so.1
2023-12-23 05:27:54.897912: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:257] found DLL info with resolved path: /usr/lib/x86_64-linux-gnu/libcuda.so.450.51.05
2023-12-23 05:27:54.897922: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:106] version string "450.51.05" made value 450.51.5
2023-12-23 05:27:54.897933: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:915] trying to read NUMA node for device ordinal: 2
2023-12-23 05:27:54.899239: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 2
2023-12-23 05:27:54.899258: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 2
2023-12-23 05:27:54.899271: I tensorflow/core/common_runtime/bfc_allocator.cc:78] Creating bin of max chunk size 256B
2023-12-23 05:27:54.899278: I tensorflow/core/common_runtime/bfc_allocator.cc:78] Creating bin of max chunk size 512B
2023-12-23 05:27:54.899289: I tensorflow/core/common_runtime/bfc_allocator.cc:78] Creating bin of max chunk size 1.0KiB
2023-12-23 05:27:54.899297: I tensorflow/core/common_runtime/bfc_allocator.cc:78] Creating bin of max chunk size 2.0KiB
2023-12-23 05:27:54.899305: I tensorflow/core/common_runtime/bfc_allocator.cc:78] Creating bin of max chunk size 4.0KiB
2023-12-23 05:27:54.899312: I tensorflow/core/common_runtime/bfc_allocator.cc:78] Creating bin of max chunk size 8.0KiB
2023-12-23 05:27:54.899319: I tensorflow/core/common_runtime/bfc_allocator.cc:78] Creating bin of max chunk size 16.0KiB
2023-12-23 05:27:54.899327: I tensorflow/core/common_runtime/bfc_allocator.cc:78] Creating bin of max chunk size 32.0KiB
2023-12-23 05:27:54.899335: I tensorflow/core/common_runtime/bfc_allocator.cc:78] Creating bin of max chunk size 64.0KiB
2023-12-23 05:27:54.899343: I tensorflow/core/common_runtime/bfc_allocator.cc:78] Creating bin of max chunk size 128.0KiB
2023-12-23 05:27:54.899351: I tensorflow/core/common_runtime/bfc_allocator.cc:78] Creating bin of max chunk size 256.0KiB
2023-12-23 05:27:54.899359: I tensorflow/core/common_runtime/bfc_allocator.cc:78] Creating bin of max chunk size 512.0KiB
2023-12-23 05:27:54.899366: I tensorflow/core/common_runtime/bfc_allocator.cc:78] Creating bin of max chunk size 1.00MiB
2023-12-23 05:27:54.899374: I tensorflow/core/common_runtime/bfc_allocator.cc:78] Creating bin of max chunk size 2.00MiB
2023-12-23 05:27:54.899382: I tensorflow/core/common_runtime/bfc_allocator.cc:78] Creating bin of max chunk size 4.00MiB
2023-12-23 05:27:54.899390: I tensorflow/core/common_runtime/bfc_allocator.cc:78] Creating bin of max chunk size 8.00MiB
2023-12-23 05:27:54.899399: I tensorflow/core/common_runtime/bfc_allocator.cc:78] Creating bin of max chunk size 16.00MiB
2023-12-23 05:27:54.899407: I tensorflow/core/common_runtime/bfc_allocator.cc:78] Creating bin of max chunk size 32.00MiB
2023-12-23 05:27:54.899416: I tensorflow/core/common_runtime/bfc_allocator.cc:78] Creating bin of max chunk size 64.00MiB
2023-12-23 05:27:54.899425: I tensorflow/core/common_runtime/bfc_allocator.cc:78] Creating bin of max chunk size 128.00MiB
2023-12-23 05:27:54.899434: I tensorflow/core/common_runtime/bfc_allocator.cc:78] Creating bin of max chunk size 256.00MiB
2023-12-23 05:27:54.899458: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1462] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:2 with 6346 MB memory) -> physical GPU (device: 2, name: Tesla T4, pci bus id: 0000:40:00.0, compute capability: 7.5)
2023-12-23 05:27:54.899469: I tensorflow/core/common_runtime/gpu/gpu_device.cc:441] BaseGPUDevice::Init device_id: 0x2
2023-12-23 05:27:54.899479: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 2
2023-12-23 05:27:54.899493: I tensorflow/stream_executor/stream.cc:256] [stream=0x5a71db80,impl=0x5a71d1e0] Called Stream::Stream(parent=0x2a7d1d0)
2023-12-23 05:27:54.899503: I tensorflow/stream_executor/stream.cc:298] [stream=0x5a71db80,impl=0x5a71d1e0] Called Stream::Init()
2023-12-23 05:27:54.899513: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 3
2023-12-23 05:27:54.899550: I tensorflow/stream_executor/cuda/cuda_driver.cc:844] successfully created stream 0x1c408390 for context 0x1edd0a0 on thread
2023-12-23 05:27:54.899559: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 3
2023-12-23 05:27:54.899568: I tensorflow/core/common_runtime/gpu/gpu_device.cc:254] Created stream[0] = 0x5a71db80 with priority: 0
2023-12-23 05:27:54.899579: I tensorflow/stream_executor/stream.cc:256] [stream=0x5a71de90,impl=0x5a71d150] Called Stream::Stream(parent=0x2a7d1d0)
2023-12-23 05:27:54.899589: I tensorflow/stream_executor/stream.cc:298] [stream=0x5a71de90,impl=0x5a71d150] Called Stream::Init()
2023-12-23 05:27:54.899597: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 3
2023-12-23 05:27:54.899608: I tensorflow/stream_executor/cuda/cuda_driver.cc:844] successfully created stream 0x5590990 for context 0x1edd0a0 on thread
2023-12-23 05:27:54.899617: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 3
2023-12-23 05:27:54.899626: I tensorflow/core/common_runtime/gpu/gpu_device.cc:273] Created host_to_device_stream[0] = 0x5a71de90
2023-12-23 05:27:54.899637: I tensorflow/stream_executor/stream.cc:256] [stream=0x5a71e090,impl=0x5a71d180] Called Stream::Stream(parent=0x2a7d1d0)
2023-12-23 05:27:54.899647: I tensorflow/stream_executor/stream.cc:298] [stream=0x5a71e090,impl=0x5a71d180] Called Stream::Init()
2023-12-23 05:27:54.899655: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 3
2023-12-23 05:27:54.900009: I tensorflow/stream_executor/cuda/cuda_driver.cc:844] successfully created stream 0x5a6ddd10 for context 0x1edd0a0 on thread
2023-12-23 05:27:54.900024: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 3
2023-12-23 05:27:54.900034: I tensorflow/core/common_runtime/gpu/gpu_device.cc:278] Created device_to_host_stream[0] = 0x5a71e090
2023-12-23 05:27:54.900045: I tensorflow/stream_executor/stream.cc:256] [stream=0x5a725e70,impl=0x5a71d1b0] Called Stream::Stream(parent=0x2a7d1d0)
2023-12-23 05:27:54.900054: I tensorflow/stream_executor/stream.cc:298] [stream=0x5a725e70,impl=0x5a71d1b0] Called Stream::Init()
2023-12-23 05:27:54.900062: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 3
2023-12-23 05:27:54.900073: I tensorflow/stream_executor/cuda/cuda_driver.cc:844] successfully created stream 0x1e8d2c0 for context 0x1edd0a0 on thread
2023-12-23 05:27:54.900081: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 3
2023-12-23 05:27:54.900090: I tensorflow/core/common_runtime/gpu/gpu_device.cc:294] Created device_to_device_stream[0] = 0x5a725e70
2023-12-23 05:27:54.900295: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:252] found DLL info with name: /usr/lib/x86_64-linux-gnu/libcuda.so.1
2023-12-23 05:27:54.900315: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:257] found DLL info with resolved path: /usr/lib/x86_64-linux-gnu/libcuda.so.450.51.05
2023-12-23 05:27:54.900326: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:106] version string "450.51.05" made value 450.51.5
2023-12-23 05:27:54.900338: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:915] trying to read NUMA node for device ordinal: 3
2023-12-23 05:27:54.901689: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 3
2023-12-23 05:27:54.901705: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 3
2023-12-23 05:27:54.901717: I tensorflow/core/common_runtime/bfc_allocator.cc:78] Creating bin of max chunk size 256B
2023-12-23 05:27:54.901724: I tensorflow/core/common_runtime/bfc_allocator.cc:78] Creating bin of max chunk size 512B
2023-12-23 05:27:54.901733: I tensorflow/core/common_runtime/bfc_allocator.cc:78] Creating bin of max chunk size 1.0KiB
2023-12-23 05:27:54.901740: I tensorflow/core/common_runtime/bfc_allocator.cc:78] Creating bin of max chunk size 2.0KiB
2023-12-23 05:27:54.901748: I tensorflow/core/common_runtime/bfc_allocator.cc:78] Creating bin of max chunk size 4.0KiB
2023-12-23 05:27:54.901756: I tensorflow/core/common_runtime/bfc_allocator.cc:78] Creating bin of max chunk size 8.0KiB
2023-12-23 05:27:54.901765: I tensorflow/core/common_runtime/bfc_allocator.cc:78] Creating bin of max chunk size 16.0KiB
2023-12-23 05:27:54.901774: I tensorflow/core/common_runtime/bfc_allocator.cc:78] Creating bin of max chunk size 32.0KiB
2023-12-23 05:27:54.901782: I tensorflow/core/common_runtime/bfc_allocator.cc:78] Creating bin of max chunk size 64.0KiB
2023-12-23 05:27:54.901791: I tensorflow/core/common_runtime/bfc_allocator.cc:78] Creating bin of max chunk size 128.0KiB
2023-12-23 05:27:54.901800: I tensorflow/core/common_runtime/bfc_allocator.cc:78] Creating bin of max chunk size 256.0KiB
2023-12-23 05:27:54.901808: I tensorflow/core/common_runtime/bfc_allocator.cc:78] Creating bin of max chunk size 512.0KiB
2023-12-23 05:27:54.901817: I tensorflow/core/common_runtime/bfc_allocator.cc:78] Creating bin of max chunk size 1.00MiB
2023-12-23 05:27:54.901826: I tensorflow/core/common_runtime/bfc_allocator.cc:78] Creating bin of max chunk size 2.00MiB
2023-12-23 05:27:54.901834: I tensorflow/core/common_runtime/bfc_allocator.cc:78] Creating bin of max chunk size 4.00MiB
2023-12-23 05:27:54.901843: I tensorflow/core/common_runtime/bfc_allocator.cc:78] Creating bin of max chunk size 8.00MiB
2023-12-23 05:27:54.901851: I tensorflow/core/common_runtime/bfc_allocator.cc:78] Creating bin of max chunk size 16.00MiB
2023-12-23 05:27:54.901860: I tensorflow/core/common_runtime/bfc_allocator.cc:78] Creating bin of max chunk size 32.00MiB
2023-12-23 05:27:54.901869: I tensorflow/core/common_runtime/bfc_allocator.cc:78] Creating bin of max chunk size 64.00MiB
2023-12-23 05:27:54.901877: I tensorflow/core/common_runtime/bfc_allocator.cc:78] Creating bin of max chunk size 128.00MiB
2023-12-23 05:27:54.901886: I tensorflow/core/common_runtime/bfc_allocator.cc:78] Creating bin of max chunk size 256.00MiB
2023-12-23 05:27:54.901909: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1462] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:3 with 6346 MB memory) -> physical GPU (device: 3, name: Tesla T4, pci bus id: 0000:41:00.0, compute capability: 7.5)
2023-12-23 05:27:54.901919: I tensorflow/core/common_runtime/gpu/gpu_device.cc:441] BaseGPUDevice::Init device_id: 0x3
2023-12-23 05:27:54.901929: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 3
2023-12-23 05:27:54.901943: I tensorflow/stream_executor/stream.cc:256] [stream=0x5a738490,impl=0x5a737a20] Called Stream::Stream(parent=0x30dc1f0)
2023-12-23 05:27:54.901954: I tensorflow/stream_executor/stream.cc:298] [stream=0x5a738490,impl=0x5a737a20] Called Stream::Init()
2023-12-23 05:27:54.901963: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 4
2023-12-23 05:27:54.901998: I tensorflow/stream_executor/cuda/cuda_driver.cc:844] successfully created stream 0x5a738660 for context 0x1ee36a0 on thread
2023-12-23 05:27:54.902012: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 4
2023-12-23 05:27:54.902023: I tensorflow/core/common_runtime/gpu/gpu_device.cc:254] Created stream[0] = 0x5a738490 with priority: 0
2023-12-23 05:27:54.902034: I tensorflow/stream_executor/stream.cc:256] [stream=0x5a7387c0,impl=0x5a737990] Called Stream::Stream(parent=0x30dc1f0)
2023-12-23 05:27:54.902044: I tensorflow/stream_executor/stream.cc:298] [stream=0x5a7387c0,impl=0x5a737990] Called Stream::Init()
2023-12-23 05:27:54.902052: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 4
2023-12-23 05:27:54.902066: I tensorflow/stream_executor/cuda/cuda_driver.cc:844] successfully created stream 0x5a738870 for context 0x1ee36a0 on thread
2023-12-23 05:27:54.902074: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 4
2023-12-23 05:27:54.902084: I tensorflow/core/common_runtime/gpu/gpu_device.cc:273] Created host_to_device_stream[0] = 0x5a7387c0
2023-12-23 05:27:54.902094: I tensorflow/stream_executor/stream.cc:256] [stream=0x5a7389e0,impl=0x5a7379c0] Called Stream::Stream(parent=0x30dc1f0)
2023-12-23 05:27:54.902104: I tensorflow/stream_executor/stream.cc:298] [stream=0x5a7389e0,impl=0x5a7379c0] Called Stream::Init()
2023-12-23 05:27:54.902112: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 4
2023-12-23 05:27:54.902455: I tensorflow/stream_executor/cuda/cuda_driver.cc:844] successfully created stream 0x5a738a90 for context 0x1ee36a0 on thread
2023-12-23 05:27:54.902469: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 4
2023-12-23 05:27:54.902479: I tensorflow/core/common_runtime/gpu/gpu_device.cc:278] Created device_to_host_stream[0] = 0x5a7389e0
2023-12-23 05:27:54.902490: I tensorflow/stream_executor/stream.cc:256] [stream=0x5a740840,impl=0x5a7379f0] Called Stream::Stream(parent=0x30dc1f0)
2023-12-23 05:27:54.902498: I tensorflow/stream_executor/stream.cc:298] [stream=0x5a740840,impl=0x5a7379f0] Called Stream::Init()
2023-12-23 05:27:54.902506: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 4
2023-12-23 05:27:54.902518: I tensorflow/stream_executor/cuda/cuda_driver.cc:844] successfully created stream 0x5a7408f0 for context 0x1ee36a0 on thread
2023-12-23 05:27:54.902527: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 4
2023-12-23 05:27:54.902537: I tensorflow/core/common_runtime/gpu/gpu_device.cc:294] Created device_to_device_stream[0] = 0x5a740840
2023-12-23 05:27:54.902717: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:252] found DLL info with name: /usr/lib/x86_64-linux-gnu/libcuda.so.1
2023-12-23 05:27:54.902734: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:257] found DLL info with resolved path: /usr/lib/x86_64-linux-gnu/libcuda.so.450.51.05
2023-12-23 05:27:54.902745: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:106] version string "450.51.05" made value 450.51.5
2023-12-23 05:27:54.902756: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:915] trying to read NUMA node for device ordinal: 4
2023-12-23 05:27:54.904013: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 4
2023-12-23 05:27:54.904026: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 4
2023-12-23 05:27:54.904037: I tensorflow/core/common_runtime/bfc_allocator.cc:78] Creating bin of max chunk size 256B
2023-12-23 05:27:54.904044: I tensorflow/core/common_runtime/bfc_allocator.cc:78] Creating bin of max chunk size 512B
2023-12-23 05:27:54.904054: I tensorflow/core/common_runtime/bfc_allocator.cc:78] Creating bin of max chunk size 1.0KiB
2023-12-23 05:27:54.904061: I tensorflow/core/common_runtime/bfc_allocator.cc:78] Creating bin of max chunk size 2.0KiB
2023-12-23 05:27:54.904068: I tensorflow/core/common_runtime/bfc_allocator.cc:78] Creating bin of max chunk size 4.0KiB
2023-12-23 05:27:54.904076: I tensorflow/core/common_runtime/bfc_allocator.cc:78] Creating bin of max chunk size 8.0KiB
2023-12-23 05:27:54.904084: I tensorflow/core/common_runtime/bfc_allocator.cc:78] Creating bin of max chunk size 16.0KiB
2023-12-23 05:27:54.904092: I tensorflow/core/common_runtime/bfc_allocator.cc:78] Creating bin of max chunk size 32.0KiB
2023-12-23 05:27:54.904099: I tensorflow/core/common_runtime/bfc_allocator.cc:78] Creating bin of max chunk size 64.0KiB
2023-12-23 05:27:54.904108: I tensorflow/core/common_runtime/bfc_allocator.cc:78] Creating bin of max chunk size 128.0KiB
2023-12-23 05:27:54.904116: I tensorflow/core/common_runtime/bfc_allocator.cc:78] Creating bin of max chunk size 256.0KiB
2023-12-23 05:27:54.904124: I tensorflow/core/common_runtime/bfc_allocator.cc:78] Creating bin of max chunk size 512.0KiB
2023-12-23 05:27:54.904132: I tensorflow/core/common_runtime/bfc_allocator.cc:78] Creating bin of max chunk size 1.00MiB
2023-12-23 05:27:54.904140: I tensorflow/core/common_runtime/bfc_allocator.cc:78] Creating bin of max chunk size 2.00MiB
2023-12-23 05:27:54.904147: I tensorflow/core/common_runtime/bfc_allocator.cc:78] Creating bin of max chunk size 4.00MiB
2023-12-23 05:27:54.904155: I tensorflow/core/common_runtime/bfc_allocator.cc:78] Creating bin of max chunk size 8.00MiB
2023-12-23 05:27:54.904162: I tensorflow/core/common_runtime/bfc_allocator.cc:78] Creating bin of max chunk size 16.00MiB
2023-12-23 05:27:54.904170: I tensorflow/core/common_runtime/bfc_allocator.cc:78] Creating bin of max chunk size 32.00MiB
2023-12-23 05:27:54.904178: I tensorflow/core/common_runtime/bfc_allocator.cc:78] Creating bin of max chunk size 64.00MiB
2023-12-23 05:27:54.904186: I tensorflow/core/common_runtime/bfc_allocator.cc:78] Creating bin of max chunk size 128.00MiB
2023-12-23 05:27:54.904194: I tensorflow/core/common_runtime/bfc_allocator.cc:78] Creating bin of max chunk size 256.00MiB
2023-12-23 05:27:54.904215: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1462] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:4 with 6346 MB memory) -> physical GPU (device: 4, name: Tesla T4, pci bus id: 0000:b1:00.0, compute capability: 7.5)
2023-12-23 05:27:54.904225: I tensorflow/core/common_runtime/gpu/gpu_device.cc:441] BaseGPUDevice::Init device_id: 0x4
2023-12-23 05:27:54.904234: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 4
2023-12-23 05:27:54.904248: I tensorflow/stream_executor/stream.cc:256] [stream=0x5a752fd0,impl=0x5a752580] Called Stream::Stream(parent=0x373dba0)
2023-12-23 05:27:54.904256: I tensorflow/stream_executor/stream.cc:298] [stream=0x5a752fd0,impl=0x5a752580] Called Stream::Init()
2023-12-23 05:27:54.904264: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 5
2023-12-23 05:27:54.904301: I tensorflow/stream_executor/cuda/cuda_driver.cc:844] successfully created stream 0x5a753200 for context 0x1ee9ca0 on thread
2023-12-23 05:27:54.904309: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 5
2023-12-23 05:27:54.904318: I tensorflow/core/common_runtime/gpu/gpu_device.cc:254] Created stream[0] = 0x5a752fd0 with priority: 0
2023-12-23 05:27:54.904328: I tensorflow/stream_executor/stream.cc:256] [stream=0x3ad6510,impl=0x5a7524f0] Called Stream::Stream(parent=0x373dba0)
2023-12-23 05:27:54.904336: I tensorflow/stream_executor/stream.cc:298] [stream=0x3ad6510,impl=0x5a7524f0] Called Stream::Init()
2023-12-23 05:27:54.904344: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 5
2023-12-23 05:27:54.904356: I tensorflow/stream_executor/cuda/cuda_driver.cc:844] successfully created stream 0x3ad65c0 for context 0x1ee9ca0 on thread
2023-12-23 05:27:54.904363: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 5
2023-12-23 05:27:54.904371: I tensorflow/core/common_runtime/gpu/gpu_device.cc:273] Created host_to_device_stream[0] = 0x3ad6510
2023-12-23 05:27:54.904381: I tensorflow/stream_executor/stream.cc:256] [stream=0x3ad6730,impl=0x5a752520] Called Stream::Stream(parent=0x373dba0)
2023-12-23 05:27:54.904389: I tensorflow/stream_executor/stream.cc:298] [stream=0x3ad6730,impl=0x5a752520] Called Stream::Init()
2023-12-23 05:27:54.904397: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 5
2023-12-23 05:27:54.904748: I tensorflow/stream_executor/cuda/cuda_driver.cc:844] successfully created stream 0x3ad67e0 for context 0x1ee9ca0 on thread
2023-12-23 05:27:54.904762: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 5
2023-12-23 05:27:54.904773: I tensorflow/core/common_runtime/gpu/gpu_device.cc:278] Created device_to_host_stream[0] = 0x3ad6730
2023-12-23 05:27:54.904784: I tensorflow/stream_executor/stream.cc:256] [stream=0x5a75c7e0,impl=0x5a752550] Called Stream::Stream(parent=0x373dba0)
2023-12-23 05:27:54.904793: I tensorflow/stream_executor/stream.cc:298] [stream=0x5a75c7e0,impl=0x5a752550] Called Stream::Init()
2023-12-23 05:27:54.904801: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 5
2023-12-23 05:27:54.904814: I tensorflow/stream_executor/cuda/cuda_driver.cc:844] successfully created stream 0x5a75c890 for context 0x1ee9ca0 on thread
2023-12-23 05:27:54.904824: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 5
2023-12-23 05:27:54.904834: I tensorflow/core/common_runtime/gpu/gpu_device.cc:294] Created device_to_device_stream[0] = 0x5a75c7e0
2023-12-23 05:27:54.905049: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:252] found DLL info with name: /usr/lib/x86_64-linux-gnu/libcuda.so.1
2023-12-23 05:27:54.905073: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:257] found DLL info with resolved path: /usr/lib/x86_64-linux-gnu/libcuda.so.450.51.05
2023-12-23 05:27:54.905084: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:106] version string "450.51.05" made value 450.51.5
2023-12-23 05:27:54.905095: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:915] trying to read NUMA node for device ordinal: 5
2023-12-23 05:27:54.906559: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 5
2023-12-23 05:27:54.906578: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 5
2023-12-23 05:27:54.906591: I tensorflow/core/common_runtime/bfc_allocator.cc:78] Creating bin of max chunk size 256B
2023-12-23 05:27:54.906599: I tensorflow/core/common_runtime/bfc_allocator.cc:78] Creating bin of max chunk size 512B
2023-12-23 05:27:54.906608: I tensorflow/core/common_runtime/bfc_allocator.cc:78] Creating bin of max chunk size 1.0KiB
2023-12-23 05:27:54.906616: I tensorflow/core/common_runtime/bfc_allocator.cc:78] Creating bin of max chunk size 2.0KiB
2023-12-23 05:27:54.906624: I tensorflow/core/common_runtime/bfc_allocator.cc:78] Creating bin of max chunk size 4.0KiB
2023-12-23 05:27:54.906633: I tensorflow/core/common_runtime/bfc_allocator.cc:78] Creating bin of max chunk size 8.0KiB
2023-12-23 05:27:54.906642: I tensorflow/core/common_runtime/bfc_allocator.cc:78] Creating bin of max chunk size 16.0KiB
2023-12-23 05:27:54.906650: I tensorflow/core/common_runtime/bfc_allocator.cc:78] Creating bin of max chunk size 32.0KiB
2023-12-23 05:27:54.906659: I tensorflow/core/common_runtime/bfc_allocator.cc:78] Creating bin of max chunk size 64.0KiB
2023-12-23 05:27:54.906668: I tensorflow/core/common_runtime/bfc_allocator.cc:78] Creating bin of max chunk size 128.0KiB
2023-12-23 05:27:54.906676: I tensorflow/core/common_runtime/bfc_allocator.cc:78] Creating bin of max chunk size 256.0KiB
2023-12-23 05:27:54.906685: I tensorflow/core/common_runtime/bfc_allocator.cc:78] Creating bin of max chunk size 512.0KiB
2023-12-23 05:27:54.906693: I tensorflow/core/common_runtime/bfc_allocator.cc:78] Creating bin of max chunk size 1.00MiB
2023-12-23 05:27:54.906701: I tensorflow/core/common_runtime/bfc_allocator.cc:78] Creating bin of max chunk size 2.00MiB
2023-12-23 05:27:54.906710: I tensorflow/core/common_runtime/bfc_allocator.cc:78] Creating bin of max chunk size 4.00MiB
2023-12-23 05:27:54.906718: I tensorflow/core/common_runtime/bfc_allocator.cc:78] Creating bin of max chunk size 8.00MiB
2023-12-23 05:27:54.906727: I tensorflow/core/common_runtime/bfc_allocator.cc:78] Creating bin of max chunk size 16.00MiB
2023-12-23 05:27:54.906736: I tensorflow/core/common_runtime/bfc_allocator.cc:78] Creating bin of max chunk size 32.00MiB
2023-12-23 05:27:54.906744: I tensorflow/core/common_runtime/bfc_allocator.cc:78] Creating bin of max chunk size 64.00MiB
2023-12-23 05:27:54.906752: I tensorflow/core/common_runtime/bfc_allocator.cc:78] Creating bin of max chunk size 128.00MiB
2023-12-23 05:27:54.906761: I tensorflow/core/common_runtime/bfc_allocator.cc:78] Creating bin of max chunk size 256.00MiB
2023-12-23 05:27:54.906784: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1462] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:5 with 6346 MB memory) -> physical GPU (device: 5, name: Tesla T4, pci bus id: 0000:b2:00.0, compute capability: 7.5)
2023-12-23 05:27:54.906795: I tensorflow/core/common_runtime/gpu/gpu_device.cc:441] BaseGPUDevice::Init device_id: 0x5
2023-12-23 05:27:54.906805: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 5
2023-12-23 05:27:54.906819: I tensorflow/stream_executor/stream.cc:256] [stream=0x5a76ef30,impl=0x5a76e460] Called Stream::Stream(parent=0x3da8850)
2023-12-23 05:27:54.906830: I tensorflow/stream_executor/stream.cc:298] [stream=0x5a76ef30,impl=0x5a76e460] Called Stream::Init()
2023-12-23 05:27:54.906839: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 6
2023-12-23 05:27:54.906869: I tensorflow/stream_executor/cuda/cuda_driver.cc:844] successfully created stream 0x5a76f160 for context 0x1ef02a0 on thread
2023-12-23 05:27:54.906880: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 6
2023-12-23 05:27:54.906890: I tensorflow/core/common_runtime/gpu/gpu_device.cc:254] Created stream[0] = 0x5a76ef30 with priority: 0
2023-12-23 05:27:54.906902: I tensorflow/stream_executor/stream.cc:256] [stream=0x5a76f2c0,impl=0x5a76e3d0] Called Stream::Stream(parent=0x3da8850)
2023-12-23 05:27:54.906912: I tensorflow/stream_executor/stream.cc:298] [stream=0x5a76f2c0,impl=0x5a76e3d0] Called Stream::Init()
2023-12-23 05:27:54.906921: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 6
2023-12-23 05:27:54.906933: I tensorflow/stream_executor/cuda/cuda_driver.cc:844] successfully created stream 0x5a76f370 for context 0x1ef02a0 on thread
2023-12-23 05:27:54.906942: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 6
2023-12-23 05:27:54.906951: I tensorflow/core/common_runtime/gpu/gpu_device.cc:273] Created host_to_device_stream[0] = 0x5a76f2c0
2023-12-23 05:27:54.906962: I tensorflow/stream_executor/stream.cc:256] [stream=0x5a76f4e0,impl=0x5a76e400] Called Stream::Stream(parent=0x3da8850)
2023-12-23 05:27:54.906972: I tensorflow/stream_executor/stream.cc:298] [stream=0x5a76f4e0,impl=0x5a76e400] Called Stream::Init()
2023-12-23 05:27:54.906980: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 6
2023-12-23 05:27:54.907270: I tensorflow/stream_executor/cuda/cuda_driver.cc:844] successfully created stream 0x5a76f590 for context 0x1ef02a0 on thread
2023-12-23 05:27:54.907284: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 6
2023-12-23 05:27:54.907294: I tensorflow/core/common_runtime/gpu/gpu_device.cc:278] Created device_to_host_stream[0] = 0x5a76f4e0
2023-12-23 05:27:54.907305: I tensorflow/stream_executor/stream.cc:256] [stream=0x5a777340,impl=0x5a76e430] Called Stream::Stream(parent=0x3da8850)
2023-12-23 05:27:54.907313: I tensorflow/stream_executor/stream.cc:298] [stream=0x5a777340,impl=0x5a76e430] Called Stream::Init()
2023-12-23 05:27:54.907320: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 6
2023-12-23 05:27:54.907332: I tensorflow/stream_executor/cuda/cuda_driver.cc:844] successfully created stream 0x5a7773f0 for context 0x1ef02a0 on thread
2023-12-23 05:27:54.907339: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 6
2023-12-23 05:27:54.907348: I tensorflow/core/common_runtime/gpu/gpu_device.cc:294] Created device_to_device_stream[0] = 0x5a777340
2023-12-23 05:27:54.907533: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:252] found DLL info with name: /usr/lib/x86_64-linux-gnu/libcuda.so.1
2023-12-23 05:27:54.907550: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:257] found DLL info with resolved path: /usr/lib/x86_64-linux-gnu/libcuda.so.450.51.05
2023-12-23 05:27:54.907561: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:106] version string "450.51.05" made value 450.51.5
2023-12-23 05:27:54.907572: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:915] trying to read NUMA node for device ordinal: 6
2023-12-23 05:27:54.908834: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 6
2023-12-23 05:27:54.908847: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 6
2023-12-23 05:27:54.908858: I tensorflow/core/common_runtime/bfc_allocator.cc:78] Creating bin of max chunk size 256B
2023-12-23 05:27:54.908865: I tensorflow/core/common_runtime/bfc_allocator.cc:78] Creating bin of max chunk size 512B
2023-12-23 05:27:54.908874: I tensorflow/core/common_runtime/bfc_allocator.cc:78] Creating bin of max chunk size 1.0KiB
2023-12-23 05:27:54.908881: I tensorflow/core/common_runtime/bfc_allocator.cc:78] Creating bin of max chunk size 2.0KiB
2023-12-23 05:27:54.908889: I tensorflow/core/common_runtime/bfc_allocator.cc:78] Creating bin of max chunk size 4.0KiB
2023-12-23 05:27:54.908897: I tensorflow/core/common_runtime/bfc_allocator.cc:78] Creating bin of max chunk size 8.0KiB
2023-12-23 05:27:54.908906: I tensorflow/core/common_runtime/bfc_allocator.cc:78] Creating bin of max chunk size 16.0KiB
2023-12-23 05:27:54.908914: I tensorflow/core/common_runtime/bfc_allocator.cc:78] Creating bin of max chunk size 32.0KiB
2023-12-23 05:27:54.908923: I tensorflow/core/common_runtime/bfc_allocator.cc:78] Creating bin of max chunk size 64.0KiB
2023-12-23 05:27:54.908931: I tensorflow/core/common_runtime/bfc_allocator.cc:78] Creating bin of max chunk size 128.0KiB
2023-12-23 05:27:54.908940: I tensorflow/core/common_runtime/bfc_allocator.cc:78] Creating bin of max chunk size 256.0KiB
2023-12-23 05:27:54.908949: I tensorflow/core/common_runtime/bfc_allocator.cc:78] Creating bin of max chunk size 512.0KiB
2023-12-23 05:27:54.908957: I tensorflow/core/common_runtime/bfc_allocator.cc:78] Creating bin of max chunk size 1.00MiB
2023-12-23 05:27:54.908966: I tensorflow/core/common_runtime/bfc_allocator.cc:78] Creating bin of max chunk size 2.00MiB
2023-12-23 05:27:54.908974: I tensorflow/core/common_runtime/bfc_allocator.cc:78] Creating bin of max chunk size 4.00MiB
2023-12-23 05:27:54.908982: I tensorflow/core/common_runtime/bfc_allocator.cc:78] Creating bin of max chunk size 8.00MiB
2023-12-23 05:27:54.908991: I tensorflow/core/common_runtime/bfc_allocator.cc:78] Creating bin of max chunk size 16.00MiB
2023-12-23 05:27:54.908999: I tensorflow/core/common_runtime/bfc_allocator.cc:78] Creating bin of max chunk size 32.00MiB
2023-12-23 05:27:54.909012: I tensorflow/core/common_runtime/bfc_allocator.cc:78] Creating bin of max chunk size 64.00MiB
2023-12-23 05:27:54.909021: I tensorflow/core/common_runtime/bfc_allocator.cc:78] Creating bin of max chunk size 128.00MiB
2023-12-23 05:27:54.909028: I tensorflow/core/common_runtime/bfc_allocator.cc:78] Creating bin of max chunk size 256.00MiB
2023-12-23 05:27:54.909051: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1462] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:6 with 6346 MB memory) -> physical GPU (device: 6, name: Tesla T4, pci bus id: 0000:b4:00.0, compute capability: 7.5)
2023-12-23 05:27:54.909060: I tensorflow/core/common_runtime/gpu/gpu_device.cc:441] BaseGPUDevice::Init device_id: 0x6
2023-12-23 05:27:54.909071: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 6
2023-12-23 05:27:54.909084: I tensorflow/stream_executor/stream.cc:256] [stream=0x5a789a60,impl=0x5a788ff0] Called Stream::Stream(parent=0x441aba0)
2023-12-23 05:27:54.909096: I tensorflow/stream_executor/stream.cc:298] [stream=0x5a789a60,impl=0x5a788ff0] Called Stream::Init()
2023-12-23 05:27:54.909105: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 7
2023-12-23 05:27:54.909138: I tensorflow/stream_executor/cuda/cuda_driver.cc:844] successfully created stream 0x5a789c90 for context 0x1ef68a0 on thread
2023-12-23 05:27:54.909148: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 7
2023-12-23 05:27:54.909157: I tensorflow/core/common_runtime/gpu/gpu_device.cc:254] Created stream[0] = 0x5a789a60 with priority: 0
2023-12-23 05:27:54.909168: I tensorflow/stream_executor/stream.cc:256] [stream=0x5a789df0,impl=0x5a788f60] Called Stream::Stream(parent=0x441aba0)
2023-12-23 05:27:54.909178: I tensorflow/stream_executor/stream.cc:298] [stream=0x5a789df0,impl=0x5a788f60] Called Stream::Init()
2023-12-23 05:27:54.909185: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 7
2023-12-23 05:27:54.909196: I tensorflow/stream_executor/cuda/cuda_driver.cc:844] successfully created stream 0x5a789ea0 for context 0x1ef68a0 on thread
2023-12-23 05:27:54.909204: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 7
2023-12-23 05:27:54.909214: I tensorflow/core/common_runtime/gpu/gpu_device.cc:273] Created host_to_device_stream[0] = 0x5a789df0
2023-12-23 05:27:54.909224: I tensorflow/stream_executor/stream.cc:256] [stream=0x5a78a010,impl=0x5a788f90] Called Stream::Stream(parent=0x441aba0)
2023-12-23 05:27:54.909233: I tensorflow/stream_executor/stream.cc:298] [stream=0x5a78a010,impl=0x5a788f90] Called Stream::Init()
2023-12-23 05:27:54.909241: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 7
2023-12-23 05:27:54.909559: I tensorflow/stream_executor/cuda/cuda_driver.cc:844] successfully created stream 0x5a78a0c0 for context 0x1ef68a0 on thread
2023-12-23 05:27:54.909578: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 7
2023-12-23 05:27:54.909588: I tensorflow/core/common_runtime/gpu/gpu_device.cc:278] Created device_to_host_stream[0] = 0x5a78a010
2023-12-23 05:27:54.909599: I tensorflow/stream_executor/stream.cc:256] [stream=0x5a791e70,impl=0x5a788fc0] Called Stream::Stream(parent=0x441aba0)
2023-12-23 05:27:54.909607: I tensorflow/stream_executor/stream.cc:298] [stream=0x5a791e70,impl=0x5a788fc0] Called Stream::Init()
2023-12-23 05:27:54.909615: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 7
2023-12-23 05:27:54.909626: I tensorflow/stream_executor/cuda/cuda_driver.cc:844] successfully created stream 0x5a791f20 for context 0x1ef68a0 on thread
2023-12-23 05:27:54.909633: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 7
2023-12-23 05:27:54.909641: I tensorflow/core/common_runtime/gpu/gpu_device.cc:294] Created device_to_device_stream[0] = 0x5a791e70
2023-12-23 05:27:54.909837: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:252] found DLL info with name: /usr/lib/x86_64-linux-gnu/libcuda.so.1
2023-12-23 05:27:54.909856: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:257] found DLL info with resolved path: /usr/lib/x86_64-linux-gnu/libcuda.so.450.51.05
2023-12-23 05:27:54.909867: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:106] version string "450.51.05" made value 450.51.5
2023-12-23 05:27:54.909879: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:915] trying to read NUMA node for device ordinal: 7
2023-12-23 05:27:54.911297: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 7
2023-12-23 05:27:54.911316: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 7
2023-12-23 05:27:54.911328: I tensorflow/core/common_runtime/bfc_allocator.cc:78] Creating bin of max chunk size 256B
2023-12-23 05:27:54.911336: I tensorflow/core/common_runtime/bfc_allocator.cc:78] Creating bin of max chunk size 512B
2023-12-23 05:27:54.911346: I tensorflow/core/common_runtime/bfc_allocator.cc:78] Creating bin of max chunk size 1.0KiB
2023-12-23 05:27:54.911353: I tensorflow/core/common_runtime/bfc_allocator.cc:78] Creating bin of max chunk size 2.0KiB
2023-12-23 05:27:54.911362: I tensorflow/core/common_runtime/bfc_allocator.cc:78] Creating bin of max chunk size 4.0KiB
2023-12-23 05:27:54.911370: I tensorflow/core/common_runtime/bfc_allocator.cc:78] Creating bin of max chunk size 8.0KiB
2023-12-23 05:27:54.911378: I tensorflow/core/common_runtime/bfc_allocator.cc:78] Creating bin of max chunk size 16.0KiB
2023-12-23 05:27:54.911386: I tensorflow/core/common_runtime/bfc_allocator.cc:78] Creating bin of max chunk size 32.0KiB
2023-12-23 05:27:54.911394: I tensorflow/core/common_runtime/bfc_allocator.cc:78] Creating bin of max chunk size 64.0KiB
2023-12-23 05:27:54.911402: I tensorflow/core/common_runtime/bfc_allocator.cc:78] Creating bin of max chunk size 128.0KiB
2023-12-23 05:27:54.911410: I tensorflow/core/common_runtime/bfc_allocator.cc:78] Creating bin of max chunk size 256.0KiB
2023-12-23 05:27:54.911417: I tensorflow/core/common_runtime/bfc_allocator.cc:78] Creating bin of max chunk size 512.0KiB
2023-12-23 05:27:54.911425: I tensorflow/core/common_runtime/bfc_allocator.cc:78] Creating bin of max chunk size 1.00MiB
2023-12-23 05:27:54.911433: I tensorflow/core/common_runtime/bfc_allocator.cc:78] Creating bin of max chunk size 2.00MiB
2023-12-23 05:27:54.911441: I tensorflow/core/common_runtime/bfc_allocator.cc:78] Creating bin of max chunk size 4.00MiB
2023-12-23 05:27:54.911449: I tensorflow/core/common_runtime/bfc_allocator.cc:78] Creating bin of max chunk size 8.00MiB
2023-12-23 05:27:54.911457: I tensorflow/core/common_runtime/bfc_allocator.cc:78] Creating bin of max chunk size 16.00MiB
2023-12-23 05:27:54.911466: I tensorflow/core/common_runtime/bfc_allocator.cc:78] Creating bin of max chunk size 32.00MiB
2023-12-23 05:27:54.911474: I tensorflow/core/common_runtime/bfc_allocator.cc:78] Creating bin of max chunk size 64.00MiB
2023-12-23 05:27:54.911482: I tensorflow/core/common_runtime/bfc_allocator.cc:78] Creating bin of max chunk size 128.00MiB
2023-12-23 05:27:54.911491: I tensorflow/core/common_runtime/bfc_allocator.cc:78] Creating bin of max chunk size 256.00MiB
2023-12-23 05:27:54.911512: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1462] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:7 with 6346 MB memory) -> physical GPU (device: 7, name: Tesla T4, pci bus id: 0000:b5:00.0, compute capability: 7.5)
2023-12-23 05:27:54.911522: I tensorflow/core/common_runtime/gpu/gpu_device.cc:441] BaseGPUDevice::Init device_id: 0x7
2023-12-23 05:27:54.911531: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 7
2023-12-23 05:27:54.911544: I tensorflow/stream_executor/stream.cc:256] [stream=0x5a7a4590,impl=0x5a7a3b20] Called Stream::Stream(parent=0x4a9eff0)
2023-12-23 05:27:54.911554: I tensorflow/stream_executor/stream.cc:298] [stream=0x5a7a4590,impl=0x5a7a3b20] Called Stream::Init()
2023-12-23 05:27:54.911562: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 8
2023-12-23 05:27:54.911591: I tensorflow/stream_executor/cuda/cuda_driver.cc:844] successfully created stream 0x5a7a47c0 for context 0x1efcea0 on thread
2023-12-23 05:27:54.911599: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 8
2023-12-23 05:27:54.911609: I tensorflow/core/common_runtime/gpu/gpu_device.cc:254] Created stream[0] = 0x5a7a4590 with priority: 0
2023-12-23 05:27:54.911620: I tensorflow/stream_executor/stream.cc:256] [stream=0x5a7a4920,impl=0x5a7a3a90] Called Stream::Stream(parent=0x4a9eff0)
2023-12-23 05:27:54.911629: I tensorflow/stream_executor/stream.cc:298] [stream=0x5a7a4920,impl=0x5a7a3a90] Called Stream::Init()
2023-12-23 05:27:54.911637: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 8
2023-12-23 05:27:54.911647: I tensorflow/stream_executor/cuda/cuda_driver.cc:844] successfully created stream 0x5a7a49d0 for context 0x1efcea0 on thread
2023-12-23 05:27:54.911655: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 8
2023-12-23 05:27:54.911664: I tensorflow/core/common_runtime/gpu/gpu_device.cc:273] Created host_to_device_stream[0] = 0x5a7a4920
2023-12-23 05:27:54.911674: I tensorflow/stream_executor/stream.cc:256] [stream=0x5a7a4b40,impl=0x5a7a3ac0] Called Stream::Stream(parent=0x4a9eff0)
2023-12-23 05:27:54.911683: I tensorflow/stream_executor/stream.cc:298] [stream=0x5a7a4b40,impl=0x5a7a3ac0] Called Stream::Init()
2023-12-23 05:27:54.911691: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 8
2023-12-23 05:27:54.911993: I tensorflow/stream_executor/cuda/cuda_driver.cc:844] successfully created stream 0x5a7a4bf0 for context 0x1efcea0 on thread
2023-12-23 05:27:54.912017: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 8
2023-12-23 05:27:54.912030: I tensorflow/core/common_runtime/gpu/gpu_device.cc:278] Created device_to_host_stream[0] = 0x5a7a4b40
2023-12-23 05:27:54.912043: I tensorflow/stream_executor/stream.cc:256] [stream=0x5a7ac9a0,impl=0x5a7a3af0] Called Stream::Stream(parent=0x4a9eff0)
2023-12-23 05:27:54.912053: I tensorflow/stream_executor/stream.cc:298] [stream=0x5a7ac9a0,impl=0x5a7a3af0] Called Stream::Init()
2023-12-23 05:27:54.912062: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 8
2023-12-23 05:27:54.912074: I tensorflow/stream_executor/cuda/cuda_driver.cc:844] successfully created stream 0x5a7aca50 for context 0x1efcea0 on thread
2023-12-23 05:27:54.912083: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 8
2023-12-23 05:27:54.912093: I tensorflow/core/common_runtime/gpu/gpu_device.cc:294] Created device_to_device_stream[0] = 0x5a7ac9a0
2023-12-23 05:27:54.912277: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2023-12-23 05:27:54.912324: I tensorflow/core/common_runtime/process_util.cc:159] Direct session inter op parallelism threads: 10
2023-12-23 05:27:54.912773: I tensorflow/core/common_runtime/direct_session.cc:361] Device mapping:
/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: Tesla T4, pci bus id: 0000:3d:00.0, compute capability: 7.5
/job:localhost/replica:0/task:0/device:GPU:1 -> device: 1, name: Tesla T4, pci bus id: 0000:3e:00.0, compute capability: 7.5
/job:localhost/replica:0/task:0/device:GPU:2 -> device: 2, name: Tesla T4, pci bus id: 0000:40:00.0, compute capability: 7.5
/job:localhost/replica:0/task:0/device:GPU:3 -> device: 3, name: Tesla T4, pci bus id: 0000:41:00.0, compute capability: 7.5
/job:localhost/replica:0/task:0/device:GPU:4 -> device: 4, name: Tesla T4, pci bus id: 0000:b1:00.0, compute capability: 7.5
/job:localhost/replica:0/task:0/device:GPU:5 -> device: 5, name: Tesla T4, pci bus id: 0000:b2:00.0, compute capability: 7.5
/job:localhost/replica:0/task:0/device:GPU:6 -> device: 6, name: Tesla T4, pci bus id: 0000:b4:00.0, compute capability: 7.5
/job:localhost/replica:0/task:0/device:GPU:7 -> device: 7, name: Tesla T4, pci bus id: 0000:b5:00.0, compute capability: 7.5

Successfully created a new TF Session object




========================================================================================================================
2. Create the Session object with graph
========================================================================================================================
2023-12-23 05:27:54.928029: I tensorflow/core/common_runtime/optimization_registry.cc:41] Running optimization phase 10
2023-12-23 05:27:54.928052: I tensorflow/core/common_runtime/optimization_registry.cc:43] Running optimization pass: AccumulateNV2RemovePass
2023-12-23 05:27:54.928083: W tensorflow/core/util/dump_graph.cc:134] Failed to dump after_group_0_phase_10_AccumulateNV2RemovePass_1492560288 because dump location is not  specified through either TF_DUMP_GRAPH_PREFIX environment variable or function argument.
2023-12-23 05:27:54.928102: I tensorflow/core/common_runtime/optimization_registry.cc:43] Running optimization pass: LowerFunctionalOpsPass
2023-12-23 05:27:54.928118: W tensorflow/core/util/dump_graph.cc:134] Failed to dump after_group_0_phase_10_LowerFunctionalOpsPass_1492560288 because dump location is not  specified through either TF_DUMP_GRAPH_PREFIX environment variable or function argument.
2023-12-23 05:27:54.928129: I tensorflow/core/common_runtime/optimization_registry.cc:43] Running optimization pass: ParallelConcatRemovePass
2023-12-23 05:27:54.928144: W tensorflow/core/util/dump_graph.cc:134] Failed to dump after_group_0_phase_10_ParallelConcatRemovePass_1492560288 because dump location is not  specified through either TF_DUMP_GRAPH_PREFIX environment variable or function argument.
2023-12-23 05:27:54.928154: I tensorflow/core/common_runtime/optimization_registry.cc:41] Running optimization phase 35
2023-12-23 05:27:54.928159: I tensorflow/core/common_runtime/optimization_registry.cc:43] Running optimization pass: IsolatePlacerInspectionRequiredOpsPass
2023-12-23 05:27:54.928165: I tensorflow/core/common_runtime/isolate_placer_inspection_required_ops_pass.cc:34] IsolatePlacerInspectionRequiredOpsPass::Run
2023-12-23 05:27:54.928293: W tensorflow/core/util/dump_graph.cc:134] Failed to dump after_group_0_phase_35_IsolatePlacerInspectionRequiredOpsPass_1492560288 because dump location is not  specified through either TF_DUMP_GRAPH_PREFIX environment variable or function argument.
2023-12-23 05:27:54.928305: I tensorflow/core/common_runtime/optimization_registry.cc:43] Running optimization pass: IntroduceFloatingPointJitterPass
2023-12-23 05:27:54.928314: I tensorflow/compiler/jit/introduce_floating_point_jitter_pass.cc:126] Nothing to do
2023-12-23 05:27:54.928327: W tensorflow/core/util/dump_graph.cc:134] Failed to dump after_group_0_phase_35_IntroduceFloatingPointJitterPass_1492560288 because dump location is not  specified through either TF_DUMP_GRAPH_PREFIX environment variable or function argument.
2023-12-23 05:27:54.928337: I tensorflow/core/common_runtime/optimization_registry.cc:41] Running optimization phase 36
2023-12-23 05:27:54.928342: I tensorflow/core/common_runtime/optimization_registry.cc:43] Running optimization pass: EncapsulateXlaComputationsPass
2023-12-23 05:27:54.928356: W tensorflow/core/util/dump_graph.cc:134] Failed to dump encapsulate_xla_computations_before because dump location is not  specified through either TF_DUMP_GRAPH_PREFIX environment variable or function argument.
2023-12-23 05:27:54.928366: I tensorflow/compiler/jit/encapsulate_xla_computations_pass.cc:369] EncapsulateXlaComputations(): (failed to create writable file: Invalid argument: TF_DUMP_GRAPH_PREFIX not specified)
2023-12-23 05:27:54.928415: W tensorflow/core/util/dump_graph.cc:134] Failed to dump encapsulate_xla_computations_halfway because dump location is not  specified through either TF_DUMP_GRAPH_PREFIX environment variable or function argument.
2023-12-23 05:27:54.928426: I tensorflow/compiler/jit/encapsulate_xla_computations_pass.cc:380] EncapsulateXlaComputations() half-way: (failed to create writable file: Invalid argument: TF_DUMP_GRAPH_PREFIX not specified)
2023-12-23 05:27:54.928442: W tensorflow/core/util/dump_graph.cc:134] Failed to dump encapsulate_xla_computations_after because dump location is not  specified through either TF_DUMP_GRAPH_PREFIX environment variable or function argument.
2023-12-23 05:27:54.928451: I tensorflow/compiler/jit/encapsulate_xla_computations_pass.cc:386] EncapsulateXlaComputations() finished: (failed to create writable file: Invalid argument: TF_DUMP_GRAPH_PREFIX not specified)
2023-12-23 05:27:54.928464: W tensorflow/core/util/dump_graph.cc:134] Failed to dump after_group_0_phase_36_EncapsulateXlaComputationsPass_1492609632 because dump location is not  specified through either TF_DUMP_GRAPH_PREFIX environment variable or function argument.
2023-12-23 05:27:54.928474: I tensorflow/core/common_runtime/optimization_registry.cc:41] Running optimization phase 37
2023-12-23 05:27:54.928480: I tensorflow/core/common_runtime/optimization_registry.cc:43] Running optimization pass: FunctionalizeControlFlowForXlaPass
2023-12-23 05:27:54.928513: W tensorflow/core/util/dump_graph.cc:134] Failed to dump after_group_0_phase_37_FunctionalizeControlFlowForXlaPass_1492609632 because dump location is not  specified through either TF_DUMP_GRAPH_PREFIX environment variable or function argument.
2023-12-23 05:27:54.928533: W tensorflow/core/util/dump_graph.cc:134] Failed to dump placer_input because dump location is not  specified through either TF_DUMP_GRAPH_PREFIX environment variable or function argument.
2023-12-23 05:27:54.928561: I tensorflow/core/framework/op_kernel.cc:1378] No device-specific kernels found for NodeDef '{{node X}}'Will fall back to a default kernel.

Weight/read: (Identity): /job:localhost/replica:0/task:0/device:GPU:0
2023-12-23 05:27:54.928626: I tensorflow/core/common_runtime/placer.cc:114] Weight/read: (Identity): /job:localhost/replica:0/task:0/device:GPU:0
Bias/read: (Identity): /job:localhost/replica:0/task:0/device:GPU:0
2023-12-23 05:27:54.928635: I tensorflow/core/common_runtime/placer.cc:114] Bias/read: (Identity): /job:localhost/replica:0/task:0/device:GPU:0
MatMul: (MatMul): /job:localhost/replica:0/task:0/device:GPU:0
2023-12-23 05:27:54.928643: I tensorflow/core/common_runtime/placer.cc:114] MatMul: (MatMul): /job:localhost/replica:0/task:0/device:GPU:0
Add: (Add): /job:localhost/replica:0/task:0/device:GPU:0
2023-12-23 05:27:54.928652: I tensorflow/core/common_runtime/placer.cc:114] Add: (Add): /job:localhost/replica:0/task:0/device:GPU:0
Sigmoid: (Sigmoid): /job:localhost/replica:0/task:0/device:GPU:0
2023-12-23 05:27:54.928660: I tensorflow/core/common_runtime/placer.cc:114] Sigmoid: (Sigmoid): /job:localhost/replica:0/task:0/device:GPU:0
X: (Placeholder): /job:localhost/replica:0/task:0/device:GPU:0
2023-12-23 05:27:54.928669: I tensorflow/core/common_runtime/placer.cc:114] X: (Placeholder): /job:localhost/replica:0/task:0/device:GPU:0
Weight: (Const): /job:localhost/replica:0/task:0/device:GPU:0
2023-12-23 05:27:54.928678: I tensorflow/core/common_runtime/placer.cc:114] Weight: (Const): /job:localhost/replica:0/task:0/device:GPU:0
Bias: (Const): /job:localhost/replica:0/task:0/device:GPU:0
2023-12-23 05:27:54.928686: I tensorflow/core/common_runtime/placer.cc:114] Bias: (Const): /job:localhost/replica:0/task:0/device:GPU:0
2023-12-23 05:27:54.928703: W tensorflow/core/util/dump_graph.cc:134] Failed to dump placer_output because dump location is not  specified through either TF_DUMP_GRAPH_PREFIX environment variable or function argument.
2023-12-23 05:27:54.928717: E tensorflow/core/common_runtime/placer.cc:93] Failed to write final colocation graph to file  with Internal: Failed to get the directory for colocation_graph because dump location is not specified through TF_DUMP_GRAPH_PREFIX environment variable
2023-12-23 05:27:54.928725: I tensorflow/core/common_runtime/optimization_registry.cc:41] Running optimization phase 0
2023-12-23 05:27:54.928730: I tensorflow/core/common_runtime/optimization_registry.cc:43] Running optimization pass: NcclReplacePass
2023-12-23 05:27:54.928746: W tensorflow/core/util/dump_graph.cc:134] Failed to dump after_group_1_phase_0_NcclReplacePass_1492609632 because dump location is not  specified through either TF_DUMP_GRAPH_PREFIX environment variable or function argument.
2023-12-23 05:27:54.928757: I tensorflow/core/common_runtime/graph_execution_state.cc:636] Mapping _SOURCE to 0
2023-12-23 05:27:54.928763: I tensorflow/core/common_runtime/graph_execution_state.cc:636] Mapping _SINK to 1
2023-12-23 05:27:54.928767: I tensorflow/core/common_runtime/graph_execution_state.cc:636] Mapping X to 2
2023-12-23 05:27:54.928773: I tensorflow/core/common_runtime/graph_execution_state.cc:636] Mapping Weight to 3
2023-12-23 05:27:54.928777: I tensorflow/core/common_runtime/graph_execution_state.cc:636] Mapping Weight/read to 4
2023-12-23 05:27:54.928782: I tensorflow/core/common_runtime/graph_execution_state.cc:636] Mapping Bias to 5
2023-12-23 05:27:54.928787: I tensorflow/core/common_runtime/graph_execution_state.cc:636] Mapping Bias/read to 6
2023-12-23 05:27:54.928792: I tensorflow/core/common_runtime/graph_execution_state.cc:636] Mapping MatMul to 7
2023-12-23 05:27:54.928797: I tensorflow/core/common_runtime/graph_execution_state.cc:636] Mapping Add to 8
2023-12-23 05:27:54.928802: I tensorflow/core/common_runtime/graph_execution_state.cc:636] Mapping Sigmoid to 9
Successfully created session! model=test_model_v1




========================================================================================================================
3. Run the Session object with input tensors
========================================================================================================================
Input X:0 with shape{3, 5}
2023-12-23 05:27:54.929163: I tensorflow/core/framework/log_memory.cc:34] __LOG_MEMORY__ MemoryLogTensorAllocation { step_id: -6 kernel_name: "Unknown" tensor { dtype: DT_FLOAT shape { dim { size: 3 } dim { size: 5 } } allocation_description { requested_bytes: 60 allocated_bytes: 60 allocator_name: "cpu" allocation_id: 1 has_single_reference: true ptr: 30465344 } } }
>> 0.0926052 0.969749 0.0945846 0.595827 0.0591915 
>> 0.26526 0.18775 0.894581 0.689607 0.33116 
>> 0.561817 0.66168 0.509413 0.691881 0.761327 

Fetch name: Sigmoid:0

>> Start Session Run
2023-12-23 05:27:54.929237: I tensorflow/core/common_runtime/graph_execution_state.cc:852] BuildGraph
2023-12-23 05:27:54.929247: I tensorflow/core/common_runtime/graph_execution_state.cc:868] Grappler optimization failed. Error: Meta Optimizer disabled
2023-12-23 05:27:54.929292: I tensorflow/core/graph/subgraph.cc:141] Found fetch node for Sigmoid:0
2023-12-23 05:27:54.929308: I tensorflow/core/graph/algorithm.cc:235] Reverse reach : _retval_Sigmoid_0_0 from Sigmoid
2023-12-23 05:27:54.929315: I tensorflow/core/graph/algorithm.cc:235] Reverse reach : Sigmoid from Add
2023-12-23 05:27:54.929320: I tensorflow/core/graph/algorithm.cc:235] Reverse reach : Add from MatMul
2023-12-23 05:27:54.929324: I tensorflow/core/graph/algorithm.cc:235] Reverse reach : Add from Bias/read
2023-12-23 05:27:54.929329: I tensorflow/core/graph/algorithm.cc:235] Reverse reach : MatMul from _arg_X_0_0
2023-12-23 05:27:54.929334: I tensorflow/core/graph/algorithm.cc:235] Reverse reach : MatMul from Weight/read
2023-12-23 05:27:54.929339: I tensorflow/core/graph/algorithm.cc:235] Reverse reach : Bias/read from Bias
2023-12-23 05:27:54.929343: I tensorflow/core/graph/algorithm.cc:235] Reverse reach : _arg_X_0_0 from _SOURCE
2023-12-23 05:27:54.929348: I tensorflow/core/graph/algorithm.cc:235] Reverse reach : Weight/read from Weight
2023-12-23 05:27:54.929357: I tensorflow/core/common_runtime/optimization_registry.cc:41] Running optimization phase 5
2023-12-23 05:27:54.929362: I tensorflow/core/common_runtime/optimization_registry.cc:43] Running optimization pass: CloneConstantsForBetterClusteringPass
2023-12-23 05:27:54.929388: W tensorflow/core/util/dump_graph.cc:134] Failed to dump after_group_2_phase_5_CloneConstantsForBetterClusteringPass_1492560288 because dump location is not  specified through either TF_DUMP_GRAPH_PREFIX environment variable or function argument.
2023-12-23 05:27:54.929403: I tensorflow/core/common_runtime/optimization_registry.cc:41] Running optimization phase 9
2023-12-23 05:27:54.929408: I tensorflow/core/common_runtime/optimization_registry.cc:43] Running optimization pass: ClusterScopingPass
2023-12-23 05:27:54.929423: W tensorflow/core/util/dump_graph.cc:134] Failed to dump after_group_2_phase_9_ClusterScopingPass_1492560288 because dump location is not  specified through either TF_DUMP_GRAPH_PREFIX environment variable or function argument.
2023-12-23 05:27:54.929434: I tensorflow/core/common_runtime/optimization_registry.cc:41] Running optimization phase 10
2023-12-23 05:27:54.929439: I tensorflow/core/common_runtime/optimization_registry.cc:43] Running optimization pass: MarkForCompilationPass
2023-12-23 05:27:54.929455: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: XlaWhile
2023-12-23 05:27:54.929469: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: XlaWhile
2023-12-23 05:27:54.929479: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: While
2023-12-23 05:27:54.929488: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: While
2023-12-23 05:27:54.929499: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: XlaIf
2023-12-23 05:27:54.929511: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: XlaIf
2023-12-23 05:27:54.929524: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: Case
2023-12-23 05:27:54.929535: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Case
2023-12-23 05:27:54.929547: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: Svd
2023-12-23 05:27:54.929556: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Svd
2023-12-23 05:27:54.929569: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: XlaReduce
2023-12-23 05:27:54.929579: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: XlaReduce
2023-12-23 05:27:54.929588: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: XlaDot
2023-12-23 05:27:54.929596: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: XlaDot
2023-12-23 05:27:54.929604: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: XlaDequantize
2023-12-23 05:27:54.929610: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: XlaDequantize
2023-12-23 05:27:54.929623: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: XlaConvV2
2023-12-23 05:27:54.929638: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: XlaConvV2
2023-12-23 05:27:54.929651: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: XlaConv
2023-12-23 05:27:54.929661: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: XlaConv
2023-12-23 05:27:54.929672: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: XlaBroadcastHelper
2023-12-23 05:27:54.929681: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: XlaBroadcastHelper
2023-12-23 05:27:54.929692: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: ResourceScatterNdSub
2023-12-23 05:27:54.929702: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: ResourceScatterNdSub
2023-12-23 05:27:54.929713: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: ResourceScatterNdAdd
2023-12-23 05:27:54.929722: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: ResourceScatterNdAdd
2023-12-23 05:27:54.929733: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: ResourceScatterNdUpdate
2023-12-23 05:27:54.929743: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: ResourceScatterNdUpdate
2023-12-23 05:27:54.929755: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: ResourceScatterDiv
2023-12-23 05:27:54.929764: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: ResourceScatterDiv
2023-12-23 05:27:54.929774: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: ResourceScatterMul
2023-12-23 05:27:54.929783: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: ResourceScatterMul
2023-12-23 05:27:54.929793: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: ResourceScatterSub
2023-12-23 05:27:54.929803: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: ResourceScatterSub
2023-12-23 05:27:54.929813: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: ResourceScatterAdd
2023-12-23 05:27:54.929822: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: ResourceScatterAdd
2023-12-23 05:27:54.929834: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: AssignSubVariableOp
2023-12-23 05:27:54.929842: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: AssignSubVariableOp
2023-12-23 05:27:54.929851: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: AvgPool3DGrad
2023-12-23 05:27:54.929860: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: AvgPool3DGrad
2023-12-23 05:27:54.929870: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: AvgPoolGrad
2023-12-23 05:27:54.929878: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: AvgPoolGrad
2023-12-23 05:27:54.929888: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: Split
2023-12-23 05:27:54.929897: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Split
2023-12-23 05:27:54.929907: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: MaxPoolV2
2023-12-23 05:27:54.929915: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: MaxPoolV2
2023-12-23 05:27:54.929926: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: OneHot
2023-12-23 05:27:54.929936: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: OneHot
2023-12-23 05:27:54.929946: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: NoOp
2023-12-23 05:27:54.929952: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: NoOp
2023-12-23 05:27:54.929963: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: DepthwiseConv2dNativeBackpropFilter
2023-12-23 05:27:54.929971: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: DepthwiseConv2dNativeBackpropFilter
2023-12-23 05:27:54.929980: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: NextAfter
2023-12-23 05:27:54.929989: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: NextAfter
2023-12-23 05:27:54.929999: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: MatrixSolve
2023-12-23 05:27:54.930013: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: MatrixSolve
2023-12-23 05:27:54.930022: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: MatrixSetDiagV3
2023-12-23 05:27:54.930030: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: MatrixSetDiagV3
2023-12-23 05:27:54.930041: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: VariableShape
2023-12-23 05:27:54.930049: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: VariableShape
2023-12-23 05:27:54.930057: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: MatrixSetDiagV2
2023-12-23 05:27:54.930065: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: MatrixSetDiagV2
2023-12-23 05:27:54.930073: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: MatrixSetDiag
2023-12-23 05:27:54.930081: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: MatrixSetDiag
2023-12-23 05:27:54.930091: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: BroadcastGradientArgs
2023-12-23 05:27:54.930100: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: BroadcastGradientArgs
2023-12-23 05:27:54.930111: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: TensorListSplit
2023-12-23 05:27:54.930121: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: TensorListSplit
2023-12-23 05:27:54.930132: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: Tanh
2023-12-23 05:27:54.930142: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Tanh
2023-12-23 05:27:54.930152: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: Real
2023-12-23 05:27:54.930161: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Real
2023-12-23 05:27:54.930171: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: Pack
2023-12-23 05:27:54.930178: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Pack
2023-12-23 05:27:54.930188: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: Gather
2023-12-23 05:27:54.930197: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Gather
2023-12-23 05:27:54.930209: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: SparseMatMul
2023-12-23 05:27:54.930218: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: SparseMatMul
2023-12-23 05:27:54.930229: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: ListDiff
2023-12-23 05:27:54.930239: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: ListDiff
2023-12-23 05:27:54.930250: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: StatelessIf
2023-12-23 05:27:54.930260: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: StatelessIf
2023-12-23 05:27:54.930272: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: Bucketize
2023-12-23 05:27:54.930281: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Bucketize
2023-12-23 05:27:54.930290: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: TensorListLength
2023-12-23 05:27:54.930297: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: TensorListLength
2023-12-23 05:27:54.930306: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: ConcatV2
2023-12-23 05:27:54.930316: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: ConcatV2
2023-12-23 05:27:54.930326: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: MaxPool
2023-12-23 05:27:54.930334: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: MaxPool
2023-12-23 05:27:54.930343: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: InTopKV2
2023-12-23 05:27:54.930351: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: InTopKV2
2023-12-23 05:27:54.930362: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: MatrixBandPart
2023-12-23 05:27:54.930371: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: MatrixBandPart
2023-12-23 05:27:54.930381: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: UpperBound
2023-12-23 05:27:54.930391: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: UpperBound
2023-12-23 05:27:54.930401: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: AdjustHue
2023-12-23 05:27:54.930409: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: AdjustHue
2023-12-23 05:27:54.930418: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: SelfAdjointEigV2
2023-12-23 05:27:54.930426: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: SelfAdjointEigV2
2023-12-23 05:27:54.930435: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: AdjustSaturation
2023-12-23 05:27:54.930443: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: AdjustSaturation
2023-12-23 05:27:54.930452: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: BroadcastArgs
2023-12-23 05:27:54.930460: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: BroadcastArgs
2023-12-23 05:27:54.930470: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: TridiagonalSolve
2023-12-23 05:27:54.930478: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: TridiagonalSolve
2023-12-23 05:27:54.930488: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: HSVToRGB
2023-12-23 05:27:54.930496: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: HSVToRGB
2023-12-23 05:27:54.930506: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: ParameterizedTruncatedNormal
2023-12-23 05:27:54.930516: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: ParameterizedTruncatedNormal
2023-12-23 05:27:54.930526: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: ResourceScatterMin
2023-12-23 05:27:54.930535: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: ResourceScatterMin
2023-12-23 05:27:54.930544: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: RGBToHSV
2023-12-23 05:27:54.930552: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: RGBToHSV
2023-12-23 05:27:54.930561: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: XlaSetDynamicDimensionSize
2023-12-23 05:27:54.930570: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: XlaSetDynamicDimensionSize
2023-12-23 05:27:54.930579: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: XlaVariadicReduce
2023-12-23 05:27:54.930587: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: XlaVariadicReduce
2023-12-23 05:27:54.930596: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: GatherNd
2023-12-23 05:27:54.930605: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: GatherNd
2023-12-23 05:27:54.930615: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: Betainc
2023-12-23 05:27:54.930623: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Betainc
2023-12-23 05:27:54.930632: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: FusedBatchNormGrad
2023-12-23 05:27:54.930641: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: FusedBatchNormGrad
2023-12-23 05:27:54.930652: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: IRFFT2D
2023-12-23 05:27:54.930661: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: IRFFT2D
2023-12-23 05:27:54.930672: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: TruncateMod
2023-12-23 05:27:54.930683: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: TruncateMod
2023-12-23 05:27:54.930692: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: TensorArrayReadV3
2023-12-23 05:27:54.930702: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: TensorArrayReadV3
2023-12-23 05:27:54.930713: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: PartitionedCall
2023-12-23 05:27:54.930724: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: PartitionedCall
2023-12-23 05:27:54.930734: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: BiasAddV1
2023-12-23 05:27:54.930742: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: BiasAddV1
2023-12-23 05:27:54.930754: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: UnsortedSegmentProd
2023-12-23 05:27:54.930766: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: UnsortedSegmentProd
2023-12-23 05:27:54.930777: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: StackCloseV2
2023-12-23 05:27:54.930784: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: StackCloseV2
2023-12-23 05:27:54.930791: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: Identity
2023-12-23 05:27:54.930798: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Identity
2023-12-23 05:27:54.930809: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: ResourceApplyAdadelta
2023-12-23 05:27:54.930818: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: ResourceApplyAdadelta
2023-12-23 05:27:54.930827: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: MaxPoolGrad
2023-12-23 05:27:54.930835: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: MaxPoolGrad
2023-12-23 05:27:54.930844: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: MirrorPad
2023-12-23 05:27:54.930854: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: MirrorPad
2023-12-23 05:27:54.930864: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: Selu
2023-12-23 05:27:54.930872: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Selu
2023-12-23 05:27:54.930883: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: IsNan
2023-12-23 05:27:54.930891: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: IsNan
2023-12-23 05:27:54.930902: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: Conv2DBackpropInput
2023-12-23 05:27:54.930910: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Conv2DBackpropInput
2023-12-23 05:27:54.930920: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: ResourceScatterMax
2023-12-23 05:27:54.930930: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: ResourceScatterMax
2023-12-23 05:27:54.930940: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: IRFFT
2023-12-23 05:27:54.930949: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: IRFFT
2023-12-23 05:27:54.930958: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: MatrixTriangularSolve
2023-12-23 05:27:54.930966: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: MatrixTriangularSolve
2023-12-23 05:27:54.930976: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: TanhGrad
2023-12-23 05:27:54.930984: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: TanhGrad
2023-12-23 05:27:54.930992: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: RngReadAndSkip
2023-12-23 05:27:54.930999: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: RngReadAndSkip
2023-12-23 05:27:54.931011: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: TensorListPushBack
2023-12-23 05:27:54.931020: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: TensorListPushBack
2023-12-23 05:27:54.931030: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: IFFT3D
2023-12-23 05:27:54.931038: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: IFFT3D
2023-12-23 05:27:54.931047: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: XlaScatter
2023-12-23 05:27:54.931057: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: XlaScatter
2023-12-23 05:27:54.931069: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: Fill
2023-12-23 05:27:54.931078: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Fill
2023-12-23 05:27:54.931087: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: IFFT2D
2023-12-23 05:27:54.931095: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: IFFT2D
2023-12-23 05:27:54.931103: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: FFT2D
2023-12-23 05:27:54.931110: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: FFT2D
2023-12-23 05:27:54.931118: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: IFFT
2023-12-23 05:27:54.931126: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: IFFT
2023-12-23 05:27:54.931134: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: FFT
2023-12-23 05:27:54.931142: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: FFT
2023-12-23 05:27:54.931152: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: SparseSoftmaxCrossEntropyWithLogits
2023-12-23 05:27:54.931161: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: SparseSoftmaxCrossEntropyWithLogits
2023-12-23 05:27:54.931173: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: MatrixDiag
2023-12-23 05:27:54.931181: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: MatrixDiag
2023-12-23 05:27:54.931192: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: FloorDiv
2023-12-23 05:27:54.931201: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: FloorDiv
2023-12-23 05:27:54.931210: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: MaxPool3D
2023-12-23 05:27:54.931218: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: MaxPool3D
2023-12-23 05:27:54.931227: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: _ArrayToList
2023-12-23 05:27:54.931236: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: _ArrayToList
2023-12-23 05:27:54.931246: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: Ceil
2023-12-23 05:27:54.931254: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Ceil
2023-12-23 05:27:54.931263: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: FakeQuantWithMinMaxVars
2023-12-23 05:27:54.931270: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: FakeQuantWithMinMaxVars
2023-12-23 05:27:54.931277: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: Inv
2023-12-23 05:27:54.931286: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Inv
2023-12-23 05:27:54.931294: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: FakeParam
2023-12-23 05:27:54.931302: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: FakeParam
2023-12-23 05:27:54.931311: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: XlaRecv
2023-12-23 05:27:54.931319: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: XlaRecv
2023-12-23 05:27:54.931327: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: EnsureShape
2023-12-23 05:27:54.931335: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: EnsureShape
2023-12-23 05:27:54.931346: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: ReluGrad
2023-12-23 05:27:54.931354: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: ReluGrad
2023-12-23 05:27:54.931362: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: Empty
2023-12-23 05:27:54.931370: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Empty
2023-12-23 05:27:54.931379: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: Atanh
2023-12-23 05:27:54.931387: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Atanh
2023-12-23 05:27:54.931396: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: BitwiseOr
2023-12-23 05:27:54.931404: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: BitwiseOr
2023-12-23 05:27:54.931411: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: XlaSetBound
2023-12-23 05:27:54.931418: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: XlaSetBound
2023-12-23 05:27:54.931425: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: IgammaGradA
2023-12-23 05:27:54.931433: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: IgammaGradA
2023-12-23 05:27:54.931441: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: EluGrad
2023-12-23 05:27:54.931449: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: EluGrad
2023-12-23 05:27:54.931459: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: DepthwiseConv2dNative
2023-12-23 05:27:54.931467: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: DepthwiseConv2dNative
2023-12-23 05:27:54.931476: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: ParallelDynamicStitch
2023-12-23 05:27:54.931484: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: ParallelDynamicStitch
2023-12-23 05:27:54.931493: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: Multinomial
2023-12-23 05:27:54.931502: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Multinomial
2023-12-23 05:27:54.931513: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: ResourceStridedSliceAssign
2023-12-23 05:27:54.931522: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: ResourceStridedSliceAssign
2023-12-23 05:27:54.931531: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: LogicalOr
2023-12-23 05:27:54.931537: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: LogicalOr
2023-12-23 05:27:54.931544: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: LeftShift
2023-12-23 05:27:54.931553: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: LeftShift
2023-12-23 05:27:54.931561: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: MatrixDiagV2
2023-12-23 05:27:54.931569: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: MatrixDiagV2
2023-12-23 05:27:54.931579: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: ResizeNearestNeighbor
2023-12-23 05:27:54.931587: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: ResizeNearestNeighbor
2023-12-23 05:27:54.931596: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: RightShift
2023-12-23 05:27:54.931604: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: RightShift
2023-12-23 05:27:54.931612: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: PlaceholderWithDefault
2023-12-23 05:27:54.931620: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: PlaceholderWithDefault
2023-12-23 05:27:54.931629: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: Zeta
2023-12-23 05:27:54.931636: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Zeta
2023-12-23 05:27:54.931644: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: BitwiseXor
2023-12-23 05:27:54.931653: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: BitwiseXor
2023-12-23 05:27:54.931665: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: ResourceApplyProximalAdagrad
2023-12-23 05:27:54.931674: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: ResourceApplyProximalAdagrad
2023-12-23 05:27:54.931682: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: MulNoNan
2023-12-23 05:27:54.931690: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: MulNoNan
2023-12-23 05:27:54.931699: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: DynamicStitch
2023-12-23 05:27:54.931707: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: DynamicStitch
2023-12-23 05:27:54.931716: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: AvgPool
2023-12-23 05:27:54.931723: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: AvgPool
2023-12-23 05:27:54.931732: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: Cholesky
2023-12-23 05:27:54.931739: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Cholesky
2023-12-23 05:27:54.931749: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: Diag
2023-12-23 05:27:54.931757: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Diag
2023-12-23 05:27:54.931765: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: TensorArrayConcatV3
2023-12-23 05:27:54.931773: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: TensorArrayConcatV3
2023-12-23 05:27:54.931783: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: Sqrt
2023-12-23 05:27:54.931791: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Sqrt
2023-12-23 05:27:54.931799: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: BitwiseAnd
2023-12-23 05:27:54.931807: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: BitwiseAnd
2023-12-23 05:27:54.931816: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: BiasAddGrad
2023-12-23 05:27:54.931825: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: BiasAddGrad
2023-12-23 05:27:54.931836: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: Bitcast
2023-12-23 05:27:54.931846: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Bitcast
2023-12-23 05:27:54.931858: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: StatelessMultinomial
2023-12-23 05:27:54.931869: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: StatelessMultinomial
2023-12-23 05:27:54.931880: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: MaxPool3DGrad
2023-12-23 05:27:54.931889: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: MaxPool3DGrad
2023-12-23 05:27:54.931899: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: Erf
2023-12-23 05:27:54.931906: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Erf
2023-12-23 05:27:54.931915: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: Floor
2023-12-23 05:27:54.931922: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Floor
2023-12-23 05:27:54.931930: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: FakeQuantWithMinMaxVarsGradient
2023-12-23 05:27:54.931936: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: FakeQuantWithMinMaxVarsGradient
2023-12-23 05:27:54.931944: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: MaxPoolGradV2
2023-12-23 05:27:54.931952: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: MaxPoolGradV2
2023-12-23 05:27:54.931961: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: Minimum
2023-12-23 05:27:54.931970: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Minimum
2023-12-23 05:27:54.931977: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: SeluGrad
2023-12-23 05:27:54.931985: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: SeluGrad
2023-12-23 05:27:54.931995: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: PadV2
2023-12-23 05:27:54.932008: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: PadV2
2023-12-23 05:27:54.932018: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: DataFormatDimMap
2023-12-23 05:27:54.932026: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: DataFormatDimMap
2023-12-23 05:27:54.932035: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: ResourceApplyPowerSign
2023-12-23 05:27:54.932043: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: ResourceApplyPowerSign
2023-12-23 05:27:54.932052: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: ReciprocalGrad
2023-12-23 05:27:54.932060: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: ReciprocalGrad
2023-12-23 05:27:54.932068: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: TensorListStack
2023-12-23 05:27:54.932076: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: TensorListStack
2023-12-23 05:27:54.932083: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: VarIsInitializedOp
2023-12-23 05:27:54.932090: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: VarIsInitializedOp
2023-12-23 05:27:54.932098: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: SigmoidGrad
2023-12-23 05:27:54.932105: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: SigmoidGrad
2023-12-23 05:27:54.932114: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: AddV2
2023-12-23 05:27:54.932122: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: AddV2
2023-12-23 05:27:54.932130: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: IdentityN
2023-12-23 05:27:54.932138: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: IdentityN
2023-12-23 05:27:54.932147: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: BatchToSpaceND
2023-12-23 05:27:54.932159: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: BatchToSpaceND
2023-12-23 05:27:54.932170: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: FusedBatchNormV2
2023-12-23 05:27:54.932180: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: FusedBatchNormV2
2023-12-23 05:27:54.932189: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: FakeQuantWithMinMaxArgs
2023-12-23 05:27:54.932195: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: FakeQuantWithMinMaxArgs
2023-12-23 05:27:54.932203: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: StackV2
2023-12-23 05:27:54.932211: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: StackV2
2023-12-23 05:27:54.932219: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: ControlTrigger
2023-12-23 05:27:54.932225: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: ControlTrigger
2023-12-23 05:27:54.932233: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: ResourceApplyAddSign
2023-12-23 05:27:54.932241: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: ResourceApplyAddSign
2023-12-23 05:27:54.932250: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: Pow
2023-12-23 05:27:54.932258: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Pow
2023-12-23 05:27:54.932267: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: TensorScatterSub
2023-12-23 05:27:54.932276: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: TensorScatterSub
2023-12-23 05:27:54.932285: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: Log
2023-12-23 05:27:54.932293: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Log
2023-12-23 05:27:54.932302: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: FusedBatchNorm
2023-12-23 05:27:54.932310: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: FusedBatchNorm
2023-12-23 05:27:54.932319: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: Greater
2023-12-23 05:27:54.932326: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Greater
2023-12-23 05:27:54.932337: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: RandomStandardNormal
2023-12-23 05:27:54.932347: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: RandomStandardNormal
2023-12-23 05:27:54.932356: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: Sigmoid
2023-12-23 05:27:54.932363: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Sigmoid
2023-12-23 05:27:54.932372: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: MatrixDiagPartV2
2023-12-23 05:27:54.932380: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: MatrixDiagPartV2
2023-12-23 05:27:54.932390: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: _ListToArray
2023-12-23 05:27:54.932399: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: _ListToArray
2023-12-23 05:27:54.932409: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: Xdivy
2023-12-23 05:27:54.932417: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Xdivy
2023-12-23 05:27:54.932425: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: TensorArraySplitV3
2023-12-23 05:27:54.932433: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: TensorArraySplitV3
2023-12-23 05:27:54.932441: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: TruncateDiv
2023-12-23 05:27:54.932449: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: TruncateDiv
2023-12-23 05:27:54.932457: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: _Arg
2023-12-23 05:27:54.932466: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: _Arg
2023-12-23 05:27:54.932473: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: StackPopV2
2023-12-23 05:27:54.932481: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: StackPopV2
2023-12-23 05:27:54.932490: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: TensorScatterMin
2023-12-23 05:27:54.932500: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: TensorScatterMin
2023-12-23 05:27:54.932510: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: TensorArrayScatterV3
2023-12-23 05:27:54.932518: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: TensorArrayScatterV3
2023-12-23 05:27:54.932527: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: XlaEinsum
2023-12-23 05:27:54.932535: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: XlaEinsum
2023-12-23 05:27:54.932544: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: GreaterEqual
2023-12-23 05:27:54.932552: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: GreaterEqual
2023-12-23 05:27:54.932561: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: Conv3D
2023-12-23 05:27:54.932569: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Conv3D
2023-12-23 05:27:54.932578: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: L2Loss
2023-12-23 05:27:54.932585: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: L2Loss
2023-12-23 05:27:54.932595: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: Relu
2023-12-23 05:27:54.932603: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Relu
2023-12-23 05:27:54.932611: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: Invert
2023-12-23 05:27:54.932619: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Invert
2023-12-23 05:27:54.932627: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: StopGradient
2023-12-23 05:27:54.932635: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: StopGradient
2023-12-23 05:27:54.932644: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: _FusedBatchNormEx
2023-12-23 05:27:54.932654: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: _FusedBatchNormEx
2023-12-23 05:27:54.932664: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: FusedBatchNormGradV2
2023-12-23 05:27:54.932673: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: FusedBatchNormGradV2
2023-12-23 05:27:54.932683: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: FusedBatchNormGradV3
2023-12-23 05:27:54.932691: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: FusedBatchNormGradV3
2023-12-23 05:27:54.932700: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: Igammac
2023-12-23 05:27:54.932708: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Igammac
2023-12-23 05:27:54.932716: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: Sub
2023-12-23 05:27:54.932724: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Sub
2023-12-23 05:27:54.932732: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: Expm1
2023-12-23 05:27:54.932740: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Expm1
2023-12-23 05:27:54.932748: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: PreventGradient
2023-12-23 05:27:54.932756: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: PreventGradient
2023-12-23 05:27:54.932765: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: XlaSelfAdjointEig
2023-12-23 05:27:54.932773: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: XlaSelfAdjointEig
2023-12-23 05:27:54.932783: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: Maximum
2023-12-23 05:27:54.932791: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Maximum
2023-12-23 05:27:54.932799: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: Less
2023-12-23 05:27:54.932807: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Less
2023-12-23 05:27:54.932816: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: Conv3DBackpropFilterV2
2023-12-23 05:27:54.932824: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Conv3DBackpropFilterV2
2023-12-23 05:27:54.932832: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: Div
2023-12-23 05:27:54.932840: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Div
2023-12-23 05:27:54.932849: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: ApproximateEqual
2023-12-23 05:27:54.932857: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: ApproximateEqual
2023-12-23 05:27:54.932866: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: Conv3DBackpropInputV2
2023-12-23 05:27:54.932876: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Conv3DBackpropInputV2
2023-12-23 05:27:54.932885: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: Const
2023-12-23 05:27:54.932894: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Const
2023-12-23 05:27:54.932902: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: Reciprocal
2023-12-23 05:27:54.932910: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Reciprocal
2023-12-23 05:27:54.932919: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: Pad
2023-12-23 05:27:54.932927: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Pad
2023-12-23 05:27:54.932938: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: FusedBatchNormV3
2023-12-23 05:27:54.932947: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: FusedBatchNormV3
2023-12-23 05:27:54.932957: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: BatchMatMul
2023-12-23 05:27:54.932964: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: BatchMatMul
2023-12-23 05:27:54.932972: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: Softplus
2023-12-23 05:27:54.932980: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Softplus
2023-12-23 05:27:54.932989: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: Rank
2023-12-23 05:27:54.932996: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Rank
2023-12-23 05:27:54.933008: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: Lgamma
2023-12-23 05:27:54.933016: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Lgamma
2023-12-23 05:27:54.933025: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: Unpack
2023-12-23 05:27:54.933033: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Unpack
2023-12-23 05:27:54.933041: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: Add
2023-12-23 05:27:54.933050: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Add
2023-12-23 05:27:54.933058: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: CheckNumerics
2023-12-23 05:27:54.933067: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: CheckNumerics
2023-12-23 05:27:54.933075: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: LowerBound
2023-12-23 05:27:54.933084: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: LowerBound
2023-12-23 05:27:54.933096: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: Polygamma
2023-12-23 05:27:54.933103: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Polygamma
2023-12-23 05:27:54.933112: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: MatrixInverse
2023-12-23 05:27:54.933120: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: MatrixInverse
2023-12-23 05:27:54.933128: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: SqrtGrad
2023-12-23 05:27:54.933136: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: SqrtGrad
2023-12-23 05:27:54.933145: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: Cast
2023-12-23 05:27:54.933154: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Cast
2023-12-23 05:27:54.933164: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: _Retval
2023-12-23 05:27:54.933172: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: _Retval
2023-12-23 05:27:54.933181: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: DepthwiseConv2dNativeBackpropInput
2023-12-23 05:27:54.933189: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: DepthwiseConv2dNativeBackpropInput
2023-12-23 05:27:54.933197: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: Xlogy
2023-12-23 05:27:54.933205: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Xlogy
2023-12-23 05:27:54.933213: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: MatrixDiagPart
2023-12-23 05:27:54.933221: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: MatrixDiagPart
2023-12-23 05:27:54.933230: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: RFFT
2023-12-23 05:27:54.933239: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: RFFT
2023-12-23 05:27:54.933249: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: Asinh
2023-12-23 05:27:54.933256: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Asinh
2023-12-23 05:27:54.933266: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: AssignAddVariableOp
2023-12-23 05:27:54.933274: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: AssignAddVariableOp
2023-12-23 05:27:54.933283: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: Equal
2023-12-23 05:27:54.933290: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Equal
2023-12-23 05:27:54.933299: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: MaxPool3DGradGrad
2023-12-23 05:27:54.933307: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: MaxPool3DGradGrad
2023-12-23 05:27:54.933316: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: IRFFT3D
2023-12-23 05:27:54.933324: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: IRFFT3D
2023-12-23 05:27:54.933334: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: NotEqual
2023-12-23 05:27:54.933341: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: NotEqual
2023-12-23 05:27:54.933350: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: ResizeBilinearGrad
2023-12-23 05:27:54.933357: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: ResizeBilinearGrad
2023-12-23 05:27:54.933366: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: XlaDynamicSlice
2023-12-23 05:27:54.933375: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: XlaDynamicSlice
2023-12-23 05:27:54.933384: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: LeakyReluGrad
2023-12-23 05:27:54.933392: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: LeakyReluGrad
2023-12-23 05:27:54.933401: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: ExtractImagePatches
2023-12-23 05:27:54.933409: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: ExtractImagePatches
2023-12-23 05:27:54.933417: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: Xlog1py
2023-12-23 05:27:54.933425: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Xlog1py
2023-12-23 05:27:54.933434: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: MaxPoolGradGradV2
2023-12-23 05:27:54.933442: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: MaxPoolGradGradV2
2023-12-23 05:27:54.933450: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: ConjugateTranspose
2023-12-23 05:27:54.933460: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: ConjugateTranspose
2023-12-23 05:27:54.933470: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: XlaSelectAndScatter
2023-12-23 05:27:54.933478: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: XlaSelectAndScatter
2023-12-23 05:27:54.933489: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: BatchMatMulV2
2023-12-23 05:27:54.933496: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: BatchMatMulV2
2023-12-23 05:27:54.933505: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: StatelessRandomGetKeyCounterAlg
2023-12-23 05:27:54.933513: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: StatelessRandomGetKeyCounterAlg
2023-12-23 05:27:54.933522: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: SoftsignGrad
2023-12-23 05:27:54.933529: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: SoftsignGrad
2023-12-23 05:27:54.933538: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: RFFT2D
2023-12-23 05:27:54.933547: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: RFFT2D
2023-12-23 05:27:54.933556: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: Square
2023-12-23 05:27:54.933563: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Square
2023-12-23 05:27:54.933571: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: Elu
2023-12-23 05:27:54.933579: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Elu
2023-12-23 05:27:54.933587: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: BroadcastTo
2023-12-23 05:27:54.933596: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: BroadcastTo
2023-12-23 05:27:54.933605: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: IsInf
2023-12-23 05:27:54.933612: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: IsInf
2023-12-23 05:27:54.933620: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: LRN
2023-12-23 05:27:54.933628: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: LRN
2023-12-23 05:27:54.933637: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: LRNGrad
2023-12-23 05:27:54.933644: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: LRNGrad
2023-12-23 05:27:54.933653: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: LogicalNot
2023-12-23 05:27:54.933659: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: LogicalNot
2023-12-23 05:27:54.933667: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: SymbolicGradient
2023-12-23 05:27:54.933676: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: SymbolicGradient
2023-12-23 05:27:54.933685: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: XlaSend
2023-12-23 05:27:54.933693: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: XlaSend
2023-12-23 05:27:54.933703: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: LinSpace
2023-12-23 05:27:54.933714: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: LinSpace
2023-12-23 05:27:54.933724: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: Round
2023-12-23 05:27:54.933732: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Round
2023-12-23 05:27:54.933740: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: XlaDynamicUpdateSlice
2023-12-23 05:27:54.933750: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: XlaDynamicUpdateSlice
2023-12-23 05:27:54.933761: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: XlaDotV2
2023-12-23 05:27:54.933772: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: XlaDotV2
2023-12-23 05:27:54.933783: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: StatefulPartitionedCall
2023-12-23 05:27:54.933792: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: StatefulPartitionedCall
2023-12-23 05:27:54.933801: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: SquaredDifference
2023-12-23 05:27:54.933809: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: SquaredDifference
2023-12-23 05:27:54.933818: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: Igamma
2023-12-23 05:27:54.933825: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Igamma
2023-12-23 05:27:54.933834: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: MatMul
2023-12-23 05:27:54.933842: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: MatMul
2023-12-23 05:27:54.933850: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: FakeQuantWithMinMaxArgsGradient
2023-12-23 05:27:54.933856: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: FakeQuantWithMinMaxArgsGradient
2023-12-23 05:27:54.933865: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: NonMaxSuppressionV4
2023-12-23 05:27:54.933874: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: NonMaxSuppressionV4
2023-12-23 05:27:54.933883: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: FloorMod
2023-12-23 05:27:54.933891: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: FloorMod
2023-12-23 05:27:54.933899: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: RandomGammaGrad
2023-12-23 05:27:54.933906: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: RandomGammaGrad
2023-12-23 05:27:54.933915: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: Neg
2023-12-23 05:27:54.933922: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Neg
2023-12-23 05:27:54.933931: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: AdjustContrastv2
2023-12-23 05:27:54.933938: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: AdjustContrastv2
2023-12-23 05:27:54.933946: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: DeviceIndex
2023-12-23 05:27:54.933952: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: DeviceIndex
2023-12-23 05:27:54.933959: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: Concat
2023-12-23 05:27:54.933967: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Concat
2023-12-23 05:27:54.933975: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: RandomUniformInt
2023-12-23 05:27:54.933984: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: RandomUniformInt
2023-12-23 05:27:54.933992: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: ConcatOffset
2023-12-23 05:27:54.933998: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: ConcatOffset
2023-12-23 05:27:54.934010: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: ResizeBilinear
2023-12-23 05:27:54.934021: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: ResizeBilinear
2023-12-23 05:27:54.934033: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: Prod
2023-12-23 05:27:54.934044: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Prod
2023-12-23 05:27:54.934054: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: AddN
2023-12-23 05:27:54.934062: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: AddN
2023-12-23 05:27:54.934071: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: Max
2023-12-23 05:27:54.934080: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Max
2023-12-23 05:27:54.934089: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: Cross
2023-12-23 05:27:54.934096: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Cross
2023-12-23 05:27:54.934106: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: ArgMin
2023-12-23 05:27:54.934116: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: ArgMin
2023-12-23 05:27:54.934128: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: DepthToSpace
2023-12-23 05:27:54.934136: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: DepthToSpace
2023-12-23 05:27:54.934145: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: StatelessCase
2023-12-23 05:27:54.934154: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: StatelessCase
2023-12-23 05:27:54.934165: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: Qr
2023-12-23 05:27:54.934173: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Qr
2023-12-23 05:27:54.934181: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: AvgPool3D
2023-12-23 05:27:54.934189: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: AvgPool3D
2023-12-23 05:27:54.934198: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: QuantizeAndDequantizeV3
2023-12-23 05:27:54.934205: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: QuantizeAndDequantizeV3
2023-12-23 05:27:54.934214: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: RandomShuffle
2023-12-23 05:27:54.934222: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: RandomShuffle
2023-12-23 05:27:54.934230: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: RFFT3D
2023-12-23 05:27:54.934239: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: RFFT3D
2023-12-23 05:27:54.934249: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: MaxPoolGradGrad
2023-12-23 05:27:54.934256: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: MaxPoolGradGrad
2023-12-23 05:27:54.934266: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: TensorArrayGatherV3
2023-12-23 05:27:54.934274: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: TensorArrayGatherV3
2023-12-23 05:27:54.934283: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: TruncatedNormal
2023-12-23 05:27:54.936306: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: TruncatedNormal
2023-12-23 05:27:54.936320: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: ResourceApplyFtrlV2
2023-12-23 05:27:54.936328: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: ResourceApplyFtrlV2
2023-12-23 05:27:54.936338: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: Sum
2023-12-23 05:27:54.936347: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Sum
2023-12-23 05:27:54.936356: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: Mean
2023-12-23 05:27:54.936365: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Mean
2023-12-23 05:27:54.936374: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: Squeeze
2023-12-23 05:27:54.936382: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Squeeze
2023-12-23 05:27:54.936391: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: RandomUniform
2023-12-23 05:27:54.936401: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: RandomUniform
2023-12-23 05:27:54.936410: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: ResourceApplyFtrl
2023-12-23 05:27:54.936418: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: ResourceApplyFtrl
2023-12-23 05:27:54.936428: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: StatefulUniformInt
2023-12-23 05:27:54.936438: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: StatefulUniformInt
2023-12-23 05:27:54.936447: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: LessEqual
2023-12-23 05:27:54.936455: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: LessEqual
2023-12-23 05:27:54.936463: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: LogSoftmax
2023-12-23 05:27:54.936471: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: LogSoftmax
2023-12-23 05:27:54.936480: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: StatelessRandomGetKeyCounter
2023-12-23 05:27:54.936488: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: StatelessRandomGetKeyCounter
2023-12-23 05:27:54.936496: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: XlaReplicaId
2023-12-23 05:27:54.936502: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: XlaReplicaId
2023-12-23 05:27:54.936509: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: Sign
2023-12-23 05:27:54.936517: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Sign
2023-12-23 05:27:54.936526: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: Reshape
2023-12-23 05:27:54.936535: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Reshape
2023-12-23 05:27:54.936544: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: RsqrtGrad
2023-12-23 05:27:54.936552: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: RsqrtGrad
2023-12-23 05:27:54.936561: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: ReverseSequence
2023-12-23 05:27:54.936570: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: ReverseSequence
2023-12-23 05:27:54.936580: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: Roll
2023-12-23 05:27:54.936590: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Roll
2023-12-23 05:27:54.936600: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: StackPushV2
2023-12-23 05:27:54.936609: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: StackPushV2
2023-12-23 05:27:54.936619: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: Cumsum
2023-12-23 05:27:54.936628: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Cumsum
2023-12-23 05:27:54.936637: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: Atan2
2023-12-23 05:27:54.936645: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Atan2
2023-12-23 05:27:54.936655: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: ResourceApplyKerasMomentum
2023-12-23 05:27:54.936664: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: ResourceApplyKerasMomentum
2023-12-23 05:27:54.936672: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: StatelessWhile
2023-12-23 05:27:54.936681: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: StatelessWhile
2023-12-23 05:27:54.936691: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: Cumprod
2023-12-23 05:27:54.936700: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Cumprod
2023-12-23 05:27:54.936709: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: ResourceApplyAdagradV2
2023-12-23 05:27:54.936717: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: ResourceApplyAdagradV2
2023-12-23 05:27:54.936726: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: ScatterNd
2023-12-23 05:27:54.936735: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: ScatterNd
2023-12-23 05:27:54.936745: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: BiasAdd
2023-12-23 05:27:54.936752: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: BiasAdd
2023-12-23 05:27:54.936763: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: Mul
2023-12-23 05:27:54.936771: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Mul
2023-12-23 05:27:54.936780: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: TensorScatterAdd
2023-12-23 05:27:54.936789: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: TensorScatterAdd
2023-12-23 05:27:54.936798: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: MatrixDiagPartV3
2023-12-23 05:27:54.936806: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: MatrixDiagPartV3
2023-12-23 05:27:54.936815: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: TensorScatterMax
2023-12-23 05:27:54.936824: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: TensorScatterMax
2023-12-23 05:27:54.936832: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: ResourceApplyAdagradDA
2023-12-23 05:27:54.936840: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: ResourceApplyAdagradDA
2023-12-23 05:27:54.936849: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: TensorScatterUpdate
2023-12-23 05:27:54.936858: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: TensorScatterUpdate
2023-12-23 05:27:54.936868: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: UnsortedSegmentSum
2023-12-23 05:27:54.936879: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: UnsortedSegmentSum
2023-12-23 05:27:54.936891: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: StatelessRandomNormalV2
2023-12-23 05:27:54.936900: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: StatelessRandomNormalV2
2023-12-23 05:27:54.936910: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: Relu6
2023-12-23 05:27:54.936917: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Relu6
2023-12-23 05:27:54.936927: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: UnsortedSegmentMin
2023-12-23 05:27:54.936938: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: UnsortedSegmentMin
2023-12-23 05:27:54.936948: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: Select
2023-12-23 05:27:54.936956: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Select
2023-12-23 05:27:54.936964: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: SelectV2
2023-12-23 05:27:54.936972: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: SelectV2
2023-12-23 05:27:54.936980: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: Atan
2023-12-23 05:27:54.936988: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Atan
2023-12-23 05:27:54.936996: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: BesselI0e
2023-12-23 05:27:54.937007: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: BesselI0e
2023-12-23 05:27:54.937017: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: Range
2023-12-23 05:27:54.937025: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Range
2023-12-23 05:27:54.937034: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: CollectiveReduceV2
2023-12-23 05:27:54.937043: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: CollectiveReduceV2
2023-12-23 05:27:54.937051: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: Ndtri
2023-12-23 05:27:54.937059: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Ndtri
2023-12-23 05:27:54.937067: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: SoftmaxCrossEntropyWithLogits
2023-12-23 05:27:54.937075: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: SoftmaxCrossEntropyWithLogits
2023-12-23 05:27:54.937085: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: Shape
2023-12-23 05:27:54.937093: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Shape
2023-12-23 05:27:54.937104: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: ShapeN
2023-12-23 05:27:54.937112: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: ShapeN
2023-12-23 05:27:54.937122: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: XlaSvd
2023-12-23 05:27:54.937129: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: XlaSvd
2023-12-23 05:27:54.937139: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: ResourceApplyRMSProp
2023-12-23 05:27:54.937147: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: ResourceApplyRMSProp
2023-12-23 05:27:54.937155: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: Size
2023-12-23 05:27:54.937164: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Size
2023-12-23 05:27:54.937174: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: ReverseV2
2023-12-23 05:27:54.937183: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: ReverseV2
2023-12-23 05:27:54.937192: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: ResourceApplyCenteredRMSProp
2023-12-23 05:27:54.937200: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: ResourceApplyCenteredRMSProp
2023-12-23 05:27:54.937209: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: XlaPad
2023-12-23 05:27:54.937218: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: XlaPad
2023-12-23 05:27:54.937226: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: All
2023-12-23 05:27:54.937234: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: All
2023-12-23 05:27:54.937242: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: ExpandDims
2023-12-23 05:27:54.937251: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: ExpandDims
2023-12-23 05:27:54.937261: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: Mod
2023-12-23 05:27:54.937269: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Mod
2023-12-23 05:27:54.937278: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: OnesLike
2023-12-23 05:27:54.937286: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: OnesLike
2023-12-23 05:27:54.937294: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: DiagPart
2023-12-23 05:27:54.937301: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: DiagPart
2023-12-23 05:27:54.937311: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: StatelessRandomUniformIntV2
2023-12-23 05:27:54.937320: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: StatelessRandomUniformIntV2
2023-12-23 05:27:54.937330: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: StatelessTruncatedNormalV2
2023-12-23 05:27:54.937339: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: StatelessTruncatedNormalV2
2023-12-23 05:27:54.937350: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: ResourceScatterUpdate
2023-12-23 05:27:54.937358: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: ResourceScatterUpdate
2023-12-23 05:27:54.937369: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: EmptyTensorList
2023-12-23 05:27:54.969815: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: EmptyTensorList
2023-12-23 05:27:54.969829: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: Any
2023-12-23 05:27:54.969837: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Any
2023-12-23 05:27:54.969845: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: XlaSharding
2023-12-23 05:27:54.969854: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: XlaSharding
2023-12-23 05:27:54.969862: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: Slice
2023-12-23 05:27:54.969871: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Slice
2023-12-23 05:27:54.969881: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: MirrorPadGrad
2023-12-23 05:27:54.969889: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: MirrorPadGrad
2023-12-23 05:27:54.969900: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: Conv2D
2023-12-23 05:27:54.969908: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Conv2D
2023-12-23 05:27:54.969916: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: Reverse
2023-12-23 05:27:54.969925: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Reverse
2023-12-23 05:27:54.969933: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: InvertPermutation
2023-12-23 05:27:54.969941: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: InvertPermutation
2023-12-23 05:27:54.969950: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: Softmax
2023-12-23 05:27:54.969958: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Softmax
2023-12-23 05:27:54.969966: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: RealDiv
2023-12-23 05:27:54.969974: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: RealDiv
2023-12-23 05:27:54.969985: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: XlaSort
2023-12-23 05:27:54.969993: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: XlaSort
2023-12-23 05:27:54.970002: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: XlaKeyValueSort
2023-12-23 05:27:54.970015: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: XlaKeyValueSort
2023-12-23 05:27:54.970026: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: Cos
2023-12-23 05:27:54.970035: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Cos
2023-12-23 05:27:54.970044: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: XlaVariadicSort
2023-12-23 05:27:54.970052: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: XlaVariadicSort
2023-12-23 05:27:54.970062: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: QuantizeAndDequantizeV2
2023-12-23 05:27:54.970070: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: QuantizeAndDequantizeV2
2023-12-23 05:27:54.970080: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: SpaceToBatchND
2023-12-23 05:27:54.970090: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: SpaceToBatchND
2023-12-23 05:27:54.970100: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: LeakyRelu
2023-12-23 05:27:54.970108: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: LeakyRelu
2023-12-23 05:27:54.970117: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: SpaceToBatch
2023-12-23 05:27:54.970125: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: SpaceToBatch
2023-12-23 05:27:54.970135: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: SpaceToDepth
2023-12-23 05:27:54.970143: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: SpaceToDepth
2023-12-23 05:27:54.970152: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: BatchToSpace
2023-12-23 05:27:54.970161: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: BatchToSpace
2023-12-23 05:27:54.970171: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: Asin
2023-12-23 05:27:54.970179: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Asin
2023-12-23 05:27:54.970187: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: SparseToDense
2023-12-23 05:27:54.970196: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: SparseToDense
2023-12-23 05:27:54.970206: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: SplitV
2023-12-23 05:27:54.970215: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: SplitV
2023-12-23 05:27:54.970225: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: StridedSlice
2023-12-23 05:27:54.970233: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: StridedSlice
2023-12-23 05:27:54.970245: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: Complex
2023-12-23 05:27:54.970255: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Complex
2023-12-23 05:27:54.970265: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: Imag
2023-12-23 05:27:54.970273: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Imag
2023-12-23 05:27:54.970283: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: XlaSpmdFullToShardShape
2023-12-23 05:27:54.970293: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: XlaSpmdFullToShardShape
2023-12-23 05:27:54.970303: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: StatefulUniform
2023-12-23 05:27:54.970312: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: StatefulUniform
2023-12-23 05:27:54.970322: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: ZerosLike
2023-12-23 05:27:54.970329: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: ZerosLike
2023-12-23 05:27:54.970340: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: Dequantize
2023-12-23 05:27:54.970349: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Dequantize
2023-12-23 05:27:54.970359: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: StatefulStandardNormalV2
2023-12-23 05:27:54.970369: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: StatefulStandardNormalV2
2023-12-23 05:27:54.970379: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: StatefulTruncatedNormal
2023-12-23 05:27:54.970388: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: StatefulTruncatedNormal
2023-12-23 05:27:54.970398: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: StatefulUniformFullInt
2023-12-23 05:27:54.970408: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: StatefulUniformFullInt
2023-12-23 05:27:54.970418: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: TensorListReserve
2023-12-23 05:27:54.970427: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: TensorListReserve
2023-12-23 05:27:54.970440: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: StatelessRandomUniform
2023-12-23 05:27:54.970452: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: StatelessRandomUniform
2023-12-23 05:27:54.970464: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: StatelessRandomUniformInt
2023-12-23 05:27:54.970475: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: StatelessRandomUniformInt
2023-12-23 05:27:54.970486: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: DataFormatVecPermute
2023-12-23 05:27:54.970494: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: DataFormatVecPermute
2023-12-23 05:27:54.970502: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: DataFormatVecPermute
2023-12-23 05:27:54.970510: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: DataFormatVecPermute
2023-12-23 05:27:54.970520: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: StatelessRandomUniformFullInt
2023-12-23 05:27:54.970533: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: StatelessRandomUniformFullInt
2023-12-23 05:27:54.970543: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: SoftplusGrad
2023-12-23 05:27:54.970550: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: SoftplusGrad
2023-12-23 05:27:54.970560: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: TensorListConcatV2
2023-12-23 05:27:54.970570: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: TensorListConcatV2
2023-12-23 05:27:54.970580: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: StatelessRandomNormal
2023-12-23 05:27:54.970591: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: StatelessRandomNormal
2023-12-23 05:27:54.970602: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: If
2023-12-23 05:27:54.970613: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: If
2023-12-23 05:27:54.970624: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: StatelessTruncatedNormal
2023-12-23 05:27:54.970634: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: StatelessTruncatedNormal
2023-12-23 05:27:54.970645: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: StatelessRandomUniformV2
2023-12-23 05:27:54.970654: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: StatelessRandomUniformV2
2023-12-23 05:27:54.970664: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: StatelessRandomUniformFullIntV2
2023-12-23 05:27:54.970673: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: StatelessRandomUniformFullIntV2
2023-12-23 05:27:54.970681: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: StatelessRandomGetAlg
2023-12-23 05:27:54.970688: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: StatelessRandomGetAlg
2023-12-23 05:27:54.970696: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: StridedSliceGrad
2023-12-23 05:27:54.970705: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: StridedSliceGrad
2023-12-23 05:27:54.970715: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: TensorStridedSliceUpdate
2023-12-23 05:27:54.970724: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: TensorStridedSliceUpdate
2023-12-23 05:27:54.970733: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: TensorArrayWriteV3
2023-12-23 05:27:54.970741: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: TensorArrayWriteV3
2023-12-23 05:27:54.970749: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: TensorArraySizeV3
2023-12-23 05:27:54.970756: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: TensorArraySizeV3
2023-12-23 05:27:54.970762: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: TensorArrayGradV3
2023-12-23 05:27:54.970768: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: TensorArrayGradV3
2023-12-23 05:27:54.970776: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: ResourceGather
2023-12-23 05:27:54.970785: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: ResourceGather
2023-12-23 05:27:54.970794: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: TensorArrayCloseV3
2023-12-23 05:27:54.970800: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: TensorArrayCloseV3
2023-12-23 05:27:54.970807: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: TensorListElementShape
2023-12-23 05:27:54.970815: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: TensorListElementShape
2023-12-23 05:27:54.970825: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: ArgMax
2023-12-23 05:27:54.970836: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: ArgMax
2023-12-23 05:27:54.970846: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: IsFinite
2023-12-23 05:27:54.970855: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: IsFinite
2023-12-23 05:27:54.970863: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: TensorListGetItem
2023-12-23 05:27:54.970871: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: TensorListGetItem
2023-12-23 05:27:54.970879: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: TensorListGather
2023-12-23 05:27:54.970887: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: TensorListGather
2023-12-23 05:27:54.970895: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: Softsign
2023-12-23 05:27:54.970903: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Softsign
2023-12-23 05:27:54.970912: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: TensorListFromTensor
2023-12-23 05:27:54.970923: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: TensorListFromTensor
2023-12-23 05:27:54.970932: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: MatrixDiagV3
2023-12-23 05:27:54.970940: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: MatrixDiagV3
2023-12-23 05:27:54.970948: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: TensorListSetItem
2023-12-23 05:27:54.970956: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: TensorListSetItem
2023-12-23 05:27:54.970965: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: Tile
2023-12-23 05:27:54.970974: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Tile
2023-12-23 05:27:54.970985: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: TopKV2
2023-12-23 05:27:54.970993: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: TopKV2
2023-12-23 05:27:54.971002: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: TensorArrayV3
2023-12-23 05:27:54.971015: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: TensorArrayV3
2023-12-23 05:27:54.971024: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: ResourceApplyGradientDescent
2023-12-23 05:27:54.971034: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: ResourceApplyGradientDescent
2023-12-23 05:27:54.971044: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: Snapshot
2023-12-23 05:27:54.971052: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Snapshot
2023-12-23 05:27:54.971064: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: DivNoNan
2023-12-23 05:27:54.971072: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: DivNoNan
2023-12-23 05:27:54.971082: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: ResourceApplyProximalGradientDescent
2023-12-23 05:27:54.971091: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: ResourceApplyProximalGradientDescent
2023-12-23 05:27:54.971099: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: TensorListPopBack
2023-12-23 05:27:54.971107: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: TensorListPopBack
2023-12-23 05:27:54.971116: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: ResourceApplyMomentum
2023-12-23 05:27:54.971126: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: ResourceApplyMomentum
2023-12-23 05:27:54.971135: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: Rint
2023-12-23 05:27:54.971143: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Rint
2023-12-23 05:27:54.971152: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: ResourceApplyAdagrad
2023-12-23 05:27:54.971160: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: ResourceApplyAdagrad
2023-12-23 05:27:54.971169: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: FFT3D
2023-12-23 05:27:54.971177: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: FFT3D
2023-12-23 05:27:54.971186: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: Einsum
2023-12-23 05:27:54.971195: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Einsum
2023-12-23 05:27:54.971204: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: ResourceApplyAdam
2023-12-23 05:27:54.971212: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: ResourceApplyAdam
2023-12-23 05:27:54.971220: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: Log1p
2023-12-23 05:27:54.971228: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Log1p
2023-12-23 05:27:54.971237: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: Relu6Grad
2023-12-23 05:27:54.971245: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Relu6Grad
2023-12-23 05:27:54.971253: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: ResourceApplyAdaMax
2023-12-23 05:27:54.971262: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: ResourceApplyAdaMax
2023-12-23 05:27:54.971271: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: Transpose
2023-12-23 05:27:54.971280: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Transpose
2023-12-23 05:27:54.971290: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: Acos
2023-12-23 05:27:54.971298: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Acos
2023-12-23 05:27:54.971306: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: LogicalAnd
2023-12-23 05:27:54.971312: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: LogicalAnd
2023-12-23 05:27:54.971320: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: ComplexAbs
2023-12-23 05:27:54.971330: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: ComplexAbs
2023-12-23 05:27:54.971340: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: ClipByValue
2023-12-23 05:27:54.971349: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: ClipByValue
2023-12-23 05:27:54.971361: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: Angle
2023-12-23 05:27:54.971370: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Angle
2023-12-23 05:27:54.971380: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: Conj
2023-12-23 05:27:54.971387: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Conj
2023-12-23 05:27:54.971397: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: Abs
2023-12-23 05:27:54.971405: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Abs
2023-12-23 05:27:54.971415: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: XlaGather
2023-12-23 05:27:54.971424: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: XlaGather
2023-12-23 05:27:54.971433: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: Acosh
2023-12-23 05:27:54.971441: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Acosh
2023-12-23 05:27:54.971450: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: Cosh
2023-12-23 05:27:54.971459: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Cosh
2023-12-23 05:27:54.971467: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: Sin
2023-12-23 05:27:54.971475: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Sin
2023-12-23 05:27:54.971485: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: UnsortedSegmentMax
2023-12-23 05:27:54.971496: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: UnsortedSegmentMax
2023-12-23 05:27:54.971506: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: Exp
2023-12-23 05:27:54.971514: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Exp
2023-12-23 05:27:54.971523: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: Assert
2023-12-23 05:27:54.971531: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Assert
2023-12-23 05:27:54.971540: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: PopulationCount
2023-12-23 05:27:54.971548: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: PopulationCount
2023-12-23 05:27:54.971557: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: Rsqrt
2023-12-23 05:27:54.971565: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Rsqrt
2023-12-23 05:27:54.971573: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: Sinh
2023-12-23 05:27:54.971581: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Sinh
2023-12-23 05:27:54.971590: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: Tan
2023-12-23 05:27:54.971597: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Tan
2023-12-23 05:27:54.971607: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: GatherV2
2023-12-23 05:27:54.971618: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: GatherV2
2023-12-23 05:27:54.971628: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: Erfc
2023-12-23 05:27:54.971636: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Erfc
2023-12-23 05:27:54.971645: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: XlaReduceWindow
2023-12-23 05:27:54.971654: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: XlaReduceWindow
2023-12-23 05:27:54.971663: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: RngSkip
2023-12-23 05:27:54.971669: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: RngSkip
2023-12-23 05:27:54.971676: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: Erfinv
2023-12-23 05:27:54.971684: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Erfinv
2023-12-23 05:27:54.971694: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: Conv2DBackpropFilter
2023-12-23 05:27:54.971702: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Conv2DBackpropFilter
2023-12-23 05:27:54.971712: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: Min
2023-12-23 05:27:54.971721: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Min
2023-12-23 05:27:54.971731: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: Digamma
2023-12-23 05:27:54.971739: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: Digamma
2023-12-23 05:27:54.971746: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: BesselI1e
2023-12-23 05:27:54.971754: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: BesselI1e
2023-12-23 05:27:54.971763: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: _UnaryOpsComposition
2023-12-23 05:27:54.971770: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: _UnaryOpsComposition
2023-12-23 05:27:54.971779: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: XlaSpmdShardToFullShape
2023-12-23 05:27:54.971787: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: XlaSpmdShardToFullShape
2023-12-23 05:27:54.971796: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: ReadVariableOp
2023-12-23 05:27:54.971804: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: ReadVariableOp
2023-12-23 05:27:54.971813: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: AssignVariableOp
2023-12-23 05:27:54.971821: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: AssignVariableOp
2023-12-23 05:27:54.971857: I tensorflow/compiler/jit/mark_for_compilation_pass.cc:1152] Starting fuel: infinity
2023-12-23 05:27:54.971863: I tensorflow/compiler/jit/mark_for_compilation_pass.cc:1157] sorted_nodes.size() = 9
2023-12-23 05:27:54.972043: I tensorflow/compiler/tf2xla/xla_op_registry.cc:153] tf_xla_cpu_global_jit = 0
2023-12-23 05:27:54.972055: I tensorflow/compiler/tf2xla/xla_op_registry.cc:51] LaunchOpHasKernelForDevice kernel_class_name: XlaLocalLaunchOp
2023-12-23 05:27:54.972066: I tensorflow/compiler/tf2xla/xla_op_registry.cc:51] LaunchOpHasKernelForDevice kernel_class_name: XlaLocalLaunchOp
2023-12-23 05:27:54.972129: I tensorflow/compiler/jit/compilability_check_util.cc:73] Found uncompilable node _arg_X_0_0 (op _Arg): top level _Arg or _Retval
2023-12-23 05:27:54.972139: I tensorflow/compiler/jit/compilability_check_util.cc:73] Found uncompilable node _retval_Sigmoid_0_0 (op _Retval): top level _Arg or _Retval
2023-12-23 05:27:54.972146: I tensorflow/compiler/jit/mark_for_compilation_pass.cc:1312] compilation_candidates_.size() = 7
2023-12-23 05:27:54.972192: I tensorflow/compiler/jit/deadness_analysis.cc:1415] Done populating frame  using the pessimistic mode.
2023-12-23 05:27:54.972203: I tensorflow/compiler/jit/deadness_analysis.cc:1562] ^Add -> #true
2023-12-23 05:27:54.972208: I tensorflow/compiler/jit/deadness_analysis.cc:1562] Add:0 -> #true
2023-12-23 05:27:54.972213: I tensorflow/compiler/jit/deadness_analysis.cc:1562] ^Bias -> #true
2023-12-23 05:27:54.972217: I tensorflow/compiler/jit/deadness_analysis.cc:1562] Bias:0 -> #true
2023-12-23 05:27:54.972222: I tensorflow/compiler/jit/deadness_analysis.cc:1562] ^Bias/read -> #true
2023-12-23 05:27:54.972227: I tensorflow/compiler/jit/deadness_analysis.cc:1562] Bias/read:0 -> #true
2023-12-23 05:27:54.972232: I tensorflow/compiler/jit/deadness_analysis.cc:1562] ^MatMul -> #true
2023-12-23 05:27:54.972237: I tensorflow/compiler/jit/deadness_analysis.cc:1562] MatMul:0 -> #true
2023-12-23 05:27:54.972241: I tensorflow/compiler/jit/deadness_analysis.cc:1562] ^Sigmoid -> #true
2023-12-23 05:27:54.972246: I tensorflow/compiler/jit/deadness_analysis.cc:1562] Sigmoid:0 -> #true
2023-12-23 05:27:54.972251: I tensorflow/compiler/jit/deadness_analysis.cc:1562] ^Weight -> #true
2023-12-23 05:27:54.972256: I tensorflow/compiler/jit/deadness_analysis.cc:1562] Weight:0 -> #true
2023-12-23 05:27:54.972260: I tensorflow/compiler/jit/deadness_analysis.cc:1562] ^Weight/read -> #true
2023-12-23 05:27:54.972265: I tensorflow/compiler/jit/deadness_analysis.cc:1562] Weight/read:0 -> #true
2023-12-23 05:27:54.972270: I tensorflow/compiler/jit/deadness_analysis.cc:1562] ^_SOURCE -> #true
2023-12-23 05:27:54.972275: I tensorflow/compiler/jit/deadness_analysis.cc:1562] ^_arg_X_0_0 -> #true
2023-12-23 05:27:54.972279: I tensorflow/compiler/jit/deadness_analysis.cc:1562] _arg_X_0_0:0 -> #true
2023-12-23 05:27:54.972284: I tensorflow/compiler/jit/deadness_analysis.cc:1562] ^_retval_Sigmoid_0_0 -> #true
2023-12-23 05:27:54.972294: I tensorflow/compiler/jit/mark_for_compilation_pass.cc:626] DeadnessAnalysis time: 112 us (cumulative: 112 us, max: 112 us, #called: 1)
2023-12-23 05:27:54.972307: I tensorflow/compiler/jit/resource_operation_safety_analysis.cc:310] _SOURCE -> {}
2023-12-23 05:27:54.972318: I tensorflow/compiler/jit/resource_operation_safety_analysis.cc:310] Bias -> {}
2023-12-23 05:27:54.972324: I tensorflow/compiler/jit/resource_operation_safety_analysis.cc:310] Bias/read -> {}
2023-12-23 05:27:54.972330: I tensorflow/compiler/jit/resource_operation_safety_analysis.cc:310] Weight -> {}
2023-12-23 05:27:54.972335: I tensorflow/compiler/jit/resource_operation_safety_analysis.cc:310] Weight/read -> {}
2023-12-23 05:27:54.972341: I tensorflow/compiler/jit/resource_operation_safety_analysis.cc:310] _arg_X_0_0 -> {}
2023-12-23 05:27:54.972346: I tensorflow/compiler/jit/resource_operation_safety_analysis.cc:310] MatMul -> {}
2023-12-23 05:27:54.972351: I tensorflow/compiler/jit/resource_operation_safety_analysis.cc:310] Add -> {}
2023-12-23 05:27:54.972356: I tensorflow/compiler/jit/resource_operation_safety_analysis.cc:310] Sigmoid -> {}
2023-12-23 05:27:54.972361: I tensorflow/compiler/jit/resource_operation_safety_analysis.cc:310] _retval_Sigmoid_0_0 -> {}
2023-12-23 05:27:54.972366: I tensorflow/compiler/jit/resource_operation_safety_analysis.cc:310] _SINK -> {}
2023-12-23 05:27:54.972403: I tensorflow/compiler/jit/mark_for_compilation_pass.cc:833] Checking idempotence
2023-12-23 05:27:54.972410: I tensorflow/compiler/jit/mark_for_compilation_pass.cc:1670] Not compiling cluster with device /job:localhost/replica:0/task:0/device:GPU:0
2023-12-23 05:27:54.972425: I tensorflow/compiler/jit/mark_for_compilation_pass.cc:1484] *** Clustering info for graph of size 11
2023-12-23 05:27:54.972435: I tensorflow/compiler/jit/mark_for_compilation_pass.cc:1485]  Built 0 clusters, size 0 / 11 (0.00%)
2023-12-23 05:27:54.972440: I tensorflow/compiler/jit/mark_for_compilation_pass.cc:1504]  Unclustered nodes: 11 / 11 (100.00%)
2023-12-23 05:27:54.972446: I tensorflow/compiler/jit/mark_for_compilation_pass.cc:1509]   Add: 1 instances
2023-12-23 05:27:54.972450: I tensorflow/compiler/jit/mark_for_compilation_pass.cc:1509]   Const: 2 instances
2023-12-23 05:27:54.972455: I tensorflow/compiler/jit/mark_for_compilation_pass.cc:1509]   Identity: 2 instances
2023-12-23 05:27:54.972460: I tensorflow/compiler/jit/mark_for_compilation_pass.cc:1509]   MatMul: 1 instances
2023-12-23 05:27:54.972464: I tensorflow/compiler/jit/mark_for_compilation_pass.cc:1509]   NoOp: 2 instances
2023-12-23 05:27:54.972469: I tensorflow/compiler/jit/mark_for_compilation_pass.cc:1509]   Sigmoid: 1 instances
2023-12-23 05:27:54.972474: I tensorflow/compiler/jit/mark_for_compilation_pass.cc:1509]   _Arg: 1 instances
2023-12-23 05:27:54.972479: I tensorflow/compiler/jit/mark_for_compilation_pass.cc:1509]   _Retval: 1 instances
2023-12-23 05:27:54.972489: I tensorflow/compiler/jit/mark_for_compilation_pass.cc:1429] MarkForCompilationPassImpl::Run time: 657 us (cumulative: 657 us, max: 657 us, #called: 1)
2023-12-23 05:27:54.972520: W tensorflow/core/util/dump_graph.cc:134] Failed to dump after_group_2_phase_10_MarkForCompilationPass_1492560288 because dump location is not  specified through either TF_DUMP_GRAPH_PREFIX environment variable or function argument.
2023-12-23 05:27:54.972534: I tensorflow/core/common_runtime/optimization_registry.cc:41] Running optimization phase 12
2023-12-23 05:27:54.972539: I tensorflow/core/common_runtime/optimization_registry.cc:43] Running optimization pass: ForceXlaConstantsOnHostPass
2023-12-23 05:27:54.972561: W tensorflow/core/util/dump_graph.cc:134] Failed to dump after_group_2_phase_12_ForceXlaConstantsOnHostPass_1492560288 because dump location is not  specified through either TF_DUMP_GRAPH_PREFIX environment variable or function argument.
2023-12-23 05:27:54.972572: I tensorflow/core/common_runtime/optimization_registry.cc:41] Running optimization phase 20
2023-12-23 05:27:54.972577: I tensorflow/core/common_runtime/optimization_registry.cc:43] Running optimization pass: IncreaseDynamismForAutoJitPass
2023-12-23 05:27:54.972592: W tensorflow/core/util/dump_graph.cc:134] Failed to dump after_group_2_phase_20_IncreaseDynamismForAutoJitPass_1492560288 because dump location is not  specified through either TF_DUMP_GRAPH_PREFIX environment variable or function argument.
2023-12-23 05:27:54.972603: I tensorflow/core/common_runtime/optimization_registry.cc:41] Running optimization phase 30
2023-12-23 05:27:54.972608: I tensorflow/core/common_runtime/optimization_registry.cc:43] Running optimization pass: PartiallyDeclusterPass
2023-12-23 05:27:54.972644: W tensorflow/core/util/dump_graph.cc:134] Failed to dump after_group_2_phase_30_PartiallyDeclusterPass_1492560288 because dump location is not  specified through either TF_DUMP_GRAPH_PREFIX environment variable or function argument.
2023-12-23 05:27:54.972656: I tensorflow/core/common_runtime/optimization_registry.cc:41] Running optimization phase 40
2023-12-23 05:27:54.972661: I tensorflow/core/common_runtime/optimization_registry.cc:43] Running optimization pass: ReportClusteringInfoPass
2023-12-23 05:27:54.972743: I tensorflow/compiler/jit/xla_activity_logging_listener.cc:39] Not logging: logger not ready yet.
2023-12-23 05:27:54.972761: W tensorflow/core/util/dump_graph.cc:134] Failed to dump after_group_2_phase_40_ReportClusteringInfoPass_1492560288 because dump location is not  specified through either TF_DUMP_GRAPH_PREFIX environment variable or function argument.
2023-12-23 05:27:54.972773: I tensorflow/core/common_runtime/optimization_registry.cc:41] Running optimization phase 50
2023-12-23 05:27:54.972779: I tensorflow/core/common_runtime/optimization_registry.cc:43] Running optimization pass: EncapsulateSubgraphsPass
2023-12-23 05:27:54.972785: I tensorflow/compiler/jit/encapsulate_subgraphs_pass.cc:1165] EncapsulateSubgraphsPass::Run
2023-12-23 05:27:54.972798: W tensorflow/core/util/dump_graph.cc:134] Failed to dump encapsulate_subgraphs_before because dump location is not  specified through either TF_DUMP_GRAPH_PREFIX environment variable or function argument.
2023-12-23 05:27:54.972872: W tensorflow/core/util/dump_graph.cc:134] Failed to dump encapsulate_subgraphs_after because dump location is not  specified through either TF_DUMP_GRAPH_PREFIX environment variable or function argument.
2023-12-23 05:27:54.972894: I tensorflow/compiler/jit/xla_cluster_util.cc:555] # iterations = 1
2023-12-23 05:27:54.972903: I tensorflow/compiler/jit/xla_cluster_util.cc:555] # iterations = 1
2023-12-23 05:27:54.972908: I tensorflow/compiler/jit/xla_cluster_util.cc:569] GetNodesRelatedToRefVariables() found 0 nodes
2023-12-23 05:27:54.972920: I tensorflow/compiler/jit/encapsulate_subgraphs_pass.cc:1321] Has ref vars = 0, node: 
_SOURCENoOp*
_XlaHasReferenceVars(
2023-12-23 05:27:54.972926: I tensorflow/compiler/jit/encapsulate_subgraphs_pass.cc:1321] Has ref vars = 0, node: 
_SINKNoOp*
_XlaHasReferenceVars(
2023-12-23 05:27:54.972938: I tensorflow/compiler/jit/encapsulate_subgraphs_pass.cc:1321] Has ref vars = 0, node: 
/device:GPU:0*
_XlaHasReferenceVars(
2023-12-23 05:27:54.972948: I tensorflow/compiler/jit/encapsulate_subgraphs_pass.cc:1321] Has ref vars = 0, node: 

/device:GPU:0*tityWeight"
_XlaHasReferenceVars(
2023-12-23 05:27:54.972956: I tensorflow/compiler/jit/encapsulate_subgraphs_pass.cc:1321] Has ref vars = 0, node: 
/device:GPU:0*
_XlaHasReferenceVars(
2023-12-23 05:27:54.972965: I tensorflow/compiler/jit/encapsulate_subgraphs_pass.cc:1321] Has ref vars = 0, node: 
/device:GPU:0*eaIdentityBias"
_XlaHasReferenceVars(
2023-12-23 05:27:54.972973: I tensorflow/compiler/jit/encapsulate_subgraphs_pass.cc:1321] Has ref vars = 0, node: 
MatMulMatMulX
/device:GPU:0*eight/read"
T0*

transpose_a(
2023-12-23 05:27:54.972981: I tensorflow/compiler/jit/encapsulate_subgraphs_pass.cc:1321] Has ref vars = 0, node: 
/device:GPU:0*  Bias/read"
_XlaHasReferenceVars(
2023-12-23 05:27:54.972989: I tensorflow/compiler/jit/encapsulate_subgraphs_pass.cc:1321] Has ref vars = 0, node: 
/device:GPU:0*Add"
_XlaHasReferenceVars(
2023-12-23 05:27:54.972996: I tensorflow/compiler/jit/encapsulate_subgraphs_pass.cc:1321] Has ref vars = 0, node: 

_arg_X_0_0_Arg*
_XlaHasReferenceVars(
2023-12-23 05:27:54.973003: I tensorflow/compiler/jit/encapsulate_subgraphs_pass.cc:1321] Has ref vars = 0, node: 
_retval_Sigmoid_0_0_RetvalSigmoid*
_XlaHasReferenceVars(
2023-12-23 05:27:54.973036: W tensorflow/core/util/dump_graph.cc:134] Failed to dump after_group_2_phase_50_EncapsulateSubgraphsPass_1492592960 because dump location is not  specified through either TF_DUMP_GRAPH_PREFIX environment variable or function argument.
2023-12-23 05:27:54.973049: I tensorflow/core/common_runtime/optimization_registry.cc:41] Running optimization phase 60
2023-12-23 05:27:54.973054: I tensorflow/core/common_runtime/optimization_registry.cc:43] Running optimization pass: BuildXlaOpsPass
2023-12-23 05:27:54.973062: I tensorflow/compiler/jit/build_xla_ops_pass.cc:604] print_outputs = 0
2023-12-23 05:27:54.973067: I tensorflow/compiler/jit/build_xla_ops_pass.cc:605] check_input_numerics = 0
2023-12-23 05:27:54.973071: I tensorflow/compiler/jit/build_xla_ops_pass.cc:606] check_output_numerics = 0
2023-12-23 05:27:54.973087: W tensorflow/core/util/dump_graph.cc:134] Failed to dump build_xla_ops because dump location is not  specified through either TF_DUMP_GRAPH_PREFIX environment variable or function argument.
2023-12-23 05:27:54.973109: W tensorflow/core/util/dump_graph.cc:134] Failed to dump after_group_2_phase_60_BuildXlaOpsPass_1492592960 because dump location is not  specified through either TF_DUMP_GRAPH_PREFIX environment variable or function argument.
2023-12-23 05:27:54.973217: I tensorflow/core/graph/graph_partition.cc:282] Receiving data from _arg_X_0_0 (_Arg) on /job:localhost/replica:0/task:0/device:CPU:0 in device memory for MatMul (MatMul) on /job:localhost/replica:0/task:0/device:GPU:0 in device memory
2023-12-23 05:27:54.973249: I tensorflow/core/graph/graph_partition.cc:282] Receiving data from Sigmoid (Sigmoid) on /job:localhost/replica:0/task:0/device:GPU:0 in device memory for _retval_Sigmoid_0_0 (_Retval) on /job:localhost/replica:0/task:0/device:CPU:0 in device memory
2023-12-23 05:27:54.973269: I tensorflow/core/graph/graph_partition.cc:1242] Added send/recv: controls=0, data=2
2023-12-23 05:27:54.973275: W tensorflow/core/util/dump_graph.cc:134] Failed to dump partition_/job:localhost/replica:0/task:0/device:CPU:0_30461752 because dump location is not  specified through either TF_DUMP_GRAPH_PREFIX environment variable or function argument.
2023-12-23 05:27:54.973282: W tensorflow/core/util/dump_graph.cc:134] Failed to dump partition_/job:localhost/replica:0/task:0/device:GPU:0_31828408 because dump location is not  specified through either TF_DUMP_GRAPH_PREFIX environment variable or function argument.
2023-12-23 05:27:54.973363: I tensorflow/core/common_runtime/optimization_registry.cc:41] Running optimization phase 1
2023-12-23 05:27:54.973370: I tensorflow/core/common_runtime/optimization_registry.cc:43] Running optimization pass: MklLayoutRewritePass
2023-12-23 05:27:54.973375: I tensorflow/core/common_runtime/mkl_layout_pass.cc:4126] TF-MKL: MKL is not enabled
2023-12-23 05:27:54.973403: W tensorflow/core/util/dump_graph.cc:134] Failed to dump after_group_3_phase_1_MklLayoutRewritePass_partition_/job:localhost/replica:0/task:0/device:GPU:0_1492560288 because dump location is not  specified through either TF_DUMP_GRAPH_PREFIX environment variable or function argument.
2023-12-23 05:27:54.973427: W tensorflow/core/util/dump_graph.cc:134] Failed to dump after_group_3_phase_1_MklLayoutRewritePass_partition_/job:localhost/replica:0/task:0/device:CPU:0_1492592960 because dump location is not  specified through either TF_DUMP_GRAPH_PREFIX environment variable or function argument.
2023-12-23 05:27:54.973498: I tensorflow/core/framework/log_memory.cc:34] __LOG_MEMORY__ MemoryLogTensorAllocation { step_id: -6 kernel_name: "Unknown (from Proto)" tensor { dtype: DT_FLOAT shape { dim { size: 7 } } allocation_description { requested_bytes: 28 allocated_bytes: 28 allocator_name: "cpu" allocation_id: 2 has_single_reference: true ptr: 1527102272 } } }
2023-12-23 05:27:54.973516: I tensorflow/core/framework/log_memory.cc:34] __LOG_MEMORY__ MemoryLogTensorDeallocation { allocation_id: 2 allocator_name: "cpu" }
2023-12-23 05:27:54.973542: I tensorflow/core/framework/log_memory.cc:34] __LOG_MEMORY__ MemoryLogTensorAllocation { step_id: -6 kernel_name: "Unknown (from Proto)" tensor { dtype: DT_FLOAT shape { dim { size: 5 } dim { size: 7 } } allocation_description { requested_bytes: 140 allocated_bytes: 140 allocator_name: "cpu" allocation_id: 3 has_single_reference: true ptr: 1527104320 } } }
2023-12-23 05:27:54.973557: I tensorflow/core/framework/log_memory.cc:34] __LOG_MEMORY__ MemoryLogTensorDeallocation { allocation_id: 3 allocator_name: "cpu" }
2023-12-23 05:27:54.973596: I tensorflow/core/common_runtime/direct_session.cc:1720] Created 
() -> () {
  n4 = Const[_XlaHasReferenceVars=false, dtype=float, value=Tensor<type: float shape: [7] values: 0 0 0...>, device=GPU:0]()
  n5 = Identity[T=float, _XlaHasReferenceVars=false, _class=["loc:@Bias"], device=GPU:0](n4)
  n2 = Const[_XlaHasReferenceVars=false, dtype=float, value=Tensor<type: float shape: [5,7] values: [0.0188236237 -0.0105859637 0.016250791...]...>, device=GPU:0]()
  n3 = Identity[T=float, _XlaHasReferenceVars=false, _class=["loc:@Weight"], device=GPU:0](n2)
  n6 = _Recv[_dst="MatMul", _src="_arg_X_0_0", client_terminated=false, recv_device="/job:localhost/replica:0/task:0/device:GPU:0", send_device="/job:localhost/replica:0/task:0/device:CPU:0", send_device_incarnation=1, tensor_name="edge_13__arg_X_0_0", tensor_type=float, device=GPU:0]()
  n7 = MatMul[T=float, _XlaHasReferenceVars=false, transpose_a=false, transpose_b=false, device=GPU:0](n6, n3)
  n8 = Add[T=float, _XlaHasReferenceVars=false, device=GPU:0](n7, n5)
  n9 = Sigmoid[T=float, _XlaHasReferenceVars=false, device=GPU:0](n8)
  n10 = _Send[T=float, _dst="_retval_Sigmoid_0_0", _src="Sigmoid", client_terminated=false, recv_device="/job:localhost/replica:0/task:0/device:CPU:0", send_device="/job:localhost/replica:0/task:0/device:GPU:0", send_device_incarnation=1, tensor_name="edge_14_Sigmoid", device=GPU:0](n9)
}
 for /job:localhost/replica:0/task:0/device:GPU:0
2023-12-23 05:27:54.973645: I tensorflow/core/common_runtime/direct_session.cc:1720] Created 
(n2:float@CPU:0) -> (n4:float@CPU:0) {
  n4 = _Recv[_dst="_retval_Sigmoid_0_0", _src="Sigmoid", client_terminated=false, recv_device="/job:localhost/replica:0/task:0/device:CPU:0", send_device="/job:localhost/replica:0/task:0/device:GPU:0", send_device_incarnation=1, tensor_name="edge_14_Sigmoid", tensor_type=float, device=CPU:0]()
  n3 = _Send[T=float, _dst="MatMul", _src="_arg_X_0_0", client_terminated=false, recv_device="/job:localhost/replica:0/task:0/device:GPU:0", send_device="/job:localhost/replica:0/task:0/device:CPU:0", send_device_incarnation=1, tensor_name="edge_13__arg_X_0_0", device=CPU:0](n2)
}
 for /job:localhost/replica:0/task:0/device:CPU:0
2023-12-23 05:27:54.973686: I tensorflow/core/common_runtime/function_utils.cc:78] Graph Initial #nodes 11 #edges 13
2023-12-23 05:27:54.973692: I tensorflow/core/common_runtime/function_utils.cc:164] Removing list array converter
2023-12-23 05:27:54.973713: I tensorflow/core/common_runtime/function_utils.cc:78] Graph ReCopy #nodes 11 #edges 14
2023-12-23 05:27:54.973724: I tensorflow/core/framework/op_kernel.cc:1378] No device-specific kernels found for NodeDef '{{node _SOURCE}}'Will fall back to a default kernel.

2023-12-23 05:27:54.973733: I tensorflow/core/framework/op_kernel.cc:1378] No device-specific kernels found for NodeDef '{{node _SINK}}'Will fall back to a default kernel.

2023-12-23 05:27:54.973743: I tensorflow/core/common_runtime/memory_types.cc:75] out mvec 2 0 0
2023-12-23 05:27:54.973754: I tensorflow/core/common_runtime/memory_types.cc:71] inp mvec 3 0 0
2023-12-23 05:27:54.973759: I tensorflow/core/common_runtime/memory_types.cc:75] out mvec 3 0 0
2023-12-23 05:27:54.973766: I tensorflow/core/common_runtime/memory_types.cc:75] out mvec 4 0 0
2023-12-23 05:27:54.973774: I tensorflow/core/common_runtime/memory_types.cc:71] inp mvec 5 0 0
2023-12-23 05:27:54.973779: I tensorflow/core/common_runtime/memory_types.cc:75] out mvec 5 0 0
2023-12-23 05:27:54.973786: I tensorflow/core/framework/op_kernel.cc:1378] No device-specific kernels found for NodeDef '{{node _arg_X_0_0}}'Will fall back to a default kernel.

2023-12-23 05:27:54.973792: I tensorflow/core/common_runtime/memory_types.cc:75] out mvec 6 0 0
2023-12-23 05:27:54.973801: I tensorflow/core/common_runtime/memory_types.cc:71] inp mvec 7 0 0
2023-12-23 05:27:54.973806: I tensorflow/core/common_runtime/memory_types.cc:71] inp mvec 7 1 0
2023-12-23 05:27:54.973810: I tensorflow/core/common_runtime/memory_types.cc:75] out mvec 7 0 0
2023-12-23 05:27:54.973818: I tensorflow/core/common_runtime/memory_types.cc:71] inp mvec 8 0 0
2023-12-23 05:27:54.973823: I tensorflow/core/common_runtime/memory_types.cc:71] inp mvec 8 1 0
2023-12-23 05:27:54.973828: I tensorflow/core/common_runtime/memory_types.cc:75] out mvec 8 0 0
2023-12-23 05:27:54.973835: I tensorflow/core/common_runtime/memory_types.cc:71] inp mvec 9 0 0
2023-12-23 05:27:54.973840: I tensorflow/core/common_runtime/memory_types.cc:75] out mvec 9 0 0
2023-12-23 05:27:54.973847: I tensorflow/core/framework/op_kernel.cc:1378] No device-specific kernels found for NodeDef '{{node Sigmoid}}'Will fall back to a default kernel.

2023-12-23 05:27:54.973853: I tensorflow/core/common_runtime/memory_types.cc:71] inp mvec 10 0 0
2023-12-23 05:27:54.973859: I tensorflow/core/common_runtime/memory_types.cc:87] 2:0 -> 3:0: 0 -> 0
2023-12-23 05:27:54.973864: I tensorflow/core/common_runtime/memory_types.cc:87] 4:0 -> 5:0: 0 -> 0
2023-12-23 05:27:54.973869: I tensorflow/core/common_runtime/memory_types.cc:87] 6:0 -> 7:0: 0 -> 0
2023-12-23 05:27:54.973875: I tensorflow/core/common_runtime/memory_types.cc:87] 3:0 -> 7:1: 0 -> 0
2023-12-23 05:27:54.973880: I tensorflow/core/common_runtime/memory_types.cc:87] 7:0 -> 8:0: 0 -> 0
2023-12-23 05:27:54.973885: I tensorflow/core/common_runtime/memory_types.cc:87] 5:0 -> 8:1: 0 -> 0
2023-12-23 05:27:54.973890: I tensorflow/core/common_runtime/memory_types.cc:87] 8:0 -> 9:0: 0 -> 0
2023-12-23 05:27:54.973895: I tensorflow/core/common_runtime/memory_types.cc:87] 9:0 -> 10:0: 0 -> 0
2023-12-23 05:27:54.973924: W tensorflow/core/util/dump_graph.cc:134] Failed to dump EnsureMemoryTypes because dump location is not  specified through either TF_DUMP_GRAPH_PREFIX environment variable or function argument.
2023-12-23 05:27:54.973937: I tensorflow/core/common_runtime/memory_types.cc:210] Dumped graph after EnsureMemoryTypes to (failed to create writable file: Invalid argument: TF_DUMP_GRAPH_PREFIX not specified)
2023-12-23 05:27:54.973944: I tensorflow/core/framework/op_kernel.cc:1378] No device-specific kernels found for NodeDef '{{node _SOURCE}}'Will fall back to a default kernel.

2023-12-23 05:27:54.973951: I tensorflow/core/framework/op_kernel.cc:1378] No device-specific kernels found for NodeDef '{{node _SINK}}'Will fall back to a default kernel.

2023-12-23 05:27:54.973960: I tensorflow/core/common_runtime/memory_types.cc:75] out mvec 2 0 0
2023-12-23 05:27:54.973967: I tensorflow/core/common_runtime/memory_types.cc:71] inp mvec 3 0 0
2023-12-23 05:27:54.973972: I tensorflow/core/common_runtime/memory_types.cc:75] out mvec 3 0 0
2023-12-23 05:27:54.973979: I tensorflow/core/common_runtime/memory_types.cc:75] out mvec 4 0 0
2023-12-23 05:27:54.973986: I tensorflow/core/common_runtime/memory_types.cc:71] inp mvec 5 0 0
2023-12-23 05:27:54.973991: I tensorflow/core/common_runtime/memory_types.cc:75] out mvec 5 0 0
2023-12-23 05:27:54.973996: I tensorflow/core/framework/op_kernel.cc:1378] No device-specific kernels found for NodeDef '{{node _arg_X_0_0}}'Will fall back to a default kernel.

2023-12-23 05:27:54.974003: I tensorflow/core/common_runtime/memory_types.cc:75] out mvec 6 0 0
2023-12-23 05:27:54.974015: I tensorflow/core/common_runtime/memory_types.cc:71] inp mvec 7 0 0
2023-12-23 05:27:54.974020: I tensorflow/core/common_runtime/memory_types.cc:71] inp mvec 7 1 0
2023-12-23 05:27:54.974025: I tensorflow/core/common_runtime/memory_types.cc:75] out mvec 7 0 0
2023-12-23 05:27:54.974031: I tensorflow/core/common_runtime/memory_types.cc:71] inp mvec 8 0 0
2023-12-23 05:27:54.974039: I tensorflow/core/common_runtime/memory_types.cc:71] inp mvec 8 1 0
2023-12-23 05:27:54.974044: I tensorflow/core/common_runtime/memory_types.cc:75] out mvec 8 0 0
2023-12-23 05:27:54.974050: I tensorflow/core/common_runtime/memory_types.cc:71] inp mvec 9 0 0
2023-12-23 05:27:54.974055: I tensorflow/core/common_runtime/memory_types.cc:75] out mvec 9 0 0
2023-12-23 05:27:54.974061: I tensorflow/core/framework/op_kernel.cc:1378] No device-specific kernels found for NodeDef '{{node Sigmoid}}'Will fall back to a default kernel.

2023-12-23 05:27:54.974067: I tensorflow/core/common_runtime/memory_types.cc:71] inp mvec 10 0 0
2023-12-23 05:27:54.974072: I tensorflow/core/common_runtime/memory_types.cc:87] 2:0 -> 3:0: 0 -> 0
2023-12-23 05:27:54.974077: I tensorflow/core/common_runtime/memory_types.cc:87] 4:0 -> 5:0: 0 -> 0
2023-12-23 05:27:54.974082: I tensorflow/core/common_runtime/memory_types.cc:87] 6:0 -> 7:0: 0 -> 0
2023-12-23 05:27:54.974087: I tensorflow/core/common_runtime/memory_types.cc:87] 3:0 -> 7:1: 0 -> 0
2023-12-23 05:27:54.974092: I tensorflow/core/common_runtime/memory_types.cc:87] 7:0 -> 8:0: 0 -> 0
2023-12-23 05:27:54.974097: I tensorflow/core/common_runtime/memory_types.cc:87] 5:0 -> 8:1: 0 -> 0
2023-12-23 05:27:54.974102: I tensorflow/core/common_runtime/memory_types.cc:87] 8:0 -> 9:0: 0 -> 0
2023-12-23 05:27:54.974107: I tensorflow/core/common_runtime/memory_types.cc:87] 9:0 -> 10:0: 0 -> 0
2023-12-23 05:27:54.974162: I tensorflow/core/framework/op_kernel.cc:1626] Instantiating kernel for node: {{node _SOURCE}} = NoOp[]()
2023-12-23 05:27:54.974169: I tensorflow/core/framework/op_kernel.cc:1378] No device-specific kernels found for NodeDef '{{node _SOURCE}}'Will fall back to a default kernel.

2023-12-23 05:27:54.974175: I tensorflow/core/framework/op_kernel.cc:1378] No device-specific kernels found for NodeDef '{{node _SOURCE}}'Will fall back to a default kernel.

2023-12-23 05:27:54.974206: I tensorflow/core/framework/log_memory.cc:34] __LOG_MEMORY__ MemoryLogTensorAllocation { step_id: -6 kernel_name: "Unknown (from Proto)" tensor { dtype: DT_FLOAT shape { dim { size: 5 } dim { size: 7 } } allocation_description { requested_bytes: 140 allocated_bytes: 140 allocator_name: "cpu" allocation_id: 4 has_single_reference: true ptr: 1527096704 } } }
2023-12-23 05:27:54.974222: I tensorflow/core/framework/log_memory.cc:34] __LOG_MEMORY__ MemoryLogTensorDeallocation { allocation_id: 4 allocator_name: "cpu" }
2023-12-23 05:27:54.974229: I tensorflow/core/framework/op_kernel.cc:1626] Instantiating kernel for node: {{node Weight}} = Const[_XlaHasReferenceVars=false, dtype=DT_FLOAT, value=Tensor<type: float shape: [5,7] values: [0.0188236237 -0.0105859637 0.016250791...]...>, _device="/job:localhost/replica:0/task:0/device:GPU:0"]()
2023-12-23 05:27:54.974257: I tensorflow/stream_executor/executor_cache.cc:91] hit in cache for device ordinal 7
2023-12-23 05:27:54.974270: I tensorflow/core/common_runtime/bfc_allocator.cc:78] Creating bin of max chunk size 256B
2023-12-23 05:27:54.974275: I tensorflow/core/common_runtime/bfc_allocator.cc:78] Creating bin of max chunk size 512B
2023-12-23 05:27:54.974281: I tensorflow/core/common_runtime/bfc_allocator.cc:78] Creating bin of max chunk size 1.0KiB
2023-12-23 05:27:54.974286: I tensorflow/core/common_runtime/bfc_allocator.cc:78] Creating bin of max chunk size 2.0KiB
2023-12-23 05:27:54.974291: I tensorflow/core/common_runtime/bfc_allocator.cc:78] Creating bin of max chunk size 4.0KiB
2023-12-23 05:27:54.974296: I tensorflow/core/common_runtime/bfc_allocator.cc:78] Creating bin of max chunk size 8.0KiB
2023-12-23 05:27:54.974302: I tensorflow/core/common_runtime/bfc_allocator.cc:78] Creating bin of max chunk size 16.0KiB
2023-12-23 05:27:54.974307: I tensorflow/core/common_runtime/bfc_allocator.cc:78] Creating bin of max chunk size 32.0KiB
2023-12-23 05:27:54.974312: I tensorflow/core/common_runtime/bfc_allocator.cc:78] Creating bin of max chunk size 64.0KiB
2023-12-23 05:27:54.974318: I tensorflow/core/common_runtime/bfc_allocator.cc:78] Creating bin of max chunk size 128.0KiB
2023-12-23 05:27:54.974323: I tensorflow/core/common_runtime/bfc_allocator.cc:78] Creating bin of max chunk size 256.0KiB
2023-12-23 05:27:54.974328: I tensorflow/core/common_runtime/bfc_allocator.cc:78] Creating bin of max chunk size 512.0KiB
2023-12-23 05:27:54.974333: I tensorflow/core/common_runtime/bfc_allocator.cc:78] Creating bin of max chunk size 1.00MiB
2023-12-23 05:27:54.974338: I tensorflow/core/common_runtime/bfc_allocator.cc:78] Creating bin of max chunk size 2.00MiB
2023-12-23 05:27:54.974343: I tensorflow/core/common_runtime/bfc_allocator.cc:78] Creating bin of max chunk size 4.00MiB
2023-12-23 05:27:54.974348: I tensorflow/core/common_runtime/bfc_allocator.cc:78] Creating bin of max chunk size 8.00MiB
2023-12-23 05:27:54.974353: I tensorflow/core/common_runtime/bfc_allocator.cc:78] Creating bin of max chunk size 16.00MiB
2023-12-23 05:27:54.974358: I tensorflow/core/common_runtime/bfc_allocator.cc:78] Creating bin of max chunk size 32.00MiB
2023-12-23 05:27:54.974363: I tensorflow/core/common_runtime/bfc_allocator.cc:78] Creating bin of max chunk size 64.00MiB
2023-12-23 05:27:54.974368: I tensorflow/core/common_runtime/bfc_allocator.cc:78] Creating bin of max chunk size 128.00MiB
2023-12-23 05:27:54.974374: I tensorflow/core/common_runtime/bfc_allocator.cc:78] Creating bin of max chunk size 256.00MiB
2023-12-23 05:27:54.974379: I tensorflow/core/common_runtime/gpu/gpu_process_state.cc:361] try warmup with TF_GPU_HOST_WARMUP_BYTES=0
2023-12-23 05:27:54.974385: I tensorflow/core/common_runtime/bfc_allocator.cc:276] AllocateRaw gpu_host_bfc  140
2023-12-23 05:27:54.974393: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 8
2023-12-23 05:27:54.977565: I tensorflow/stream_executor/stream_executor_pimpl.cc:569] Called StreamExecutor::HostMemoryAllocate(size=2097152) returns 0x7f8253000000
2023-12-23 05:27:54.977592: I tensorflow/core/common_runtime/bfc_allocator.cc:174] Extending allocation by 2.00MiB bytes.
2023-12-23 05:27:54.977599: I tensorflow/core/common_runtime/bfc_allocator.cc:178] Total allocated bytes: 2.00MiB
2023-12-23 05:27:54.977605: I tensorflow/core/common_runtime/bfc_allocator.cc:181] Allocated memory at 0x7f8253000000 to 0x7f8253200000
2023-12-23 05:27:54.977657: I tensorflow/core/framework/log_memory.cc:34] __LOG_MEMORY__ MemoryLogTensorAllocation { step_id: -6 kernel_name: "Unknown (from Proto)" tensor { dtype: DT_FLOAT shape { dim { size: 5 } dim { size: 7 } } allocation_description { requested_bytes: 140 allocated_bytes: 256 allocator_name: "gpu_host_bfc" allocation_id: 1 has_single_reference: true ptr: 140197714984960 } } }
2023-12-23 05:27:54.977666: I tensorflow/core/common_runtime/bfc_allocator.cc:276] AllocateRaw GPU_0_bfc  140
2023-12-23 05:27:54.977674: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 1
2023-12-23 05:27:54.979074: I tensorflow/stream_executor/cuda/cuda_driver.cc:885] allocated 0x7f8253200000 for context 0x1eafff0 of 2097152 bytes
2023-12-23 05:27:54.979092: I tensorflow/stream_executor/stream_executor_pimpl.cc:515] Called StreamExecutor::Allocate(size=2097152, memory_space=0) returns 0x7f8253200000
2023-12-23 05:27:54.979100: I tensorflow/core/common_runtime/bfc_allocator.cc:174] Extending allocation by 2.00MiB bytes.
2023-12-23 05:27:54.979106: I tensorflow/core/common_runtime/bfc_allocator.cc:178] Total allocated bytes: 2.00MiB
2023-12-23 05:27:54.979111: I tensorflow/core/common_runtime/bfc_allocator.cc:181] Allocated memory at 0x7f8253200000 to 0x7f8253400000
2023-12-23 05:27:54.979147: I tensorflow/core/framework/log_memory.cc:34] __LOG_MEMORY__ MemoryLogTensorAllocation { step_id: -6 kernel_name: "Unknown (with attributes)" tensor { dtype: DT_FLOAT shape { dim { size: 5 } dim { size: 7 } } allocation_description { requested_bytes: 140 allocated_bytes: 256 allocator_name: "GPU_0_bfc" allocation_id: 1 has_single_reference: true ptr: 140197717082112 } } }
2023-12-23 05:27:54.979159: I tensorflow/core/common_runtime/gpu/gpu_util.cc:303] CopyCPUTensorToGPU
2023-12-23 05:27:54.979169: I tensorflow/stream_executor/stream.cc:1397] [stream=0x5a6e0670,impl=0x5a6dcd30] Called Stream::ThenWaitFor(other=0x5a9132e0)
2023-12-23 05:27:54.979176: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 1
2023-12-23 05:27:54.979192: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 1
2023-12-23 05:27:54.979212: I tensorflow/stream_executor/stream.cc:4509] [stream=0x5a6e0670,impl=0x5a6dcd30] Called Stream::ThenMemcpy(gpu_dst=0x7f8253200000, host_src=0x7f8253000000, size=140)
2023-12-23 05:27:54.979219: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 1
2023-12-23 05:27:54.979248: I tensorflow/stream_executor/cuda/cuda_driver.cc:1298] successfully enqueued async memcpy h2d of 140 bytes on stream 0x3fea7d80
2023-12-23 05:27:54.979255: I tensorflow/core/common_runtime/device/device_event_mgr.cc:170] QueueInUse  free_events_ 0 used_events_ 0
2023-12-23 05:27:54.979262: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 1
2023-12-23 05:27:54.979270: I tensorflow/stream_executor/stream.cc:330] [stream=0x5a6e0670,impl=0x5a6dcd30] Called Stream::ThenRecordEvent(event=0x1d06f60)
2023-12-23 05:27:54.979276: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 1
2023-12-23 05:27:54.979283: I tensorflow/core/common_runtime/device/device_event_mgr.cc:208] PollEvents  free_events_ 0 used_events_ 1
2023-12-23 05:27:54.979289: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 1
2023-12-23 05:27:54.979325: I tensorflow/core/common_runtime/device/device_event_mgr.cc:208] PollEvents  free_events_ 1 used_events_ 0
2023-12-23 05:27:54.979366: I tensorflow/core/framework/log_memory.cc:34] __LOG_MEMORY__ MemoryLogTensorDeallocation { allocation_id: 1 allocator_name: "gpu_host_bfc" }
2023-12-23 05:27:54.979374: I tensorflow/core/common_runtime/bfc_allocator.cc:660] DeallocateRaw gpu_host_bfc 140
2023-12-23 05:27:54.979399: I tensorflow/core/framework/op_kernel.cc:1626] Instantiating kernel for node: {{node Weight/read}} = Identity[T=DT_FLOAT, _XlaHasReferenceVars=false, _class=["loc:@Weight"], _device="/job:localhost/replica:0/task:0/device:GPU:0"](Weight)
2023-12-23 05:27:54.979441: I tensorflow/core/framework/log_memory.cc:34] __LOG_MEMORY__ MemoryLogTensorAllocation { step_id: -6 kernel_name: "Unknown (from Proto)" tensor { dtype: DT_FLOAT shape { dim { size: 7 } } allocation_description { requested_bytes: 28 allocated_bytes: 28 allocator_name: "cpu" allocation_id: 5 has_single_reference: true ptr: 1527288000 } } }
2023-12-23 05:27:54.979458: I tensorflow/core/framework/log_memory.cc:34] __LOG_MEMORY__ MemoryLogTensorDeallocation { allocation_id: 5 allocator_name: "cpu" }
2023-12-23 05:27:54.979465: I tensorflow/core/framework/op_kernel.cc:1626] Instantiating kernel for node: {{node Bias}} = Const[_XlaHasReferenceVars=false, dtype=DT_FLOAT, value=Tensor<type: float shape: [7] values: 0 0 0...>, _device="/job:localhost/replica:0/task:0/device:GPU:0"]()
2023-12-23 05:27:54.979488: I tensorflow/core/common_runtime/bfc_allocator.cc:276] AllocateRaw gpu_host_bfc  28
2023-12-23 05:27:54.979503: I tensorflow/core/framework/log_memory.cc:34] __LOG_MEMORY__ MemoryLogTensorAllocation { step_id: -6 kernel_name: "Unknown (from Proto)" tensor { dtype: DT_FLOAT shape { dim { size: 7 } } allocation_description { requested_bytes: 28 allocated_bytes: 256 allocator_name: "gpu_host_bfc" allocation_id: 2 has_single_reference: true ptr: 140197714984960 } } }
2023-12-23 05:27:54.979511: I tensorflow/core/common_runtime/bfc_allocator.cc:276] AllocateRaw GPU_0_bfc  28
2023-12-23 05:27:54.979523: I tensorflow/core/framework/log_memory.cc:34] __LOG_MEMORY__ MemoryLogTensorAllocation { step_id: -6 kernel_name: "Unknown (with attributes)" tensor { dtype: DT_FLOAT shape { dim { size: 7 } } allocation_description { requested_bytes: 28 allocated_bytes: 256 allocator_name: "GPU_0_bfc" allocation_id: 2 has_single_reference: true ptr: 140197717082368 } } }
2023-12-23 05:27:54.979530: I tensorflow/core/common_runtime/gpu/gpu_util.cc:303] CopyCPUTensorToGPU
2023-12-23 05:27:54.979537: I tensorflow/stream_executor/stream.cc:1397] [stream=0x5a6e0670,impl=0x5a6dcd30] Called Stream::ThenWaitFor(other=0x5a9132e0)
2023-12-23 05:27:54.979543: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 1
2023-12-23 05:27:54.979550: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 1
2023-12-23 05:27:54.979560: I tensorflow/stream_executor/stream.cc:4509] [stream=0x5a6e0670,impl=0x5a6dcd30] Called Stream::ThenMemcpy(gpu_dst=0x7f8253200100, host_src=0x7f8253000000, size=28)
2023-12-23 05:27:54.979565: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 1
2023-12-23 05:27:54.979583: I tensorflow/stream_executor/cuda/cuda_driver.cc:1298] successfully enqueued async memcpy h2d of 28 bytes on stream 0x3fea7d80
2023-12-23 05:27:54.979589: I tensorflow/core/common_runtime/device/device_event_mgr.cc:170] QueueInUse  free_events_ 1 used_events_ 0
2023-12-23 05:27:54.979595: I tensorflow/stream_executor/stream.cc:330] [stream=0x5a6e0670,impl=0x5a6dcd30] Called Stream::ThenRecordEvent(event=0x1d06f60)
2023-12-23 05:27:54.979600: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 1
2023-12-23 05:27:54.979607: I tensorflow/core/common_runtime/device/device_event_mgr.cc:208] PollEvents  free_events_ 0 used_events_ 1
2023-12-23 05:27:54.979612: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 1
2023-12-23 05:27:54.979626: I tensorflow/core/common_runtime/device/device_event_mgr.cc:208] PollEvents  free_events_ 1 used_events_ 0
2023-12-23 05:27:54.979642: I tensorflow/core/framework/log_memory.cc:34] __LOG_MEMORY__ MemoryLogTensorDeallocation { allocation_id: 2 allocator_name: "gpu_host_bfc" }
2023-12-23 05:27:54.979650: I tensorflow/core/common_runtime/bfc_allocator.cc:660] DeallocateRaw gpu_host_bfc 28
2023-12-23 05:27:54.979663: I tensorflow/core/framework/op_kernel.cc:1626] Instantiating kernel for node: {{node Bias/read}} = Identity[T=DT_FLOAT, _XlaHasReferenceVars=false, _class=["loc:@Bias"], _device="/job:localhost/replica:0/task:0/device:GPU:0"](Bias)
2023-12-23 05:27:54.979684: I tensorflow/core/framework/op_kernel.cc:1626] Instantiating kernel for node: {{node _arg_X_0_0/_1}} = _Recv[_dst="MatMul", _src="_arg_X_0_0", client_terminated=false, recv_device="/job:localhost/replica:0/task:0/device:GPU:0", send_device="/job:localhost/replica:0/task:0/device:CPU:0", send_device_incarnation=1, tensor_name="edge_13__arg_X_0_0", tensor_type=DT_FLOAT, _device="/job:localhost/replica:0/task:0/device:GPU:0"]()
2023-12-23 05:27:54.979698: I tensorflow/core/framework/op_kernel.cc:1378] No device-specific kernels found for NodeDef '{{node _arg_X_0_0}}'Will fall back to a default kernel.

2023-12-23 05:27:54.979704: I tensorflow/core/framework/op_kernel.cc:1378] No device-specific kernels found for NodeDef '{{node _arg_X_0_0}}'Will fall back to a default kernel.

2023-12-23 05:27:54.979725: I tensorflow/core/framework/op_kernel.cc:1626] Instantiating kernel for node: {{node MatMul}} = MatMul[T=DT_FLOAT, _XlaHasReferenceVars=false, transpose_a=false, transpose_b=false, _device="/job:localhost/replica:0/task:0/device:GPU:0"](_arg_X_0_0/_1, Weight/read)
2023-12-23 05:27:54.979742: I tensorflow/core/framework/op_kernel.cc:1626] Instantiating kernel for node: {{node Add}} = Add[T=DT_FLOAT, _XlaHasReferenceVars=false, _device="/job:localhost/replica:0/task:0/device:GPU:0"](MatMul, Bias/read)
2023-12-23 05:27:54.979758: I tensorflow/core/framework/op_kernel.cc:1626] Instantiating kernel for node: {{node Sigmoid}} = Sigmoid[T=DT_FLOAT, _XlaHasReferenceVars=false, _device="/job:localhost/replica:0/task:0/device:GPU:0"](Add)
2023-12-23 05:27:54.979774: I tensorflow/core/framework/op_kernel.cc:1626] Instantiating kernel for node: {{node Sigmoid/_2}} = _Send[T=DT_FLOAT, _dst="_retval_Sigmoid_0_0", _src="Sigmoid", client_terminated=false, recv_device="/job:localhost/replica:0/task:0/device:CPU:0", send_device="/job:localhost/replica:0/task:0/device:GPU:0", send_device_incarnation=1, tensor_name="edge_14_Sigmoid", _device="/job:localhost/replica:0/task:0/device:GPU:0"](Sigmoid)
2023-12-23 05:27:54.979785: I tensorflow/core/framework/op_kernel.cc:1378] No device-specific kernels found for NodeDef '{{node Sigmoid}}'Will fall back to a default kernel.

2023-12-23 05:27:54.979791: I tensorflow/core/framework/op_kernel.cc:1378] No device-specific kernels found for NodeDef '{{node Sigmoid}}'Will fall back to a default kernel.

2023-12-23 05:27:54.979808: I tensorflow/core/common_runtime/graph_view.cc:364] default alloc case local type GPU remote type CPU
2023-12-23 05:27:54.979815: I tensorflow/core/common_runtime/graph_view.cc:391] default alloc case local type GPU remote type CPU
2023-12-23 05:27:54.979831: I tensorflow/core/common_runtime/function_utils.cc:78] Graph Initial #nodes 6 #edges 7
2023-12-23 05:27:54.979837: I tensorflow/core/common_runtime/function_utils.cc:164] Removing list array converter
2023-12-23 05:27:54.979859: I tensorflow/core/common_runtime/function_utils.cc:78] Graph ReCopy #nodes 6 #edges 8
2023-12-23 05:27:54.979886: W tensorflow/core/util/dump_graph.cc:134] Failed to dump EnsureMemoryTypes because dump location is not  specified through either TF_DUMP_GRAPH_PREFIX environment variable or function argument.
2023-12-23 05:27:54.979898: I tensorflow/core/common_runtime/memory_types.cc:210] Dumped graph after EnsureMemoryTypes to (failed to create writable file: Invalid argument: TF_DUMP_GRAPH_PREFIX not specified)
2023-12-23 05:27:54.979933: I tensorflow/core/framework/op_kernel.cc:1626] Instantiating kernel for node: {{node _SOURCE}} = NoOp[]()
2023-12-23 05:27:54.979941: I tensorflow/core/framework/op_kernel.cc:1378] No device-specific kernels found for NodeDef '{{node _SOURCE}}'Will fall back to a default kernel.

2023-12-23 05:27:54.979947: I tensorflow/core/framework/op_kernel.cc:1378] No device-specific kernels found for NodeDef '{{node _SOURCE}}'Will fall back to a default kernel.

2023-12-23 05:27:54.979958: I tensorflow/core/framework/op_kernel.cc:1626] Instantiating kernel for node: {{node _arg_X_0_0}} = _Arg[T=DT_FLOAT, _XlaHasReferenceVars=false, index=0, _device="/job:localhost/replica:0/task:0/device:CPU:0"]()
2023-12-23 05:27:54.979974: I tensorflow/core/framework/op_kernel.cc:1626] Instantiating kernel for node: {{node _arg_X_0_0/_0}} = _Send[T=DT_FLOAT, _dst="MatMul", _src="_arg_X_0_0", client_terminated=false, recv_device="/job:localhost/replica:0/task:0/device:GPU:0", send_device="/job:localhost/replica:0/task:0/device:CPU:0", send_device_incarnation=1, tensor_name="edge_13__arg_X_0_0", _device="/job:localhost/replica:0/task:0/device:CPU:0"](_arg_X_0_0)
2023-12-23 05:27:54.979997: I tensorflow/core/framework/op_kernel.cc:1626] Instantiating kernel for node: {{node Sigmoid/_3}} = _Recv[_dst="_retval_Sigmoid_0_0", _src="Sigmoid", client_terminated=false, recv_device="/job:localhost/replica:0/task:0/device:CPU:0", send_device="/job:localhost/replica:0/task:0/device:GPU:0", send_device_incarnation=1, tensor_name="edge_14_Sigmoid", tensor_type=DT_FLOAT, _device="/job:localhost/replica:0/task:0/device:CPU:0"]()
2023-12-23 05:27:54.980021: I tensorflow/core/framework/op_kernel.cc:1626] Instantiating kernel for node: {{node _retval_Sigmoid_0_0}} = _Retval[T=DT_FLOAT, _XlaHasReferenceVars=false, index=0, _device="/job:localhost/replica:0/task:0/device:CPU:0"](Sigmoid/_3)
2023-12-23 05:27:54.980034: I tensorflow/core/common_runtime/graph_view.cc:389] node _arg_X_0_0 is the source of a cpu->gpu copy
2023-12-23 05:27:54.980041: I tensorflow/core/common_runtime/graph_view.cc:362] node Sigmoid/_3 is the sink of a gpu->cpu copy
2023-12-23 05:27:54.980068: I tensorflow/core/framework/log_memory.cc:34] __LOG_MEMORY__ MemoryLogStep { step_id: 1 handle: "X:0->Sigmoid:0//0/;0" }
2023-12-23 05:27:54.980104: I tensorflow/core/common_runtime/executor.cc:764] Process node: 0 step 1 {{node _SOURCE}} = NoOp[]() device: /job:localhost/replica:0/task:0/device:GPU:0
2023-12-23 05:27:54.980122: I tensorflow/core/common_runtime/executor.cc:764] Process node: 0 step 1 {{node _SOURCE}} = NoOp[]() device: /job:localhost/replica:0/task:0/device:CPU:0
2023-12-23 05:27:54.980148: I tensorflow/core/common_runtime/executor.cc:817] Synchronous kernel done: 0 step 1 {{node _SOURCE}} = NoOp[]() device: /job:localhost/replica:0/task:0/device:GPU:0
2023-12-23 05:27:54.980158: I tensorflow/core/common_runtime/executor.cc:817] Synchronous kernel done: 0 step 1 {{node _SOURCE}} = NoOp[]() device: /job:localhost/replica:0/task:0/device:CPU:0
2023-12-23 05:27:54.980168: I tensorflow/core/common_runtime/executor.cc:764] Process node: 2 step 1 {{node Weight}} = Const[dtype=DT_FLOAT, _device="/job:localhost/replica:0/task:0/device:GPU:0"]() device: /job:localhost/replica:0/task:0/device:GPU:0
2023-12-23 05:27:54.980177: I tensorflow/core/common_runtime/executor.cc:817] Synchronous kernel done: 2 step 1 {{node Weight}} = Const[dtype=DT_FLOAT, _device="/job:localhost/replica:0/task:0/device:GPU:0"]() device: /job:localhost/replica:0/task:0/device:GPU:0
2023-12-23 05:27:54.980185: I tensorflow/core/common_runtime/executor.cc:764] Process node: 2 step 1 {{node _arg_X_0_0}} = _Arg[T=DT_FLOAT, _XlaHasReferenceVars=false, index=0, _device="/job:localhost/replica:0/task:0/device:CPU:0"]() device: /job:localhost/replica:0/task:0/device:CPU:0
2023-12-23 05:27:54.980193: I tensorflow/core/common_runtime/executor.cc:764] Process node: 4 step 1 {{node Sigmoid/_3}} = _Recv[_dst="_retval_Sigmoid_0_0", _src="Sigmoid", client_terminated=false, recv_device="/job:localhost/replica:0/task:0/device:CPU:0", send_device="/job:localhost/replica:0/task:0/device:GPU:0", send_device_incarnation=1, tensor_name="edge_14_Sigmoid", tensor_type=DT_FLOAT, _device="/job:localhost/replica:0/task:0/device:CPU:0"]() device: /job:localhost/replica:0/task:0/device:CPU:0
2023-12-23 05:27:54.980206: I tensorflow/core/common_runtime/executor.cc:764] Process node: 4 step 1 {{node Bias}} = Const[dtype=DT_FLOAT, _device="/job:localhost/replica:0/task:0/device:GPU:0"]() device: /job:localhost/replica:0/task:0/device:GPU:0
2023-12-23 05:27:54.980212: I tensorflow/core/kernels/sendrecv_ops.cc:203] Recv /job:localhost/replica:0/task:0/device:GPU:0;0000000000000001;/job:localhost/replica:0/task:0/device:CPU:0;edge_14_Sigmoid;0:0 using 1527301904
2023-12-23 05:27:54.980223: I tensorflow/core/common_runtime/executor.cc:817] Synchronous kernel done: 4 step 1 {{node Bias}} = Const[dtype=DT_FLOAT, _device="/job:localhost/replica:0/task:0/device:GPU:0"]() device: /job:localhost/replica:0/task:0/device:GPU:0
2023-12-23 05:27:54.980231: I tensorflow/core/framework/log_memory.cc:34] __LOG_MEMORY__ MemoryLogTensorOutput { step_id: 1 kernel_name: "_arg_X_0_0" tensor { dtype: DT_FLOAT shape { dim { size: 3 } dim { size: 5 } } allocation_description { requested_bytes: 60 allocated_bytes: 60 allocator_name: "cpu" allocation_id: 1 ptr: 30465344 } } }
2023-12-23 05:27:54.980246: I tensorflow/core/common_runtime/rendezvous_mgr.cc:172] IntraProcessRendezvous Recv 0x5b08c710 /job:localhost/replica:0/task:0/device:GPU:0;0000000000000001;/job:localhost/replica:0/task:0/device:CPU:0;edge_14_Sigmoid;0:0
2023-12-23 05:27:54.980256: I tensorflow/core/common_runtime/rendezvous_mgr.cc:123] IntraProcessRendezvous Recv 0x5b08c730 /job:localhost/replica:0/task:0/device:GPU:0;0000000000000001;/job:localhost/replica:0/task:0/device:CPU:0;edge_14_Sigmoid;0:0
2023-12-23 05:27:54.980265: I tensorflow/core/common_runtime/executor.cc:764] Process node: 6 step 1 {{node _arg_X_0_0/_1}} = _Recv[_dst="MatMul", _src="_arg_X_0_0", client_terminated=false, recv_device="/job:localhost/replica:0/task:0/device:GPU:0", send_device="/job:localhost/replica:0/task:0/device:CPU:0", send_device_incarnation=1, tensor_name="edge_13__arg_X_0_0", tensor_type=DT_FLOAT, _device="/job:localhost/replica:0/task:0/device:GPU:0"]() device: /job:localhost/replica:0/task:0/device:GPU:0
2023-12-23 05:27:54.980276: I tensorflow/core/common_runtime/executor.cc:817] Synchronous kernel done: 2 step 1 {{node _arg_X_0_0}} = _Arg[T=DT_FLOAT, _XlaHasReferenceVars=false, index=0, _device="/job:localhost/replica:0/task:0/device:CPU:0"]() device: /job:localhost/replica:0/task:0/device:CPU:0
2023-12-23 05:27:54.980290: I tensorflow/core/common_runtime/executor.cc:764] Process node: 3 step 1 {{node _arg_X_0_0/_0}} = _Send[T=DT_FLOAT, _dst="MatMul", _src="_arg_X_0_0", client_terminated=false, recv_device="/job:localhost/replica:0/task:0/device:GPU:0", send_device="/job:localhost/replica:0/task:0/device:CPU:0", send_device_incarnation=1, tensor_name="edge_13__arg_X_0_0", _device="/job:localhost/replica:0/task:0/device:CPU:0"](_arg_X_0_0) device: /job:localhost/replica:0/task:0/device:CPU:0
2023-12-23 05:27:54.980301: I tensorflow/core/kernels/sendrecv_ops.cc:96] Send /job:localhost/replica:0/task:0/device:CPU:0;0000000000000001;/job:localhost/replica:0/task:0/device:GPU:0;edge_13__arg_X_0_0;0:0 using 1527301904
2023-12-23 05:27:54.980308: I tensorflow/core/common_runtime/rendezvous_mgr.cc:165] IntraProcessRendezvous Send 0x5b08c710 /job:localhost/replica:0/task:0/device:CPU:0;0000000000000001;/job:localhost/replica:0/task:0/device:GPU:0;edge_13__arg_X_0_0;0:0
2023-12-23 05:27:54.980318: I tensorflow/core/common_runtime/executor.cc:817] Synchronous kernel done: 3 step 1 {{node _arg_X_0_0/_0}} = _Send[T=DT_FLOAT, _dst="MatMul", _src="_arg_X_0_0", client_terminated=false, recv_device="/job:localhost/replica:0/task:0/device:GPU:0", send_device="/job:localhost/replica:0/task:0/device:CPU:0", send_device_incarnation=1, tensor_name="edge_13__arg_X_0_0", _device="/job:localhost/replica:0/task:0/device:CPU:0"](_arg_X_0_0) device: /job:localhost/replica:0/task:0/device:CPU:0
2023-12-23 05:27:54.985233: I tensorflow/core/common_runtime/bfc_allocator.cc:276] AllocateRaw GPU_0_bfc  1028
2023-12-23 05:27:54.985250: I tensorflow/stream_executor/stream_executor_pimpl.cc:611] Called StreamExecutor::SynchronousMemZero(location=0x7f82017f2de0, size=1028)
2023-12-23 05:27:54.985257: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 1
2023-12-23 05:27:54.985284: I tensorflow/core/common_runtime/gpu/gpu_device.cc:645] GpuDevice::ComputeAsync _arg_X_0_0/_1 op _Recv on GPU0 stream[0]
2023-12-23 05:27:54.985291: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 1
2023-12-23 05:27:54.985297: I tensorflow/core/kernels/sendrecv_ops.cc:203] Recv /job:localhost/replica:0/task:0/device:CPU:0;0000000000000001;/job:localhost/replica:0/task:0/device:GPU:0;edge_13__arg_X_0_0;0:0 using 1527301904
2023-12-23 05:27:54.985303: I tensorflow/core/common_runtime/rendezvous_mgr.cc:172] IntraProcessRendezvous Recv 0x5b08c710 /job:localhost/replica:0/task:0/device:CPU:0;0000000000000001;/job:localhost/replica:0/task:0/device:GPU:0;edge_13__arg_X_0_0;0:0
2023-12-23 05:27:54.985309: I tensorflow/core/common_runtime/rendezvous_mgr.cc:123] IntraProcessRendezvous Recv 0x5b08c730 /job:localhost/replica:0/task:0/device:CPU:0;0000000000000001;/job:localhost/replica:0/task:0/device:GPU:0;edge_13__arg_X_0_0;0:0
2023-12-23 05:27:54.985318: I tensorflow/core/common_runtime/bfc_allocator.cc:276] AllocateRaw GPU_0_bfc  60
2023-12-23 05:27:54.985353: I tensorflow/core/framework/log_memory.cc:34] __LOG_MEMORY__ MemoryLogTensorAllocation { step_id: -6 kernel_name: "Unknown (with attributes)" tensor { dtype: DT_FLOAT shape { dim { size: 3 } dim { size: 5 } } allocation_description { requested_bytes: 60 allocated_bytes: 256 allocator_name: "GPU_0_bfc" allocation_id: 4 has_single_reference: true ptr: 140197717083904 } } }
2023-12-23 05:27:54.985362: I tensorflow/core/common_runtime/copy_tensor.cc:211] Copy edge_13__arg_X_0_0
2023-12-23 05:27:54.985368: I tensorflow/core/common_runtime/gpu/gpu_util.cc:303] CopyCPUTensorToGPU
2023-12-23 05:27:54.985377: I tensorflow/stream_executor/stream.cc:1397] [stream=0x5a6e0670,impl=0x5a6dcd30] Called Stream::ThenWaitFor(other=0x5a9132e0)
2023-12-23 05:27:54.985391: I tensorflow/stream_executor/stream.cc:4509] [stream=0x5a6e0670,impl=0x5a6dcd30] Called Stream::ThenMemcpy(gpu_dst=0x7f8253200700, host_src=0x1d0dd40, size=60)
2023-12-23 05:27:54.985419: I tensorflow/stream_executor/cuda/cuda_driver.cc:1298] successfully enqueued async memcpy h2d of 60 bytes on stream 0x3fea7d80
2023-12-23 05:27:54.985426: I tensorflow/core/common_runtime/device/device_event_mgr.cc:170] QueueInUse  free_events_ 1 used_events_ 0
2023-12-23 05:27:54.985433: I tensorflow/stream_executor/stream.cc:330] [stream=0x5a6e0670,impl=0x5a6dcd30] Called Stream::ThenRecordEvent(event=0x1d06f60)
2023-12-23 05:27:54.985440: I tensorflow/core/common_runtime/device/device_event_mgr.cc:208] PollEvents  free_events_ 0 used_events_ 1
2023-12-23 05:27:54.985461: I tensorflow/core/common_runtime/device/device_event_mgr.cc:208] PollEvents  free_events_ 1 used_events_ 0
2023-12-23 05:27:54.985477: I tensorflow/core/common_runtime/executor.cc:764] Process node: 3 step 1 {{node Weight/read}} = Identity[T=DT_FLOAT, _XlaHasReferenceVars=false, _class=["loc:@Weight"], _device="/job:localhost/replica:0/task:0/device:GPU:0"](Weight) device: /job:localhost/replica:0/task:0/device:GPU:0
2023-12-23 05:27:54.985489: I tensorflow/core/common_runtime/gpu/gpu_device.cc:575] GpuDevice::ComputeHelper Weight/read op Identity on GPU 0 stream[0]
2023-12-23 05:27:54.985495: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 1
2023-12-23 05:27:54.985500: I tensorflow/core/framework/log_memory.cc:34] __LOG_MEMORY__ MemoryLogTensorOutput { step_id: 1 kernel_name: "_arg_X_0_0/_1" tensor { dtype: DT_FLOAT shape { dim { size: 3 } dim { size: 5 } } allocation_description { requested_bytes: 60 allocated_bytes: 256 allocator_name: "GPU_0_bfc" allocation_id: 4 ptr: 140197717083904 } } }
2023-12-23 05:27:54.985525: I tensorflow/core/common_runtime/gpu/gpu_device.cc:601] GpuDevice::ComputeHelper scheduled Weight/read op Identity on GPU 0 stream[0]
2023-12-23 05:27:54.985536: I tensorflow/core/common_runtime/executor.cc:611] Async kernel done: 6 step 1 {{node _arg_X_0_0/_1}} = _Recv[_dst="MatMul", _src="_arg_X_0_0", client_terminated=false, recv_device="/job:localhost/replica:0/task:0/device:GPU:0", send_device="/job:localhost/replica:0/task:0/device:CPU:0", send_device_incarnation=1, tensor_name="edge_13__arg_X_0_0", tensor_type=DT_FLOAT, _device="/job:localhost/replica:0/task:0/device:GPU:0"]() device: /job:localhost/replica:0/task:0/device:GPU:0
2023-12-23 05:27:54.985544: I tensorflow/core/framework/log_memory.cc:34] __LOG_MEMORY__ MemoryLogTensorOutput { step_id: 1 kernel_name: "Weight/read" tensor { dtype: DT_FLOAT shape { dim { size: 5 } dim { size: 7 } } allocation_description { requested_bytes: 140 allocated_bytes: 256 allocator_name: "GPU_0_bfc" allocation_id: 1 ptr: 140197717082112 } } }
2023-12-23 05:27:54.985555: I tensorflow/core/common_runtime/executor.cc:817] Synchronous kernel done: 3 step 1 {{node Weight/read}} = Identity[T=DT_FLOAT, _XlaHasReferenceVars=false, _class=["loc:@Weight"], _device="/job:localhost/replica:0/task:0/device:GPU:0"](Weight) device: /job:localhost/replica:0/task:0/device:GPU:0
2023-12-23 05:27:54.985564: I tensorflow/core/common_runtime/executor.cc:764] Process node: 5 step 1 {{node Bias/read}} = Identity[T=DT_FLOAT, _XlaHasReferenceVars=false, _class=["loc:@Bias"], _device="/job:localhost/replica:0/task:0/device:GPU:0"](Bias) device: /job:localhost/replica:0/task:0/device:GPU:0
2023-12-23 05:27:54.985573: I tensorflow/core/common_runtime/gpu/gpu_device.cc:575] GpuDevice::ComputeHelper Bias/read op Identity on GPU 0 stream[0]
2023-12-23 05:27:54.985578: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 1
2023-12-23 05:27:54.985583: I tensorflow/core/common_runtime/gpu/gpu_device.cc:601] GpuDevice::ComputeHelper scheduled Bias/read op Identity on GPU 0 stream[0]
2023-12-23 05:27:54.985595: I tensorflow/core/framework/log_memory.cc:34] __LOG_MEMORY__ MemoryLogTensorOutput { step_id: 1 kernel_name: "Bias/read" tensor { dtype: DT_FLOAT shape { dim { size: 7 } } allocation_description { requested_bytes: 28 allocated_bytes: 256 allocator_name: "GPU_0_bfc" allocation_id: 2 ptr: 140197717082368 } } }
2023-12-23 05:27:54.985604: I tensorflow/core/common_runtime/executor.cc:817] Synchronous kernel done: 5 step 1 {{node Bias/read}} = Identity[T=DT_FLOAT, _XlaHasReferenceVars=false, _class=["loc:@Bias"], _device="/job:localhost/replica:0/task:0/device:GPU:0"](Bias) device: /job:localhost/replica:0/task:0/device:GPU:0
2023-12-23 05:27:54.985612: I tensorflow/core/common_runtime/executor.cc:764] Process node: 7 step 1 {{node MatMul}} = MatMul[T=DT_FLOAT, _XlaHasReferenceVars=false, transpose_a=false, transpose_b=false, _device="/job:localhost/replica:0/task:0/device:GPU:0"](_arg_X_0_0/_1, Weight/read) device: /job:localhost/replica:0/task:0/device:GPU:0
2023-12-23 05:27:54.985618: I tensorflow/core/common_runtime/gpu/gpu_device.cc:575] GpuDevice::ComputeHelper MatMul op MatMul on GPU 0 stream[0]
2023-12-23 05:27:54.985623: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 1
2023-12-23 05:27:54.985633: I tensorflow/core/common_runtime/bfc_allocator.cc:276] AllocateRaw GPU_0_bfc  84
2023-12-23 05:27:54.985647: I tensorflow/core/framework/log_memory.cc:34] __LOG_MEMORY__ MemoryLogTensorAllocation { step_id: 1 kernel_name: "MatMul" tensor { dtype: DT_FLOAT shape { dim { size: 3 } dim { size: 7 } } allocation_description { requested_bytes: 84 allocated_bytes: 256 allocator_name: "GPU_0_bfc" allocation_id: 5 has_single_reference: true ptr: 140197717084160 } } }
2023-12-23 05:27:54.985675: I tensorflow/stream_executor/stream.cc:3164] [stream=0x5a9132e0,impl=0x1c418c40] Called Stream::ThenBlasGemm(transa=NoTranspose, transb=NoTranspose, m=7, n=3, k=5, alpha=1, a=0x7f8253200000, lda=7, b=0x7f8253200700, ldb=5, beta=0, c=0x7f8253200800, ldc=7)
2023-12-23 05:27:54.985683: I tensorflow/stream_executor/plugin_registry.cc:246] Selecting default BLAS plugin, cuBLAS
2023-12-23 05:27:54.985715: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11
2023-12-23 05:27:55.665512: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11
2023-12-23 05:27:55.665583: I tensorflow/stream_executor/cuda/cuda_blas.cc:1799] doing cuBLAS SGEMM: at=0 bt=0 m=7 n=3 k=5 alpha=1.000000 a=0x7f8253200000 lda=7 b=0x7f8253200700 ldb=5 beta=0.000000 c=0x7f8253200800 ldc=7
2023-12-23 05:27:55.666084: I tensorflow/core/common_runtime/gpu/gpu_device.cc:601] GpuDevice::ComputeHelper scheduled MatMul op MatMul on GPU 0 stream[0]
2023-12-23 05:27:55.666158: I tensorflow/core/framework/log_memory.cc:34] __LOG_MEMORY__ MemoryLogTensorOutput { step_id: 1 kernel_name: "MatMul" tensor { dtype: DT_FLOAT shape { dim { size: 3 } dim { size: 7 } } allocation_description { requested_bytes: 84 allocated_bytes: 256 allocator_name: "GPU_0_bfc" allocation_id: 5 has_single_reference: true ptr: 140197717084160 } } }
2023-12-23 05:27:55.666178: I tensorflow/core/common_runtime/executor.cc:817] Synchronous kernel done: 7 step 1 {{node MatMul}} = MatMul[T=DT_FLOAT, _XlaHasReferenceVars=false, transpose_a=false, transpose_b=false, _device="/job:localhost/replica:0/task:0/device:GPU:0"](_arg_X_0_0/_1, Weight/read) device: /job:localhost/replica:0/task:0/device:GPU:0
2023-12-23 05:27:55.666188: I tensorflow/core/framework/log_memory.cc:34] __LOG_MEMORY__ MemoryLogTensorDeallocation { allocation_id: 4 allocator_name: "GPU_0_bfc" }
2023-12-23 05:27:55.666194: I tensorflow/core/common_runtime/bfc_allocator.cc:660] DeallocateRaw GPU_0_bfc 60
2023-12-23 05:27:55.666206: I tensorflow/core/common_runtime/executor.cc:764] Process node: 8 step 1 {{node Add}} = Add[T=DT_FLOAT, _XlaHasReferenceVars=false, _device="/job:localhost/replica:0/task:0/device:GPU:0"](MatMul, Bias/read) device: /job:localhost/replica:0/task:0/device:GPU:0
2023-12-23 05:27:55.666218: I tensorflow/core/common_runtime/gpu/gpu_device.cc:575] GpuDevice::ComputeHelper Add op Add on GPU 0 stream[0]
2023-12-23 05:27:55.666225: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 1
2023-12-23 05:27:55.666279: I tensorflow/core/common_runtime/gpu/gpu_device.cc:601] GpuDevice::ComputeHelper scheduled Add op Add on GPU 0 stream[0]
2023-12-23 05:27:55.666297: I tensorflow/core/framework/log_memory.cc:34] __LOG_MEMORY__ MemoryLogTensorOutput { step_id: 1 kernel_name: "Add" tensor { dtype: DT_FLOAT shape { dim { size: 3 } dim { size: 7 } } allocation_description { requested_bytes: 84 allocated_bytes: 256 allocator_name: "GPU_0_bfc" allocation_id: 5 ptr: 140197717084160 } } }
2023-12-23 05:27:55.666306: I tensorflow/core/common_runtime/executor.cc:817] Synchronous kernel done: 8 step 1 {{node Add}} = Add[T=DT_FLOAT, _XlaHasReferenceVars=false, _device="/job:localhost/replica:0/task:0/device:GPU:0"](MatMul, Bias/read) device: /job:localhost/replica:0/task:0/device:GPU:0
2023-12-23 05:27:55.666315: I tensorflow/core/common_runtime/executor.cc:764] Process node: 9 step 1 {{node Sigmoid}} = Sigmoid[T=DT_FLOAT, _XlaHasReferenceVars=false, _device="/job:localhost/replica:0/task:0/device:GPU:0"](Add) device: /job:localhost/replica:0/task:0/device:GPU:0
2023-12-23 05:27:55.666322: I tensorflow/core/common_runtime/gpu/gpu_device.cc:575] GpuDevice::ComputeHelper Sigmoid op Sigmoid on GPU 0 stream[0]
2023-12-23 05:27:55.666327: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 1
2023-12-23 05:27:55.666350: I tensorflow/core/common_runtime/gpu/gpu_device.cc:601] GpuDevice::ComputeHelper scheduled Sigmoid op Sigmoid on GPU 0 stream[0]
2023-12-23 05:27:55.666364: I tensorflow/core/framework/log_memory.cc:34] __LOG_MEMORY__ MemoryLogTensorOutput { step_id: 1 kernel_name: "Sigmoid" tensor { dtype: DT_FLOAT shape { dim { size: 3 } dim { size: 7 } } allocation_description { requested_bytes: 84 allocated_bytes: 256 allocator_name: "GPU_0_bfc" allocation_id: 5 ptr: 140197717084160 } } }
2023-12-23 05:27:55.666372: I tensorflow/core/common_runtime/executor.cc:817] Synchronous kernel done: 9 step 1 {{node Sigmoid}} = Sigmoid[T=DT_FLOAT, _XlaHasReferenceVars=false, _device="/job:localhost/replica:0/task:0/device:GPU:0"](Add) device: /job:localhost/replica:0/task:0/device:GPU:0
2023-12-23 05:27:55.666385: I tensorflow/core/common_runtime/executor.cc:764] Process node: 10 step 1 {{node Sigmoid/_2}} = _Send[T=DT_FLOAT, _dst="_retval_Sigmoid_0_0", _src="Sigmoid", client_terminated=false, recv_device="/job:localhost/replica:0/task:0/device:CPU:0", send_device="/job:localhost/replica:0/task:0/device:GPU:0", send_device_incarnation=1, tensor_name="edge_14_Sigmoid", _device="/job:localhost/replica:0/task:0/device:GPU:0"](Sigmoid) device: /job:localhost/replica:0/task:0/device:GPU:0
2023-12-23 05:27:55.666392: I tensorflow/core/common_runtime/gpu/gpu_device.cc:575] GpuDevice::ComputeHelper Sigmoid/_2 op _Send on GPU 0 stream[0]
2023-12-23 05:27:55.666397: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 1
2023-12-23 05:27:55.666404: I tensorflow/core/kernels/sendrecv_ops.cc:96] Send /job:localhost/replica:0/task:0/device:GPU:0;0000000000000001;/job:localhost/replica:0/task:0/device:CPU:0;edge_14_Sigmoid;0:0 using 1527301904
2023-12-23 05:27:55.666411: I tensorflow/core/common_runtime/rendezvous_mgr.cc:165] IntraProcessRendezvous Send 0x5b08c710 /job:localhost/replica:0/task:0/device:GPU:0;0000000000000001;/job:localhost/replica:0/task:0/device:CPU:0;edge_14_Sigmoid;0:0
2023-12-23 05:27:55.666424: I tensorflow/core/common_runtime/bfc_allocator.cc:276] AllocateRaw gpu_host_bfc  84
2023-12-23 05:27:55.666441: I tensorflow/core/framework/log_memory.cc:34] __LOG_MEMORY__ MemoryLogTensorAllocation { step_id: -6 kernel_name: "Unknown (with attributes)" tensor { dtype: DT_FLOAT shape { dim { size: 3 } dim { size: 7 } } allocation_description { requested_bytes: 84 allocated_bytes: 256 allocator_name: "gpu_host_bfc" allocation_id: 3 has_single_reference: true ptr: 140197714984960 } } }
2023-12-23 05:27:55.666449: I tensorflow/core/common_runtime/copy_tensor.cc:211] Copy edge_14_Sigmoid
2023-12-23 05:27:55.666456: I tensorflow/core/common_runtime/gpu/gpu_util.cc:258] CopyGPUTensorToCPU
2023-12-23 05:27:55.666467: I tensorflow/stream_executor/stream.cc:1397] [stream=0x51838640,impl=0x5a6e0f10] Called Stream::ThenWaitFor(other=0x5a9132e0)
2023-12-23 05:27:55.666481: I tensorflow/stream_executor/stream.cc:4501] [stream=0x51838640,impl=0x5a6e0f10] Called Stream::ThenMemcpy(host_dst=0x7f8253000000, gpu_src=0x7f8253200800, size=84)
2023-12-23 05:27:55.666506: I tensorflow/stream_executor/cuda/cuda_driver.cc:1278] successfully enqueued async memcpy d2h of 84 bytes from 0x7f8253200800 to 0x7f8253000000 on stream 0x3f6cbe90
2023-12-23 05:27:55.666514: I tensorflow/core/common_runtime/device/device_event_mgr.cc:170] QueueInUse  free_events_ 1 used_events_ 0
2023-12-23 05:27:55.666521: I tensorflow/stream_executor/stream.cc:330] [stream=0x51838640,impl=0x5a6e0f10] Called Stream::ThenRecordEvent(event=0x1d06f60)
2023-12-23 05:27:55.666529: I tensorflow/core/common_runtime/device/device_event_mgr.cc:208] PollEvents  free_events_ 0 used_events_ 1
2023-12-23 05:27:55.666556: I tensorflow/core/common_runtime/gpu/gpu_device.cc:601] GpuDevice::ComputeHelper scheduled Sigmoid/_2 op _Send on GPU 0 stream[0]
2023-12-23 05:27:55.666566: I tensorflow/core/common_runtime/device/device_event_mgr.cc:208] PollEvents  free_events_ 1 used_events_ 0
2023-12-23 05:27:55.666587: I tensorflow/core/common_runtime/executor.cc:817] Synchronous kernel done: 10 step 1 {{node Sigmoid/_2}} = _Send[T=DT_FLOAT, _dst="_retval_Sigmoid_0_0", _src="Sigmoid", client_terminated=false, recv_device="/job:localhost/replica:0/task:0/device:CPU:0", send_device="/job:localhost/replica:0/task:0/device:GPU:0", send_device_incarnation=1, tensor_name="edge_14_Sigmoid", _device="/job:localhost/replica:0/task:0/device:GPU:0"](Sigmoid) device: /job:localhost/replica:0/task:0/device:GPU:0
2023-12-23 05:27:55.666601: I tensorflow/core/framework/log_memory.cc:34] __LOG_MEMORY__ MemoryLogTensorDeallocation { allocation_id: 5 allocator_name: "GPU_0_bfc" }
2023-12-23 05:27:55.666607: I tensorflow/core/common_runtime/bfc_allocator.cc:660] DeallocateRaw GPU_0_bfc 84
2023-12-23 05:27:55.666616: I tensorflow/core/framework/log_memory.cc:34] __LOG_MEMORY__ MemoryLogTensorOutput { step_id: 1 kernel_name: "Sigmoid/_3" tensor { dtype: DT_FLOAT shape { dim { size: 3 } dim { size: 7 } } allocation_description { requested_bytes: 84 allocated_bytes: 256 allocator_name: "gpu_host_bfc" allocation_id: 3 ptr: 140197714984960 } } }
2023-12-23 05:27:55.666648: I tensorflow/core/common_runtime/propagator_state.cc:357] Delete frame 0
2023-12-23 05:27:55.666658: I tensorflow/stream_executor/stream.cc:4980] [stream=0x5a9132e0,impl=0x1c418c40] Called Stream::BlockHostUntilDone()
2023-12-23 05:27:55.666665: I tensorflow/stream_executor/temporary_memory_manager.cc:63] deallocated 0 finalized temporaries
2023-12-23 05:27:55.666672: I tensorflow/stream_executor/cuda/cuda_driver.cc:250] ScopedActivateContext switching to 1
2023-12-23 05:27:55.666681: I tensorflow/core/common_runtime/executor.cc:611] Async kernel done: 4 step 1 {{node Sigmoid/_3}} = _Recv[_dst="_retval_Sigmoid_0_0", _src="Sigmoid", client_terminated=false, recv_device="/job:localhost/replica:0/task:0/device:CPU:0", send_device="/job:localhost/replica:0/task:0/device:GPU:0", send_device_incarnation=1, tensor_name="edge_14_Sigmoid", tensor_type=DT_FLOAT, _device="/job:localhost/replica:0/task:0/device:CPU:0"]() device: /job:localhost/replica:0/task:0/device:CPU:0
2023-12-23 05:27:55.666703: I tensorflow/core/common_runtime/executor.cc:764] Process node: 5 step 1 {{node _retval_Sigmoid_0_0}} = _Retval[T=DT_FLOAT, _XlaHasReferenceVars=false, index=0, _device="/job:localhost/replica:0/task:0/device:CPU:0"](Sigmoid/_3) device: /job:localhost/replica:0/task:0/device:CPU:0
2023-12-23 05:27:55.666713: I tensorflow/core/common_runtime/executor.cc:817] Synchronous kernel done: 5 step 1 {{node _retval_Sigmoid_0_0}} = _Retval[T=DT_FLOAT, _XlaHasReferenceVars=false, index=0, _device="/job:localhost/replica:0/task:0/device:CPU:0"](Sigmoid/_3) device: /job:localhost/replica:0/task:0/device:CPU:0
2023-12-23 05:27:55.666720: I tensorflow/core/common_runtime/propagator_state.cc:357] Delete frame 0
Successfully ran session! model=test_model_v1


Output Sigmoid:0:
Tensor<type: float shape: [3,7] values: [0.500614464 0.498256832 0.503368378...]...>
>> 0.500614 0.498257 0.503368 0.498498 0.500473 0.50682 0.501661 
>> 0.502666 0.498646 0.505361 0.496998 0.498443 0.501473 0.4982 
>> 0.502755 0.496212 0.508648 0.499186 0.50004 0.503455 0.499526 

FINISHED
2023-12-23 05:27:55.666810: I tensorflow/core/framework/log_memory.cc:34] __LOG_MEMORY__ MemoryLogTensorDeallocation { allocation_id: 3 allocator_name: "gpu_host_bfc" }
2023-12-23 05:27:55.666821: I tensorflow/core/common_runtime/bfc_allocator.cc:660] DeallocateRaw gpu_host_bfc 84
2023-12-23 05:27:55.666832: I tensorflow/core/framework/log_memory.cc:34] __LOG_MEMORY__ MemoryLogTensorDeallocation { allocation_id: 1 allocator_name: "cpu" }
son.nguyen@n238-046-199:~/workspace/dtf/tfsession$ 